(* ---------------------------------------------------------- *)
(* --- Complete behaviors 'not_newly_idle_without_idle',
                   'not_newly_idle_with_idle_cpu',
                   'not_newly_idle_with_idle_core',
                   'not_newly_idle_with_idle', 'newly_idle', 'race_condition' --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_complete_not_newly_idle_without_idle_no___
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import A_thread_variables_properties.A_thread_variables_properties
use import Compound.Compound
use import Cint.Cint
use import A_schedule_cpumask.A_schedule_cpumask
use import Cbits.Cbits

(*
goal WP "expl:Complete behaviors 'not_newly_idle_without_idle',
                   'not_newly_idle_with_idle_cpu',
                   'not_newly_idle_with_idle_core',
                   'not_newly_idle_with_idle', 'newly_idle', 'race_condition'":
*)
goal goal0:
  forall i : int.
  forall t : map int int.
  forall t_1 : map addr int.
  forall t_2 : map addr addr.
  forall a_1 a : addr.
  let x = t_1[(shiftfield_f5_lb_env_dst_cpu a_1)] in
  let x_1 = t_1[(shiftfield_f5_lb_env_idle a_1)] in
  let a_2 = t_2[(shiftfield_f5_lb_env_cpus a_1)] in
  let a_3 = t_2[(shiftfield_f5_lb_env_sd a_1)] in
  let x_2 = t_1[(shiftfield_f3_sched_domain_flags a_3)] in
  let a_4 = t_2[(shiftfield_f3_sched_domain_groups a_3)] in
  let a_5 = t_2[(shiftfield_f1_cpumask_bits a_2)] in
  let x_3 = t_1[(shift_uint8 a_5 x)] in
  let a_6 = (shift_uint8 a_5 0) in
  let a_7 = t_2[(shiftfield_f1_cpumask_bits ((l_group_balance_mask a_4)))] in
  let x_4 = (land 7 x_2) in
  (0 <= i) ->
  (i < l_size) ->
  (0 <= x) ->
  (x < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_2)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 x_1)) ->
  ((is_sint32 x)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t t_2[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_3 2)) ->
  ((is_sint32 x_2)) ->
  ((valid_rd t a_4 1)) ->
  ((is_uint8 x_3)) ->
  ((valid_rd t a_6 l_size)) ->
  (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
   ((separated a_6 l_size
      ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))]
         0)) l_size))) ->
  (forall i_1 : int. let a_8 = (shift_cpumask a i_1) in (0 <= i_1) ->
   (i_1 < l_size) ->
   (((valid_rd t a_8 1)) /\
    ((valid_rw t ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_8)] 0))
       l_size)))) ->
  (forall a_8 : addr. let a_9 = (l_sched_group_cpus a_8) in
   let a_10 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_9)] 0) in
   ((valid_rd t a_9 1)) /\ ((valid_rd t a_10 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_10 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall a_8 : addr. let a_9 = (l_sched_group_mask a_8) in
   let a_10 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_9)] 0) in
   ((valid_rd t a_9 1)) /\ ((valid_rd t a_10 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_10 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall a_8 : addr. let a_9 = (l_group_balance_mask a_8) in
   let a_10 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_9)] 0) in
   ((valid_rd t a_9 1)) /\ ((valid_rd t a_10 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_10 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall i_1 : int. let a_8 = (l_cpu_smt_mask i_1) in
   let a_9 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_8)] 0) in
   (0 <= i_1) -> (i_1 < l_size) ->
   (((valid_rd t a_8 1)) /\ ((valid_rd t a_9 l_size)) /\
    (forall i_2 : int. (0 <= i_2) -> (i_2 < l_size) ->
     ((separated a_9 l_size
        ((shift_uint8
           t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_2)))] 0))
        l_size))))) ->
  ((x_3 = 0) \/ ((x_1 = 2) /\ (x_3 <> 0)) \/
   ((x_1 <> 2) /\ (x_3 <> 0) /\
    (forall i_1 : int. (t_1[(shift_uint8 a_5 i_1)] <> 0) ->
     (t_1[(shift_uint8 a_7 i_1)] <> 0) -> (0 <= i_1) -> (i_1 < l_size) ->
     (((l_idle_cpu i_1)) = 0))) \/
   ((x_1 <> 2) /\ (x_4 = 0) /\ (x_3 <> 0) /\
    (exists i_1 : int. (t_1[(shift_uint8 a_5 i_1)] <> 0) /\
     (t_1[(shift_uint8 a_7 i_1)] <> 0) /\ (0 <= i_1) /\ (i_1 < l_size) /\
     ((p_idle_core t_2 t_1 i_1)))) \/
   ((x_1 <> 2) /\ (x_4 <> 0) /\ (x_3 <> 0) /\
    (exists i_1 : int. (((l_idle_cpu i_1)) <> 0) /\
     (t_1[(shift_uint8 a_5 i_1)] <> 0) /\
     (t_1[(shift_uint8 a_7 i_1)] <> 0) /\ (0 <= i_1) /\ (i_1 < l_size))) \/
   ((x_1 <> 2) /\ (x_4 = 0) /\ (x_3 <> 0) /\
    (forall i_1 : int. (t_1[(shift_uint8 a_5 i_1)] <> 0) ->
     (t_1[(shift_uint8 a_7 i_1)] <> 0) -> (0 <= i_1) -> (i_1 < l_size) ->
     (not (p_idle_core t_2 t_1 i_1))) /\
    (exists i_1 : int. (((l_idle_cpu i_1)) <> 0) /\
     (t_1[(shift_uint8 a_5 i_1)] <> 0) /\
     (t_1[(shift_uint8 a_7 i_1)] <> 0) /\ (0 <= i_1) /\ (i_1 < l_size))))

end

(* ---------------------------------------------------------- *)
(* --- Disjoint behaviors 'not_newly_idle_without_idle',
                   'not_newly_idle_with_idle_cpu',
                   'not_newly_idle_with_idle_core',
                   'not_newly_idle_with_idle', 'newly_idle', 'race_condition' --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_disjoint_not_newly_idle_without_idle_no___
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import A_thread_variables_properties.A_thread_variables_properties
use import Compound.Compound
use import Cint.Cint
use import A_schedule_cpumask.A_schedule_cpumask
use import Cbits.Cbits

(*
goal WP "expl:Disjoint behaviors 'not_newly_idle_without_idle',
                   'not_newly_idle_with_idle_cpu',
                   'not_newly_idle_with_idle_core',
                   'not_newly_idle_with_idle', 'newly_idle', 'race_condition'":
*)
goal goal1:
  forall i : int.
  forall t : map int int.
  forall t_1 : map addr int.
  forall t_2 : map addr addr.
  forall a_1 a : addr.
  let x = t_1[(shiftfield_f5_lb_env_dst_cpu a_1)] in
  let x_1 = t_1[(shiftfield_f5_lb_env_idle a_1)] in
  let a_2 = t_2[(shiftfield_f5_lb_env_cpus a_1)] in
  let a_3 = t_2[(shiftfield_f5_lb_env_sd a_1)] in
  let x_2 = t_1[(shiftfield_f3_sched_domain_flags a_3)] in
  let a_4 = t_2[(shiftfield_f3_sched_domain_groups a_3)] in
  let a_5 = t_2[(shiftfield_f1_cpumask_bits a_2)] in
  let x_3 = t_1[(shift_uint8 a_5 x)] in
  let a_6 = (shift_uint8 a_5 0) in
  let a_7 = t_2[(shiftfield_f1_cpumask_bits ((l_group_balance_mask a_4)))] in
  (0 <= i) ->
  (i < l_size) ->
  (0 <= x) ->
  (x < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_2)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 x_1)) ->
  ((is_sint32 x)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t t_2[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_3 2)) ->
  ((is_sint32 x_2)) ->
  ((valid_rd t a_4 1)) ->
  ((is_uint8 x_3)) ->
  ((valid_rd t a_6 l_size)) ->
  (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
   ((separated a_6 l_size
      ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))]
         0)) l_size))) ->
  (forall i_1 : int. let a_8 = (shift_cpumask a i_1) in (0 <= i_1) ->
   (i_1 < l_size) ->
   (((valid_rd t a_8 1)) /\
    ((valid_rw t ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_8)] 0))
       l_size)))) ->
  (forall a_8 : addr. let a_9 = (l_sched_group_cpus a_8) in
   let a_10 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_9)] 0) in
   ((valid_rd t a_9 1)) /\ ((valid_rd t a_10 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_10 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall a_8 : addr. let a_9 = (l_sched_group_mask a_8) in
   let a_10 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_9)] 0) in
   ((valid_rd t a_9 1)) /\ ((valid_rd t a_10 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_10 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall a_8 : addr. let a_9 = (l_group_balance_mask a_8) in
   let a_10 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_9)] 0) in
   ((valid_rd t a_9 1)) /\ ((valid_rd t a_10 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_10 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall i_1 : int. let a_8 = (l_cpu_smt_mask i_1) in
   let a_9 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_8)] 0) in
   (0 <= i_1) -> (i_1 < l_size) ->
   (((valid_rd t a_8 1)) /\ ((valid_rd t a_9 l_size)) /\
    (forall i_2 : int. (0 <= i_2) -> (i_2 < l_size) ->
     ((separated a_9 l_size
        ((shift_uint8
           t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_2)))] 0))
        l_size))))) ->
  ((x_1 = 2) \/ (((land 7 x_2)) <> 0) \/ (x_3 = 0) \/
   (exists i_1 : int. (((l_idle_cpu i_1)) <> 0) /\
    (t_1[(shift_uint8 a_5 i_1)] <> 0) /\ (t_1[(shift_uint8 a_7 i_1)] <> 0) /\
    (0 <= i_1) /\ (i_1 < l_size)) \/
   (forall i_1 : int. (t_1[(shift_uint8 a_5 i_1)] = 0) \/
    (t_1[(shift_uint8 a_7 i_1)] = 0) \/ (i_1 < 0) \/ (l_size <= i_1) \/
    (not (p_idle_core t_2 t_1 i_1))))

end

(* ---------------------------------------------------------- *)
(* --- Assertion 'rte,mem_access' (file c11.c, line 114)  --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_assert_rte_mem_access
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import A_thread_variables_properties.A_thread_variables_properties
use import Compound.Compound
use import Cint.Cint
use import A_schedule_cpumask.A_schedule_cpumask

(*
goal WP "expl:Assertion 'rte,mem_access' (file c11.c, line 114)":
*)
goal goal2:
  forall i : int.
  forall t : map int int.
  forall t_1 : map addr int.
  forall t_2 : map addr addr.
  forall a_1 a : addr.
  let x = t_1[(shiftfield_f5_lb_env_dst_cpu a_1)] in
  let a_2 = t_2[(shiftfield_f5_lb_env_cpus a_1)] in
  let a_3 = (shiftfield_f5_lb_env_sd a_1) in
  let a_4 = t_2[a_3] in
  let a_5 = t_2[(shiftfield_f1_cpumask_bits a_2)] in
  let a_6 = (shift_uint8 a_5 0) in
  (0 <= i) ->
  (i < l_size) ->
  (0 <= x) ->
  (x < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_2)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 t_1[(shiftfield_f5_lb_env_idle a_1)])) ->
  ((is_sint32 x)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t t_2[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_4 2)) ->
  ((is_sint32 t_1[(shiftfield_f3_sched_domain_flags a_4)])) ->
  ((valid_rd t t_2[(shiftfield_f3_sched_domain_groups a_4)] 1)) ->
  ((is_uint8 t_1[(shift_uint8 a_5 x)])) ->
  ((valid_rd t a_6 l_size)) ->
  (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
   ((separated a_6 l_size
      ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))]
         0)) l_size))) ->
  (forall i_1 : int. let a_7 = (shift_cpumask a i_1) in (0 <= i_1) ->
   (i_1 < l_size) ->
   (((valid_rd t a_7 1)) /\
    ((valid_rw t ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_7)] 0))
       l_size)))) ->
  (forall a_7 : addr. let a_8 = (l_sched_group_cpus a_7) in
   let a_9 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_8)] 0) in
   ((valid_rd t a_8 1)) /\ ((valid_rd t a_9 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_9 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall a_7 : addr. let a_8 = (l_sched_group_mask a_7) in
   let a_9 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_8)] 0) in
   ((valid_rd t a_8 1)) /\ ((valid_rd t a_9 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_9 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall a_7 : addr. let a_8 = (l_group_balance_mask a_7) in
   let a_9 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_8)] 0) in
   ((valid_rd t a_8 1)) /\ ((valid_rd t a_9 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_9 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall i_1 : int. let a_7 = (l_cpu_smt_mask i_1) in
   let a_8 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_7)] 0) in
   (0 <= i_1) -> (i_1 < l_size) ->
   (((valid_rd t a_7 1)) /\ ((valid_rd t a_8 l_size)) /\
    (forall i_2 : int. (0 <= i_2) -> (i_2 < l_size) ->
     ((separated a_8 l_size
        ((shift_uint8
           t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_2)))] 0))
        l_size))))) ->
  ((valid_rd t a_3 1))

end

(* ---------------------------------------------------------- *)
(* --- Assertion 'rte,mem_access' (file c11.c, line 114)  --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_assert_rte_mem_access_2
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import A_thread_variables_properties.A_thread_variables_properties
use import Compound.Compound
use import Cint.Cint
use import A_schedule_cpumask.A_schedule_cpumask

(*
goal WP "expl:Assertion 'rte,mem_access' (file c11.c, line 114)":
*)
goal goal3:
  forall i : int.
  forall t : map int int.
  forall t_1 : map addr int.
  forall t_2 : map addr addr.
  forall a_1 a : addr.
  let x = t_1[(shiftfield_f5_lb_env_dst_cpu a_1)] in
  let a_2 = t_2[(shiftfield_f5_lb_env_cpus a_1)] in
  let a_3 = t_2[(shiftfield_f5_lb_env_sd a_1)] in
  let a_4 = (shiftfield_f3_sched_domain_groups a_3) in
  let a_5 = t_2[(shiftfield_f1_cpumask_bits a_2)] in
  let a_6 = (shift_uint8 a_5 0) in
  (0 <= i) ->
  (i < l_size) ->
  (0 <= x) ->
  (x < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_2)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 t_1[(shiftfield_f5_lb_env_idle a_1)])) ->
  ((is_sint32 x)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t t_2[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_3 2)) ->
  ((is_sint32 t_1[(shiftfield_f3_sched_domain_flags a_3)])) ->
  ((valid_rd t t_2[a_4] 1)) ->
  ((is_uint8 t_1[(shift_uint8 a_5 x)])) ->
  ((valid_rd t a_6 l_size)) ->
  (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
   ((separated a_6 l_size
      ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))]
         0)) l_size))) ->
  (forall i_1 : int. let a_7 = (shift_cpumask a i_1) in (0 <= i_1) ->
   (i_1 < l_size) ->
   (((valid_rd t a_7 1)) /\
    ((valid_rw t ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_7)] 0))
       l_size)))) ->
  (forall a_7 : addr. let a_8 = (l_sched_group_cpus a_7) in
   let a_9 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_8)] 0) in
   ((valid_rd t a_8 1)) /\ ((valid_rd t a_9 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_9 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall a_7 : addr. let a_8 = (l_sched_group_mask a_7) in
   let a_9 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_8)] 0) in
   ((valid_rd t a_8 1)) /\ ((valid_rd t a_9 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_9 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall a_7 : addr. let a_8 = (l_group_balance_mask a_7) in
   let a_9 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_8)] 0) in
   ((valid_rd t a_8 1)) /\ ((valid_rd t a_9 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_9 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall i_1 : int. let a_7 = (l_cpu_smt_mask i_1) in
   let a_8 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_7)] 0) in
   (0 <= i_1) -> (i_1 < l_size) ->
   (((valid_rd t a_7 1)) /\ ((valid_rd t a_8 l_size)) /\
    (forall i_2 : int. (0 <= i_2) -> (i_2 < l_size) ->
     ((separated a_8 l_size
        ((shift_uint8
           t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_2)))] 0))
        l_size))))) ->
  ((valid_rd t a_4 1))

end

(* ---------------------------------------------------------- *)
(* --- Assertion 'rte,mem_access' (file c11.c, line 121)  --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_assert_rte_mem_access_3
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import A_thread_variables_properties.A_thread_variables_properties
use import Compound.Compound
use import Cint.Cint
use import A_schedule_cpumask.A_schedule_cpumask

(*
goal WP "expl:Assertion 'rte,mem_access' (file c11.c, line 121)":
*)
goal goal4:
  forall i : int.
  forall t : map int int.
  forall t_1 : map addr int.
  forall t_2 : map addr addr.
  forall a_1 a : addr.
  let a_2 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x = t_1[a_2] in
  let a_3 = (shiftfield_f5_lb_env_sd a_1) in
  let a_4 = t_2[(shiftfield_f5_lb_env_cpus a_1)] in
  let a_5 = t_2[a_3] in
  let a_6 = (shiftfield_f3_sched_domain_groups a_5) in
  let a_7 = t_2[(shiftfield_f1_cpumask_bits a_4)] in
  let a_8 = (shift_uint8 a_7 0) in
  (0 <= i) ->
  (i < l_size) ->
  (0 <= x) ->
  (x < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_2)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 t_1[(shiftfield_f5_lb_env_idle a_1)])) ->
  ((is_sint32 x)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_4 1)) ->
  ((valid_rd t t_2[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_5 2)) ->
  ((is_sint32 t_1[(shiftfield_f3_sched_domain_flags a_5)])) ->
  ((valid_rd t a_6 1)) ->
  ((valid_rd t t_2[a_6] 1)) ->
  ((is_uint8 t_1[(shift_uint8 a_7 x)])) ->
  ((valid_rd t a_8 l_size)) ->
  (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
   ((separated a_8 l_size
      ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))]
         0)) l_size))) ->
  (forall i_1 : int. let a_9 = (shift_cpumask a i_1) in (0 <= i_1) ->
   (i_1 < l_size) ->
   (((valid_rd t a_9 1)) /\
    ((valid_rw t ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_9)] 0))
       l_size)))) ->
  (forall a_9 : addr. let a_10 = (l_sched_group_cpus a_9) in
   let a_11 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_10)] 0) in
   ((valid_rd t a_10 1)) /\ ((valid_rd t a_11 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_11 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall a_9 : addr. let a_10 = (l_sched_group_mask a_9) in
   let a_11 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_10)] 0) in
   ((valid_rd t a_10 1)) /\ ((valid_rd t a_11 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_11 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall a_9 : addr. let a_10 = (l_group_balance_mask a_9) in
   let a_11 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_10)] 0) in
   ((valid_rd t a_10 1)) /\ ((valid_rd t a_11 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_11 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall i_1 : int. let a_9 = (l_cpu_smt_mask i_1) in
   let a_10 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_9)] 0) in
   (0 <= i_1) -> (i_1 < l_size) ->
   (((valid_rd t a_9 1)) /\ ((valid_rd t a_10 l_size)) /\
    (forall i_2 : int. (0 <= i_2) -> (i_2 < l_size) ->
     ((separated a_10 l_size
        ((shift_uint8
           t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_2)))] 0))
        l_size))))) ->
  ((valid_rd t a_2 1))

end

(* ---------------------------------------------------------- *)
(* --- Assertion 'rte,mem_access' (file c11.c, line 121)  --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_assert_rte_mem_access_4
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import A_thread_variables_properties.A_thread_variables_properties
use import Compound.Compound
use import Cint.Cint
use import A_schedule_cpumask.A_schedule_cpumask

(*
goal WP "expl:Assertion 'rte,mem_access' (file c11.c, line 121)":
*)
goal goal5:
  forall i : int.
  forall t : map int int.
  forall t_1 : map addr int.
  forall t_2 : map addr addr.
  forall a_1 a : addr.
  let x = t_1[(shiftfield_f5_lb_env_dst_cpu a_1)] in
  let a_2 = (shiftfield_f5_lb_env_sd a_1) in
  let a_3 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_4 = t_2[a_3] in
  let a_5 = t_2[a_2] in
  let a_6 = (shiftfield_f3_sched_domain_groups a_5) in
  let a_7 = t_2[(shiftfield_f1_cpumask_bits a_4)] in
  let a_8 = (shift_uint8 a_7 0) in
  (0 <= i) ->
  (i < l_size) ->
  (0 <= x) ->
  (x < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_2)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 t_1[(shiftfield_f5_lb_env_idle a_1)])) ->
  ((is_sint32 x)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t a_4 1)) ->
  ((valid_rd t t_2[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_5 2)) ->
  ((is_sint32 t_1[(shiftfield_f3_sched_domain_flags a_5)])) ->
  ((valid_rd t a_6 1)) ->
  ((valid_rd t t_2[a_6] 1)) ->
  ((is_uint8 t_1[(shift_uint8 a_7 x)])) ->
  ((valid_rd t a_8 l_size)) ->
  (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
   ((separated a_8 l_size
      ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))]
         0)) l_size))) ->
  (forall i_1 : int. let a_9 = (shift_cpumask a i_1) in (0 <= i_1) ->
   (i_1 < l_size) ->
   (((valid_rd t a_9 1)) /\
    ((valid_rw t ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_9)] 0))
       l_size)))) ->
  (forall a_9 : addr. let a_10 = (l_sched_group_cpus a_9) in
   let a_11 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_10)] 0) in
   ((valid_rd t a_10 1)) /\ ((valid_rd t a_11 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_11 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall a_9 : addr. let a_10 = (l_sched_group_mask a_9) in
   let a_11 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_10)] 0) in
   ((valid_rd t a_10 1)) /\ ((valid_rd t a_11 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_11 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall a_9 : addr. let a_10 = (l_group_balance_mask a_9) in
   let a_11 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_10)] 0) in
   ((valid_rd t a_10 1)) /\ ((valid_rd t a_11 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_11 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall i_1 : int. let a_9 = (l_cpu_smt_mask i_1) in
   let a_10 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_9)] 0) in
   (0 <= i_1) -> (i_1 < l_size) ->
   (((valid_rd t a_9 1)) /\ ((valid_rd t a_10 l_size)) /\
    (forall i_2 : int. (0 <= i_2) -> (i_2 < l_size) ->
     ((separated a_10 l_size
        ((shift_uint8
           t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_2)))] 0))
        l_size))))) ->
  ((valid_rd t a_3 1))

end

(* ---------------------------------------------------------- *)
(* --- Assertion 'rte,bool_value' (file c11.c, line 121)  --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_assert_rte_bool_value
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import Compound.Compound
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import A_schedule_cpumask.A_schedule_cpumask

(*
goal WP "expl:Assertion 'rte,bool_value' (file c11.c, line 121)":
*)
goal goal6:
  forall i_1 i : int.
  forall t : map int int.
  forall t_1 : map addr int.
  forall t_2 : map addr addr.
  forall a_1 a : addr.
  let a_2 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_3 = t_2[a_2] in
  let a_4 = t_2[(shiftfield_f1_cpumask_bits a_3)] in
  let a_5 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x = t_1[a_5] in
  let x_1 = t_1[(shift_uint8 a_4 x)] in
  let a_6 = (shiftfield_f5_lb_env_sd a_1) in
  let a_7 = t_2[a_6] in
  let a_8 = (shiftfield_f3_sched_domain_groups a_7) in
  let a_9 = (shift_uint8 a_4 0) in
  ((x_1 <> 0) <-> (i <> 0)) ->
  (0 <= i_1) ->
  (i_1 < l_size) ->
  (0 <= x) ->
  (x < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_2)) ->
  ((linked t)) ->
  ((is_uint8 i)) ->
  ((is_uint32 i_1)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 t_1[(shiftfield_f5_lb_env_idle a_1)])) ->
  ((is_sint32 x)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t a_5 1)) ->
  ((valid_rd t a_6 1)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t t_2[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_7 2)) ->
  ((is_sint32 t_1[(shiftfield_f3_sched_domain_flags a_7)])) ->
  ((valid_rd t a_8 1)) ->
  ((valid_rd t t_2[a_8] 1)) ->
  ((is_uint8 x_1)) ->
  ((valid_rd t a_9 l_size)) ->
  (forall i_2 : int. (0 <= i_2) -> (i_2 < l_size) ->
   ((separated a_9 l_size
      ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_2)))]
         0)) l_size))) ->
  (forall i_2 : int. let a_10 = (shift_cpumask a i_2) in (0 <= i_2) ->
   (i_2 < l_size) ->
   (((valid_rd t a_10 1)) /\
    ((valid_rw t ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_10)] 0))
       l_size)))) ->
  (forall a_10 : addr. let a_11 = (l_sched_group_cpus a_10) in
   let a_12 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_11)] 0) in
   ((valid_rd t a_11 1)) /\ ((valid_rd t a_12 l_size)) /\
   (forall i_2 : int. (0 <= i_2) -> (i_2 < l_size) ->
    ((separated a_12 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_2)))] 0))
       l_size)))) ->
  (forall a_10 : addr. let a_11 = (l_sched_group_mask a_10) in
   let a_12 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_11)] 0) in
   ((valid_rd t a_11 1)) /\ ((valid_rd t a_12 l_size)) /\
   (forall i_2 : int. (0 <= i_2) -> (i_2 < l_size) ->
    ((separated a_12 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_2)))] 0))
       l_size)))) ->
  (forall a_10 : addr. let a_11 = (l_group_balance_mask a_10) in
   let a_12 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_11)] 0) in
   ((valid_rd t a_11 1)) /\ ((valid_rd t a_12 l_size)) /\
   (forall i_2 : int. (0 <= i_2) -> (i_2 < l_size) ->
    ((separated a_12 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_2)))] 0))
       l_size)))) ->
  (forall i_2 : int. let a_10 = (l_cpu_smt_mask i_2) in
   let a_11 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_10)] 0) in
   (0 <= i_2) -> (i_2 < l_size) ->
   (((valid_rd t a_10 1)) /\ ((valid_rd t a_11 l_size)) /\
    (forall i_3 : int. (0 <= i_3) -> (i_3 < l_size) ->
     ((separated a_11 l_size
        ((shift_uint8
           t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_3)))] 0))
        l_size))))) ->
  ((i = 0) \/ (i = 1))

end

(* ---------------------------------------------------------- *)
(* --- Assertion 'rte,mem_access' (file c11.c, line 131)  --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_assert_rte_mem_access_5
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import Compound.Compound
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import A_schedule_cpumask.A_schedule_cpumask

(*
goal WP "expl:Assertion 'rte,mem_access' (file c11.c, line 131)":
*)
goal goal7:
  forall i : int.
  forall t : map int int.
  forall t_1 : map addr int.
  forall t_2 : map addr addr.
  forall a_1 a : addr.
  let a_2 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_3 = t_2[a_2] in
  let a_4 = t_2[(shiftfield_f1_cpumask_bits a_3)] in
  let a_5 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x = t_1[a_5] in
  let x_1 = t_1[(shift_uint8 a_4 x)] in
  let a_6 = (shiftfield_f5_lb_env_idle a_1) in
  let a_7 = (shiftfield_f5_lb_env_sd a_1) in
  let a_8 = t_2[a_7] in
  let a_9 = (shiftfield_f3_sched_domain_groups a_8) in
  let a_10 = (shift_uint8 a_4 0) in
  (x_1 <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= x) ->
  (x < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_2)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 t_1[a_6])) ->
  ((is_sint32 x)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t a_5 1)) ->
  ((valid_rd t a_7 1)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t t_2[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_8 2)) ->
  ((is_sint32 t_1[(shiftfield_f3_sched_domain_flags a_8)])) ->
  ((valid_rd t a_9 1)) ->
  ((valid_rd t t_2[a_9] 1)) ->
  ((is_uint8 x_1)) ->
  ((valid_rd t a_10 l_size)) ->
  (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
   ((separated a_10 l_size
      ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))]
         0)) l_size))) ->
  (forall i_1 : int. let a_11 = (shift_cpumask a i_1) in (0 <= i_1) ->
   (i_1 < l_size) ->
   (((valid_rd t a_11 1)) /\
    ((valid_rw t ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_11)] 0))
       l_size)))) ->
  (forall a_11 : addr. let a_12 = (l_sched_group_cpus a_11) in
   let a_13 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_12)] 0) in
   ((valid_rd t a_12 1)) /\ ((valid_rd t a_13 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_13 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall a_11 : addr. let a_12 = (l_sched_group_mask a_11) in
   let a_13 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_12)] 0) in
   ((valid_rd t a_12 1)) /\ ((valid_rd t a_13 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_13 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall a_11 : addr. let a_12 = (l_group_balance_mask a_11) in
   let a_13 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_12)] 0) in
   ((valid_rd t a_12 1)) /\ ((valid_rd t a_13 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_13 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall i_1 : int. let a_11 = (l_cpu_smt_mask i_1) in
   let a_12 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_11)] 0) in
   (0 <= i_1) -> (i_1 < l_size) ->
   (((valid_rd t a_11 1)) /\ ((valid_rd t a_12 l_size)) /\
    (forall i_2 : int. (0 <= i_2) -> (i_2 < l_size) ->
     ((separated a_12 l_size
        ((shift_uint8
           t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_2)))] 0))
        l_size))))) ->
  ((valid_rd t a_6 1))

end

(* ---------------------------------------------------------- *)
(* --- Assertion 'rte,mem_access' (file c11.c, line 132)  --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_assert_rte_mem_access_6
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import Compound.Compound
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import A_schedule_cpumask.A_schedule_cpumask

(*
goal WP "expl:Assertion 'rte,mem_access' (file c11.c, line 132)":
*)
goal goal8:
  forall i : int.
  forall t : map int int.
  forall t_1 : map addr int.
  forall t_2 : map addr addr.
  forall a_1 a : addr.
  let a_2 = (shiftfield_f5_lb_env_idle a_1) in
  let a_3 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_4 = t_2[a_3] in
  let a_5 = t_2[(shiftfield_f1_cpumask_bits a_4)] in
  let a_6 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x = t_1[a_6] in
  let x_1 = t_1[(shift_uint8 a_5 x)] in
  let a_7 = (shiftfield_f5_lb_env_sd a_1) in
  let a_8 = (shiftfield_f5_lb_env_dst_rq a_1) in
  let a_9 = t_2[a_7] in
  let a_10 = (shiftfield_f3_sched_domain_groups a_9) in
  let a_11 = (shift_uint8 a_5 0) in
  (t_1[a_2] = 2) ->
  (x_1 <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= x) ->
  (x < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_2)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((valid_rd t a_1 5)) ->
  ((is_sint32 x)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_6 1)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t a_7 1)) ->
  ((valid_rd t a_4 1)) ->
  ((valid_rd t t_2[a_8] 2)) ->
  ((valid_rd t a_9 2)) ->
  ((is_sint32 t_1[(shiftfield_f3_sched_domain_flags a_9)])) ->
  ((valid_rd t a_10 1)) ->
  ((valid_rd t t_2[a_10] 1)) ->
  ((is_uint8 x_1)) ->
  ((valid_rd t a_11 l_size)) ->
  (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
   ((separated a_11 l_size
      ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))]
         0)) l_size))) ->
  (forall i_1 : int. let a_12 = (shift_cpumask a i_1) in (0 <= i_1) ->
   (i_1 < l_size) ->
   (((valid_rd t a_12 1)) /\
    ((valid_rw t ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_12)] 0))
       l_size)))) ->
  (forall a_12 : addr. let a_13 = (l_sched_group_cpus a_12) in
   let a_14 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_13)] 0) in
   ((valid_rd t a_13 1)) /\ ((valid_rd t a_14 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_14 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall a_12 : addr. let a_13 = (l_sched_group_mask a_12) in
   let a_14 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_13)] 0) in
   ((valid_rd t a_13 1)) /\ ((valid_rd t a_14 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_14 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall a_12 : addr. let a_13 = (l_group_balance_mask a_12) in
   let a_14 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_13)] 0) in
   ((valid_rd t a_13 1)) /\ ((valid_rd t a_14 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_14 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall i_1 : int. let a_12 = (l_cpu_smt_mask i_1) in
   let a_13 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_12)] 0) in
   (0 <= i_1) -> (i_1 < l_size) ->
   (((valid_rd t a_12 1)) /\ ((valid_rd t a_13 l_size)) /\
    (forall i_2 : int. (0 <= i_2) -> (i_2 < l_size) ->
     ((separated a_13 l_size
        ((shift_uint8
           t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_2)))] 0))
        l_size))))) ->
  ((valid_rd t a_8 1))

end

(* ---------------------------------------------------------- *)
(* --- Assertion 'rte,mem_access' (file c11.c, line 132)  --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_assert_rte_mem_access_7
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import Compound.Compound
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import A_schedule_cpumask.A_schedule_cpumask

(*
goal WP "expl:Assertion 'rte,mem_access' (file c11.c, line 132)":
*)
goal goal9:
  forall i : int.
  forall t : map int int.
  forall t_1 : map addr int.
  forall t_2 : map addr addr.
  forall a_1 a : addr.
  let a_2 = (shiftfield_f5_lb_env_idle a_1) in
  let a_3 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_4 = t_2[a_3] in
  let a_5 = t_2[(shiftfield_f1_cpumask_bits a_4)] in
  let a_6 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x = t_1[a_6] in
  let x_1 = t_1[(shift_uint8 a_5 x)] in
  let a_7 = (shiftfield_f5_lb_env_sd a_1) in
  let a_8 = t_2[(shiftfield_f5_lb_env_dst_rq a_1)] in
  let a_9 = t_2[a_7] in
  let a_10 = (shiftfield_f3_sched_domain_groups a_9) in
  let a_11 = (shift_uint8 a_5 0) in
  (t_1[a_2] = 2) ->
  (x_1 <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= x) ->
  (x < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_2)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((valid_rd t a_1 5)) ->
  ((is_sint32 x)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_6 1)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t a_7 1)) ->
  ((valid_rd t a_4 1)) ->
  ((valid_rd t a_8 2)) ->
  ((valid_rd t a_9 2)) ->
  ((is_sint32 t_1[(shiftfield_f3_sched_domain_flags a_9)])) ->
  ((valid_rd t a_10 1)) ->
  ((valid_rd t t_2[a_10] 1)) ->
  ((is_uint8 x_1)) ->
  ((valid_rd t a_11 l_size)) ->
  (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
   ((separated a_11 l_size
      ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))]
         0)) l_size))) ->
  (forall i_1 : int. let a_12 = (shift_cpumask a i_1) in (0 <= i_1) ->
   (i_1 < l_size) ->
   (((valid_rd t a_12 1)) /\
    ((valid_rw t ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_12)] 0))
       l_size)))) ->
  (forall a_12 : addr. let a_13 = (l_sched_group_cpus a_12) in
   let a_14 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_13)] 0) in
   ((valid_rd t a_13 1)) /\ ((valid_rd t a_14 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_14 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall a_12 : addr. let a_13 = (l_sched_group_mask a_12) in
   let a_14 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_13)] 0) in
   ((valid_rd t a_13 1)) /\ ((valid_rd t a_14 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_14 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall a_12 : addr. let a_13 = (l_group_balance_mask a_12) in
   let a_14 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_13)] 0) in
   ((valid_rd t a_13 1)) /\ ((valid_rd t a_14 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_14 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall i_1 : int. let a_12 = (l_cpu_smt_mask i_1) in
   let a_13 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_12)] 0) in
   (0 <= i_1) -> (i_1 < l_size) ->
   (((valid_rd t a_12 1)) /\ ((valid_rd t a_13 l_size)) /\
    (forall i_2 : int. (0 <= i_2) -> (i_2 < l_size) ->
     ((separated a_13 l_size
        ((shift_uint8
           t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_2)))] 0))
        l_size))))) ->
  ((valid_rd t ((shiftfield_f4_rq_nr_running a_8)) 1))

end

(* ---------------------------------------------------------- *)
(* --- Assertion 'rte,mem_access' (file c11.c, line 132)  --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_assert_rte_mem_access_9
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import Compound.Compound
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import A_schedule_cpumask.A_schedule_cpumask

(*
goal WP "expl:Assertion 'rte,mem_access' (file c11.c, line 132)":
*)
goal goal10:
  forall i : int.
  forall t : map int int.
  forall t_1 : map addr int.
  forall t_2 : map addr addr.
  forall a_1 a : addr.
  let a_2 = (shiftfield_f5_lb_env_idle a_1) in
  let a_3 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_4 = t_2[a_3] in
  let a_5 = t_2[(shiftfield_f1_cpumask_bits a_4)] in
  let a_6 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x = t_1[a_6] in
  let x_1 = t_1[(shift_uint8 a_5 x)] in
  let a_7 = (shiftfield_f5_lb_env_dst_rq a_1) in
  let a_8 = t_2[a_7] in
  let a_9 = (shiftfield_f4_rq_nr_running a_8) in
  let x_2 = t_1[a_9] in
  let a_10 = (shiftfield_f5_lb_env_sd a_1) in
  let a_11 = t_2[a_10] in
  let a_12 = (shiftfield_f4_rq_ttwu_pending a_8) in
  let a_13 = (shiftfield_f3_sched_domain_groups a_11) in
  let a_14 = (shift_uint8 a_5 0) in
  (t_1[a_2] = 2) ->
  (x_1 <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= x) ->
  (x < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  (x_2 <= 0) ->
  ((framed t_2)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((valid_rd t a_1 5)) ->
  ((is_sint32 x)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_6 1)) ->
  ((valid_rd t a_7 1)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t a_10 1)) ->
  ((valid_rd t a_4 1)) ->
  ((valid_rd t a_8 2)) ->
  ((valid_rd t a_11 2)) ->
  ((is_uint32 x_2)) ->
  ((is_uint32 t_1[a_12])) ->
  ((is_sint32 t_1[(shiftfield_f3_sched_domain_flags a_11)])) ->
  ((valid_rd t a_13 1)) ->
  ((valid_rd t a_9 1)) ->
  ((valid_rd t t_2[a_13] 1)) ->
  ((is_uint8 x_1)) ->
  ((valid_rd t a_14 l_size)) ->
  (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
   ((separated a_14 l_size
      ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))]
         0)) l_size))) ->
  (forall i_1 : int. let a_15 = (shift_cpumask a i_1) in (0 <= i_1) ->
   (i_1 < l_size) ->
   (((valid_rd t a_15 1)) /\
    ((valid_rw t ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_15)] 0))
       l_size)))) ->
  (forall a_15 : addr. let a_16 = (l_sched_group_cpus a_15) in
   let a_17 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_16)] 0) in
   ((valid_rd t a_16 1)) /\ ((valid_rd t a_17 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_17 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall a_15 : addr. let a_16 = (l_sched_group_mask a_15) in
   let a_17 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_16)] 0) in
   ((valid_rd t a_16 1)) /\ ((valid_rd t a_17 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_17 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall a_15 : addr. let a_16 = (l_group_balance_mask a_15) in
   let a_17 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_16)] 0) in
   ((valid_rd t a_16 1)) /\ ((valid_rd t a_17 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_17 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall i_1 : int. let a_15 = (l_cpu_smt_mask i_1) in
   let a_16 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_15)] 0) in
   (0 <= i_1) -> (i_1 < l_size) ->
   (((valid_rd t a_15 1)) /\ ((valid_rd t a_16 l_size)) /\
    (forall i_2 : int. (0 <= i_2) -> (i_2 < l_size) ->
     ((separated a_16 l_size
        ((shift_uint8
           t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_2)))] 0))
        l_size))))) ->
  ((valid_rd t a_12 1))

end

(* ---------------------------------------------------------- *)
(* --- Preservation of Invariant (file c11.c, line 140)   --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_loop_inv_preserved
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import A_schedule_cpumask.A_schedule_cpumask
use import Compound.Compound
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import Cbits.Cbits

(*
goal WP "expl:Preservation of Invariant (file c11.c, line 140)":
*)
goal goal11:
  forall p : bool.
  forall i_4 i_3 i_2 i_1 i : int.
  forall t : map int int.
  forall t_4 t_3 t_2 t_1 : map addr int.
  forall t_5 : map addr addr.
  forall a_2 a_1 a : addr.
  let x = (l_idle_cpu i_3) in
  let a_3 = (shiftfield_f5_lb_env_idle a_1) in
  let x_1 = t_3[a_3] in
  let a_4 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_5 = t_5[a_4] in
  let a_6 = (shiftfield_f1_cpumask_bits a_5) in
  let a_7 = t_5[a_6] in
  let a_8 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x_2 = t_3[a_8] in
  let x_3 = t_3[(shift_uint8 a_7 x_2)] in
  let a_9 = (shiftfield_f5_lb_env_sd a_1) in
  let a_10 = (shift_cpumask a i) in
  let a_11 = t_5[a_9] in
  let a_12 = (shiftfield_f3_sched_domain_flags a_11) in
  let a_13 = (shiftfield_f5_lb_env_sd a_2) in
  let a_14 = (shiftfield_f3_sched_domain_flags t_5[a_13]) in
  let x_4 = t_4[a_14] in
  let a_15 = (shiftfield_f1_cpumask_bits a_10) in
  let a_16 = (shiftfield_f3_sched_domain_groups a_11) in
  let a_17 = t_5[a_16] in
  let a_18 = (l_group_balance_mask a_17) in
  let a_19 = t_5[a_15] in
  let a_20 = (shift_uint8 a_19 0) in
  let a_21 = (shift_uint8 a_7 0) in
  let a_22 = (havoc t_1 t_3 a_20 l_size) in
  let a_23 = t_5[(shiftfield_f1_cpumask_bits a_18)] in
  let a_24 = (havoc t_2 t_3 a_20 l_size) in
  let a_25 = a_24[(shift_uint8 a_19 i_3)] in
  let a_26 = a_24[(shift_uint8 a_7 i_1)] in
  let a_27 = a_24[(shift_uint8 a_7 i_3)] in
  let a_28 = a_24[(shift_uint8 a_23 i_1)] in
  let a_29 = a_24[a_12] in
  let a_30 = (shift_uint8 a_23 0) in
  let x_5 = (to_uint32 i_4) in
  ((x <> 0) <-> (i_2 <> 0)) ->
  (x_1 <> 2) ->
  (x_3 <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= i_3) ->
  (i_3 < l_size) ->
  (0 <= i_4) ->
  (i_4 <= l_size) ->
  (((to_uint32 i_3)) < l_size) ->
  (0 <= x_2) ->
  (x_2 < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_5)) ->
  ((linked t)) ->
  ((is_uint8 i_2)) ->
  ((is_uint32 i)) ->
  ((is_sint32 i_1)) ->
  ((is_sint32 i_3)) ->
  ((is_sint32 i_4)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 x_1)) ->
  ((is_sint32 (1 + i_3))) ->
  ((is_sint32 x_2)) ->
  ((valid_rd t a_4 1)) ->
  ((valid_rd t a_8 1)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_9 1)) ->
  ((valid_rd t a_10 1)) ->
  ((valid_rd t a_5 1)) ->
  ((valid_rd t t_5[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_11 2)) ->
  ((is_sint32 t_3[a_12])) ->
  ((is_sint32 x_4)) ->
  ((valid_rd t a_15 1)) ->
  ((valid_rd t a_6 1)) ->
  ((valid_rd t a_16 1)) ->
  ((valid_rd t a_17 1)) ->
  ((valid_rd t a_18 1)) ->
  ((is_uint8 x_3)) ->
  ((valid_rd t a_20 l_size)) ->
  ((valid_rd t a_21 l_size)) ->
  ((valid_rw t a_20 l_size)) ->
  ((is_uint8 a_22[(shift_uint8 a_7 (-1))])) ->
  ((is_uint8 a_22[(shift_uint8 a_23 (-1))])) ->
  ((is_uint8 a_25)) ->
  ((is_uint8 a_26)) ->
  ((is_uint8 a_27)) ->
  ((is_uint8 a_28)) ->
  ((is_sint32 a_22[a_12])) ->
  ((is_sint32 a_29)) ->
  ((valid_rd t a_30 l_size)) ->
  ((separated a_20 l_size a_30 l_size)) ->
  (if (i_2 = 0) then (i_3 <= 2147483646)
   else ((p=False) /\ (a_2 = a_1) /\ (x <> 0) /\ (((land 7 x_4)) = 0) /\
         (a_24 = t_4) /\ (i_3 <= 2147483646) /\
         (not (p_idle_core t_5 t_4 i_3)) /\ ((valid_rd t a_13 1)) /\
         ((valid_rd t a_14 1)))) ->
  ((((land 7 a_29)) <> 0) -> (i_1 = (-1))) ->
  ((i_1 <> (-1)) ->
   ((((l_idle_cpu i_1)) <> 0) /\ (a_26 <> 0) /\ (a_28 <> 0) /\ (0 <= i_1) /\
    (i_1 < l_size))) ->
  ((i_1 = (-1)) ->
   (forall i_5 : int. (a_24[(shift_uint8 a_23 i_5)] <> 0) -> (0 <= i_5) ->
    (i_5 < l_size) -> (a_24[(shift_uint8 a_19 i_5)] <> 0))) ->
  ((exists i_5 : int. (a_24[(shift_uint8 a_19 i_5)] <> 0) /\
    (a_24[(shift_uint8 a_7 i_5)] <> 0) /\ (i_5 < l_size) /\ (x_5 <= i_5)) ->
   (x_5 <= i_3)) ->
  ((exists i_5 : int. (a_24[(shift_uint8 a_19 i_5)] <> 0) /\
    (a_24[(shift_uint8 a_7 i_5)] <> 0) /\ (i_5 < l_size) /\ (x_5 <= i_5)) ->
   ((a_25 <> 0) /\ (a_27 <> 0))) ->
  ((forall i_5 : int. (i_5 < l_size) -> (x_5 <= i_5) ->
    ((a_24[(shift_uint8 a_19 i_5)] = 0) \/ (a_24[(shift_uint8 a_7 i_5)] = 0))) ->
   (l_size = i_3)) ->
  ((i_1 <> (-1)) ->
   (forall i_5 : int. (a_24[(shift_uint8 a_7 i_5)] <> 0) ->
    (a_24[(shift_uint8 a_23 i_5)] <> 0) -> (0 <= i_5) -> (i_5 < i_1) ->
    (i_5 < l_size) -> (((l_idle_cpu i_5)) = 0))) ->
  ((i_1 = (-1)) ->
   (forall i_5 : int. (a_24[(shift_uint8 a_7 i_5)] <> 0) ->
    (a_24[(shift_uint8 a_23 i_5)] <> 0) -> (0 <= i_5) -> (i_5 < i_4) ->
    (i_5 < l_size) -> (((l_idle_cpu i_5)) = 0))) ->
  ((exists i_5 : int. (a_24[(shift_uint8 a_19 i_5)] <> 0) /\
    (a_24[(shift_uint8 a_7 i_5)] <> 0) /\ (i_5 < l_size) /\ (x_5 <= i_5)) ->
   (forall i_5 : int. (i_5 < i_3) -> (x_5 <= i_5) ->
    ((a_24[(shift_uint8 a_19 i_5)] = 0) \/ (a_24[(shift_uint8 a_7 i_5)] = 0)))) ->
  ((i_1 <> (-1)) ->
   (forall i_5 : int. (a_24[(shift_uint8 a_7 i_5)] <> 0) ->
    (a_24[(shift_uint8 a_23 i_5)] <> 0) -> (0 <= i_5) -> (i_1 <= i_5) ->
    (i_5 < i_4) -> (i_5 < l_size) -> (not (p_idle_core t_5 a_24 i_5)))) ->
  ((i_1 <> (-1)) ->
   (forall i_5 : int. (a_24[(shift_uint8 a_23 i_5)] <> 0) -> (0 <= i_5) ->
    (i_5 < l_size) ->
    ((a_24[(shift_uint8 a_19 i_5)] <> 0) \/ (not (p_idle_core t_5 a_24 i_5))))) ->
  ((i_2 = 0) \/ (i_2 = 1)) ->
  (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
   ((separated a_21 l_size
      ((shift_uint8 t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_5)))]
         0)) l_size))) ->
  (forall i_5 : int. let a_31 = (shift_cpumask a i_5) in (0 <= i_5) ->
   (i_5 < l_size) ->
   (((valid_rd t a_31 1)) /\
    ((valid_rw t ((shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_31)] 0))
       l_size)))) ->
  (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
   ((a_22[(shift_uint8 a_23 i_5)] <> 0) <->
    (a_22[(shift_uint8 a_19 i_5)] <> 0))) ->
  (forall i_5 : int. (a_24[(shift_uint8 a_19 i_5)] <> 0) -> (0 <= i_5) ->
   (i_5 < l_size) -> (a_24[(shift_uint8 a_23 i_5)] <> 0)) ->
  (forall a_31 : addr. let a_32 = (l_sched_group_cpus a_31) in
   let a_33 = (shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_32)] 0) in
   ((valid_rd t a_32 1)) /\ ((valid_rd t a_33 l_size)) /\
   (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
    ((separated a_33 l_size
       ((shift_uint8
          t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_5)))] 0))
       l_size)))) ->
  (forall a_31 : addr. let a_32 = (l_sched_group_mask a_31) in
   let a_33 = (shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_32)] 0) in
   ((valid_rd t a_32 1)) /\ ((valid_rd t a_33 l_size)) /\
   (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
    ((separated a_33 l_size
       ((shift_uint8
          t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_5)))] 0))
       l_size)))) ->
  (forall a_31 : addr. let a_32 = (l_group_balance_mask a_31) in
   let a_33 = (shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_32)] 0) in
   ((valid_rd t a_32 1)) /\ ((valid_rd t a_33 l_size)) /\
   (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
    ((separated a_33 l_size
       ((shift_uint8
          t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_5)))] 0))
       l_size)))) ->
  (forall i_5 : int. let a_31 = (l_cpu_smt_mask i_5) in
   let a_32 = (shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_31)] 0) in
   (0 <= i_5) -> (i_5 < l_size) ->
   (((valid_rd t a_31 1)) /\ ((valid_rd t a_32 l_size)) /\
    (forall i_6 : int. (0 <= i_6) -> (i_6 < l_size) ->
     ((separated a_32 l_size
        ((shift_uint8
           t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_6)))] 0))
        l_size))))) ->
  ((-1) <= i_3)

end

(* ---------------------------------------------------------- *)
(* --- Establishment of Invariant (file c11.c, line 140)  --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_loop_inv_established
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import Compound.Compound
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import A_schedule_cpumask.A_schedule_cpumask

(*
goal WP "expl:Establishment of Invariant (file c11.c, line 140)":
*)
goal goal12:
  forall i : int.
  forall t : map int int.
  forall t_2 t_1 : map addr int.
  forall t_3 : map addr addr.
  forall a_1 a : addr.
  let a_2 = (shiftfield_f5_lb_env_idle a_1) in
  let x = t_2[a_2] in
  let a_3 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_4 = t_3[a_3] in
  let a_5 = t_3[(shiftfield_f1_cpumask_bits a_4)] in
  let a_6 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x_1 = t_2[a_6] in
  let x_2 = t_2[(shift_uint8 a_5 x_1)] in
  let a_7 = (shiftfield_f5_lb_env_sd a_1) in
  let a_8 = (shift_cpumask a i) in
  let a_9 = t_3[a_7] in
  let a_10 = (shiftfield_f3_sched_domain_groups a_9) in
  let a_11 = t_3[a_10] in
  let a_12 = (l_group_balance_mask a_11) in
  let a_13 = (shift_uint8 a_5 0) in
  let a_14 = t_3[(shiftfield_f1_cpumask_bits a_8)] in
  let a_15 = (shift_uint8 a_14 0) in
  let a_16 = t_3[(shiftfield_f1_cpumask_bits a_12)] in
  let a_17 = (shift_uint8 a_16 0) in
  let a_18 = (havoc t_1 t_2 a_15 l_size) in
  (x <> 2) ->
  (x_2 <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= x_1) ->
  (x_1 < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_3)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 x)) ->
  ((is_sint32 x_1)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_6 1)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t a_7 1)) ->
  ((valid_rd t a_8 1)) ->
  ((valid_rd t a_4 1)) ->
  ((valid_rd t t_3[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_9 2)) ->
  ((is_sint32 t_2[(shiftfield_f3_sched_domain_flags a_9)])) ->
  ((valid_rd t a_10 1)) ->
  ((valid_rd t a_11 1)) ->
  ((valid_rd t a_12 1)) ->
  ((is_uint8 x_2)) ->
  ((valid_rd t a_13 l_size)) ->
  ((valid_rw t a_15 l_size)) ->
  ((valid_rd t a_17 l_size)) ->
  ((separated a_15 l_size a_17 l_size)) ->
  (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
   ((separated a_13 l_size
      ((shift_uint8 t_3[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))]
         0)) l_size))) ->
  (forall i_1 : int. let a_19 = (shift_cpumask a i_1) in (0 <= i_1) ->
   (i_1 < l_size) ->
   (((valid_rd t a_19 1)) /\
    ((valid_rw t ((shift_uint8 t_3[(shiftfield_f1_cpumask_bits a_19)] 0))
       l_size)))) ->
  (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
   ((a_18[(shift_uint8 a_16 i_1)] <> 0) <->
    (a_18[(shift_uint8 a_14 i_1)] <> 0))) ->
  (forall a_19 : addr. let a_20 = (l_sched_group_cpus a_19) in
   let a_21 = (shift_uint8 t_3[(shiftfield_f1_cpumask_bits a_20)] 0) in
   ((valid_rd t a_20 1)) /\ ((valid_rd t a_21 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_21 l_size
       ((shift_uint8
          t_3[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall a_19 : addr. let a_20 = (l_sched_group_mask a_19) in
   let a_21 = (shift_uint8 t_3[(shiftfield_f1_cpumask_bits a_20)] 0) in
   ((valid_rd t a_20 1)) /\ ((valid_rd t a_21 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_21 l_size
       ((shift_uint8
          t_3[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall a_19 : addr. let a_20 = (l_group_balance_mask a_19) in
   let a_21 = (shift_uint8 t_3[(shiftfield_f1_cpumask_bits a_20)] 0) in
   ((valid_rd t a_20 1)) /\ ((valid_rd t a_21 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_21 l_size
       ((shift_uint8
          t_3[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall i_1 : int. let a_19 = (l_cpu_smt_mask i_1) in
   let a_20 = (shift_uint8 t_3[(shiftfield_f1_cpumask_bits a_19)] 0) in
   (0 <= i_1) -> (i_1 < l_size) ->
   (((valid_rd t a_19 1)) /\ ((valid_rd t a_20 l_size)) /\
    (forall i_2 : int. (0 <= i_2) -> (i_2 < l_size) ->
     ((separated a_20 l_size
        ((shift_uint8
           t_3[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_2)))] 0))
        l_size))))) ->
  (0 <= l_size)

end

(* ---------------------------------------------------------- *)
(* --- Preservation of Invariant 'a1' (file c11.c, line 142) --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_loop_inv_a1_preserved
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import A_schedule_cpumask.A_schedule_cpumask
use import Compound.Compound
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import Cbits.Cbits

(*
goal WP "expl:Preservation of Invariant 'a1' (file c11.c, line 142)":
*)
goal goal13:
  forall p : bool.
  forall i_5 i_4 i_3 i_2 i_1 i : int.
  forall t : map int int.
  forall t_4 t_3 t_2 t_1 : map addr int.
  forall t_5 : map addr addr.
  forall a_1 a : addr.
  let x = (l_idle_cpu i_4) in
  let a_2 = (shiftfield_f5_lb_env_idle a_1) in
  let x_1 = t_3[a_2] in
  let a_3 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_4 = t_5[a_3] in
  let a_5 = (shiftfield_f1_cpumask_bits a_4) in
  let a_6 = t_5[a_5] in
  let a_7 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x_2 = t_3[a_7] in
  let x_3 = t_3[(shift_uint8 a_6 x_2)] in
  let a_8 = (shift_cpumask a i) in
  let a_9 = (shiftfield_f1_cpumask_bits a_8) in
  let a_10 = t_5[a_9] in
  let a_11 = (shift_uint8 a_10 0) in
  let a_12 = (havoc t_2 t_3 a_11 l_size) in
  let a_13 = (shiftfield_f5_lb_env_sd a_1) in
  let a_14 = t_5[a_13] in
  let a_15 = (shiftfield_f3_sched_domain_flags a_14) in
  let a_16 = (shiftfield_f3_sched_domain_groups a_14) in
  let a_17 = t_5[a_16] in
  let a_18 = (l_group_balance_mask a_17) in
  let a_19 = (shift_uint8 a_6 0) in
  let a_20 = (havoc t_1 t_3 a_11 l_size) in
  let a_21 = t_5[(shiftfield_f1_cpumask_bits a_18)] in
  let a_22 = a_12[(shift_uint8 a_10 i_4)] in
  let a_23 = a_12[(shift_uint8 a_6 i_1)] in
  let a_24 = a_12[(shift_uint8 a_6 i_4)] in
  let a_25 = a_12[(shift_uint8 a_21 i_1)] in
  let a_26 = a_12[a_15] in
  let a_27 = (shift_uint8 a_21 0) in
  let x_4 = (to_uint32 i_5) in
  ((x <> 0) <-> (i_2 <> 0)) ->
  (x_1 <> 2) ->
  (x_3 <> 0) ->
  (a_12[(shift_uint8 a_10 i_3)] <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= i_3) ->
  (i_3 < l_size) ->
  (0 <= i_4) ->
  (i_4 < l_size) ->
  (0 <= i_5) ->
  (i_5 <= l_size) ->
  (((to_uint32 i_4)) < l_size) ->
  (0 <= x_2) ->
  (x_2 < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_5)) ->
  ((linked t)) ->
  ((is_uint8 i_2)) ->
  ((is_uint32 i)) ->
  ((is_sint32 i_1)) ->
  ((is_sint32 i_4)) ->
  ((is_sint32 i_5)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 x_1)) ->
  ((is_sint32 x_2)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_7 1)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t a_13 1)) ->
  ((valid_rd t a_8 1)) ->
  ((valid_rd t a_4 1)) ->
  ((valid_rd t t_5[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_14 2)) ->
  ((is_sint32 t_3[a_15])) ->
  ((valid_rd t a_9 1)) ->
  ((valid_rd t a_5 1)) ->
  ((valid_rd t a_16 1)) ->
  ((valid_rd t a_17 1)) ->
  ((valid_rd t a_18 1)) ->
  ((is_uint8 x_3)) ->
  ((valid_rd t a_11 l_size)) ->
  ((valid_rd t a_19 l_size)) ->
  ((valid_rw t a_11 l_size)) ->
  ((is_uint8 a_20[(shift_uint8 a_6 (-1))])) ->
  ((is_uint8 a_20[(shift_uint8 a_21 (-1))])) ->
  ((is_uint8 a_22)) ->
  ((is_uint8 a_23)) ->
  ((is_uint8 a_24)) ->
  ((is_uint8 a_25)) ->
  ((is_sint32 a_20[a_15])) ->
  ((is_sint32 a_26)) ->
  ((valid_rd t a_27 l_size)) ->
  ((separated a_11 l_size a_27 l_size)) ->
  (if (i_2 = 0) then (i_4 <= 2147483646)
   else ((p=False) /\ (x <> 0) /\ (((land 7 t_4[a_15])) = 0) /\
         (a_12 = t_4) /\ (i_4 <= 2147483646) /\
         (not (p_idle_core t_5 t_4 i_4)) /\ ((valid_rd t a_15 1)))) ->
  ((((land 7 a_26)) <> 0) -> (i_1 = (-1))) ->
  ((i_1 <> (-1)) ->
   ((((l_idle_cpu i_1)) <> 0) /\ (a_23 <> 0) /\ (a_25 <> 0) /\ (0 <= i_1) /\
    (i_1 < l_size))) ->
  ((i_1 = (-1)) ->
   (forall i_6 : int. (a_12[(shift_uint8 a_21 i_6)] <> 0) -> (0 <= i_6) ->
    (i_6 < l_size) -> (a_12[(shift_uint8 a_10 i_6)] <> 0))) ->
  ((exists i_6 : int. (a_12[(shift_uint8 a_10 i_6)] <> 0) /\
    (a_12[(shift_uint8 a_6 i_6)] <> 0) /\ (i_6 < l_size) /\ (x_4 <= i_6)) ->
   (x_4 <= i_4)) ->
  ((exists i_6 : int. (a_12[(shift_uint8 a_10 i_6)] <> 0) /\
    (a_12[(shift_uint8 a_6 i_6)] <> 0) /\ (i_6 < l_size) /\ (x_4 <= i_6)) ->
   ((a_22 <> 0) /\ (a_24 <> 0))) ->
  ((forall i_6 : int. (i_6 < l_size) -> (x_4 <= i_6) ->
    ((a_12[(shift_uint8 a_10 i_6)] = 0) \/ (a_12[(shift_uint8 a_6 i_6)] = 0))) ->
   (l_size = i_4)) ->
  ((i_1 <> (-1)) ->
   (forall i_6 : int. (a_12[(shift_uint8 a_6 i_6)] <> 0) ->
    (a_12[(shift_uint8 a_21 i_6)] <> 0) -> (0 <= i_6) -> (i_6 < i_1) ->
    (i_6 < l_size) -> (((l_idle_cpu i_6)) = 0))) ->
  ((i_1 = (-1)) ->
   (forall i_6 : int. (a_12[(shift_uint8 a_6 i_6)] <> 0) ->
    (a_12[(shift_uint8 a_21 i_6)] <> 0) -> (0 <= i_6) -> (i_6 < i_5) ->
    (i_6 < l_size) -> (((l_idle_cpu i_6)) = 0))) ->
  ((exists i_6 : int. (a_12[(shift_uint8 a_10 i_6)] <> 0) /\
    (a_12[(shift_uint8 a_6 i_6)] <> 0) /\ (i_6 < l_size) /\ (x_4 <= i_6)) ->
   (forall i_6 : int. (i_6 < i_4) -> (x_4 <= i_6) ->
    ((a_12[(shift_uint8 a_10 i_6)] = 0) \/ (a_12[(shift_uint8 a_6 i_6)] = 0)))) ->
  ((i_1 <> (-1)) ->
   (forall i_6 : int. (a_12[(shift_uint8 a_6 i_6)] <> 0) ->
    (a_12[(shift_uint8 a_21 i_6)] <> 0) -> (0 <= i_6) -> (i_1 <= i_6) ->
    (i_6 < i_5) -> (i_6 < l_size) -> (not (p_idle_core t_5 a_12 i_6)))) ->
  ((i_1 <> (-1)) ->
   (forall i_6 : int. (a_12[(shift_uint8 a_21 i_6)] <> 0) -> (0 <= i_6) ->
    (i_6 < l_size) ->
    ((a_12[(shift_uint8 a_10 i_6)] <> 0) \/ (not (p_idle_core t_5 a_12 i_6))))) ->
  ((i_2 = 0) \/ (i_2 = 1)) ->
  (forall i_6 : int. (0 <= i_6) -> (i_6 < l_size) ->
   ((separated a_19 l_size
      ((shift_uint8 t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_6)))]
         0)) l_size))) ->
  (forall i_6 : int. let a_28 = (shift_cpumask a i_6) in (0 <= i_6) ->
   (i_6 < l_size) ->
   (((valid_rd t a_28 1)) /\
    ((valid_rw t ((shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_28)] 0))
       l_size)))) ->
  (forall i_6 : int. (0 <= i_6) -> (i_6 < l_size) ->
   ((a_20[(shift_uint8 a_21 i_6)] <> 0) <->
    (a_20[(shift_uint8 a_10 i_6)] <> 0))) ->
  (forall i_6 : int. (a_12[(shift_uint8 a_10 i_6)] <> 0) -> (0 <= i_6) ->
   (i_6 < l_size) -> (a_12[(shift_uint8 a_21 i_6)] <> 0)) ->
  (forall a_28 : addr. let a_29 = (l_sched_group_cpus a_28) in
   let a_30 = (shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_29)] 0) in
   ((valid_rd t a_29 1)) /\ ((valid_rd t a_30 l_size)) /\
   (forall i_6 : int. (0 <= i_6) -> (i_6 < l_size) ->
    ((separated a_30 l_size
       ((shift_uint8
          t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_6)))] 0))
       l_size)))) ->
  (forall a_28 : addr. let a_29 = (l_sched_group_mask a_28) in
   let a_30 = (shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_29)] 0) in
   ((valid_rd t a_29 1)) /\ ((valid_rd t a_30 l_size)) /\
   (forall i_6 : int. (0 <= i_6) -> (i_6 < l_size) ->
    ((separated a_30 l_size
       ((shift_uint8
          t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_6)))] 0))
       l_size)))) ->
  (forall a_28 : addr. let a_29 = (l_group_balance_mask a_28) in
   let a_30 = (shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_29)] 0) in
   ((valid_rd t a_29 1)) /\ ((valid_rd t a_30 l_size)) /\
   (forall i_6 : int. (0 <= i_6) -> (i_6 < l_size) ->
    ((separated a_30 l_size
       ((shift_uint8
          t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_6)))] 0))
       l_size)))) ->
  (forall i_6 : int. let a_28 = (l_cpu_smt_mask i_6) in
   let a_29 = (shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_28)] 0) in
   (0 <= i_6) -> (i_6 < l_size) ->
   (((valid_rd t a_28 1)) /\ ((valid_rd t a_29 l_size)) /\
    (forall i_7 : int. (0 <= i_7) -> (i_7 < l_size) ->
     ((separated a_29 l_size
        ((shift_uint8
           t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_7)))] 0))
        l_size))))) ->
  (a_12[(shift_uint8 a_21 i_3)] <> 0)

end

(* ---------------------------------------------------------- *)
(* --- Establishment of Invariant 'a1' (file c11.c, line 142) --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_loop_inv_a1_established
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import Compound.Compound
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import A_schedule_cpumask.A_schedule_cpumask

(*
goal WP "expl:Establishment of Invariant 'a1' (file c11.c, line 142)":
*)
goal goal14:
  forall i_1 i : int.
  forall t : map int int.
  forall t_2 t_1 : map addr int.
  forall t_3 : map addr addr.
  forall a_1 a : addr.
  let a_2 = (shiftfield_f5_lb_env_idle a_1) in
  let x = t_2[a_2] in
  let a_3 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_4 = t_3[a_3] in
  let a_5 = t_3[(shiftfield_f1_cpumask_bits a_4)] in
  let a_6 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x_1 = t_2[a_6] in
  let x_2 = t_2[(shift_uint8 a_5 x_1)] in
  let a_7 = (shift_cpumask a i) in
  let a_8 = t_3[(shiftfield_f1_cpumask_bits a_7)] in
  let a_9 = (shift_uint8 a_8 0) in
  let a_10 = (havoc t_1 t_2 a_9 l_size) in
  let a_11 = (shiftfield_f5_lb_env_sd a_1) in
  let a_12 = t_3[a_11] in
  let a_13 = (shiftfield_f3_sched_domain_groups a_12) in
  let a_14 = t_3[a_13] in
  let a_15 = (l_group_balance_mask a_14) in
  let a_16 = (shift_uint8 a_5 0) in
  let a_17 = t_3[(shiftfield_f1_cpumask_bits a_15)] in
  let a_18 = (shift_uint8 a_17 0) in
  (x <> 2) ->
  (x_2 <> 0) ->
  (a_10[(shift_uint8 a_8 i_1)] <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= i_1) ->
  (i_1 < l_size) ->
  (0 <= x_1) ->
  (x_1 < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_3)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 x)) ->
  ((is_sint32 x_1)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_6 1)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t a_11 1)) ->
  ((valid_rd t a_7 1)) ->
  ((valid_rd t a_4 1)) ->
  ((valid_rd t t_3[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_12 2)) ->
  ((is_sint32 t_2[(shiftfield_f3_sched_domain_flags a_12)])) ->
  ((valid_rd t a_13 1)) ->
  ((valid_rd t a_14 1)) ->
  ((valid_rd t a_15 1)) ->
  ((is_uint8 x_2)) ->
  ((valid_rd t a_16 l_size)) ->
  ((valid_rw t a_9 l_size)) ->
  ((valid_rd t a_18 l_size)) ->
  ((separated a_9 l_size a_18 l_size)) ->
  (forall i_2 : int. (0 <= i_2) -> (i_2 < l_size) ->
   ((separated a_16 l_size
      ((shift_uint8 t_3[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_2)))]
         0)) l_size))) ->
  (forall i_2 : int. let a_19 = (shift_cpumask a i_2) in (0 <= i_2) ->
   (i_2 < l_size) ->
   (((valid_rd t a_19 1)) /\
    ((valid_rw t ((shift_uint8 t_3[(shiftfield_f1_cpumask_bits a_19)] 0))
       l_size)))) ->
  (forall i_2 : int. (0 <= i_2) -> (i_2 < l_size) ->
   ((a_10[(shift_uint8 a_17 i_2)] <> 0) <->
    (a_10[(shift_uint8 a_8 i_2)] <> 0))) ->
  (forall a_19 : addr. let a_20 = (l_sched_group_cpus a_19) in
   let a_21 = (shift_uint8 t_3[(shiftfield_f1_cpumask_bits a_20)] 0) in
   ((valid_rd t a_20 1)) /\ ((valid_rd t a_21 l_size)) /\
   (forall i_2 : int. (0 <= i_2) -> (i_2 < l_size) ->
    ((separated a_21 l_size
       ((shift_uint8
          t_3[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_2)))] 0))
       l_size)))) ->
  (forall a_19 : addr. let a_20 = (l_sched_group_mask a_19) in
   let a_21 = (shift_uint8 t_3[(shiftfield_f1_cpumask_bits a_20)] 0) in
   ((valid_rd t a_20 1)) /\ ((valid_rd t a_21 l_size)) /\
   (forall i_2 : int. (0 <= i_2) -> (i_2 < l_size) ->
    ((separated a_21 l_size
       ((shift_uint8
          t_3[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_2)))] 0))
       l_size)))) ->
  (forall a_19 : addr. let a_20 = (l_group_balance_mask a_19) in
   let a_21 = (shift_uint8 t_3[(shiftfield_f1_cpumask_bits a_20)] 0) in
   ((valid_rd t a_20 1)) /\ ((valid_rd t a_21 l_size)) /\
   (forall i_2 : int. (0 <= i_2) -> (i_2 < l_size) ->
    ((separated a_21 l_size
       ((shift_uint8
          t_3[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_2)))] 0))
       l_size)))) ->
  (forall i_2 : int. let a_19 = (l_cpu_smt_mask i_2) in
   let a_20 = (shift_uint8 t_3[(shiftfield_f1_cpumask_bits a_19)] 0) in
   (0 <= i_2) -> (i_2 < l_size) ->
   (((valid_rd t a_19 1)) /\ ((valid_rd t a_20 l_size)) /\
    (forall i_3 : int. (0 <= i_3) -> (i_3 < l_size) ->
     ((separated a_20 l_size
        ((shift_uint8
           t_3[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_3)))] 0))
        l_size))))) ->
  (a_10[(shift_uint8 a_17 i_1)] <> 0)

end

(* ---------------------------------------------------------- *)
(* --- Preservation of Invariant 'a2' (file c11.c, line 143) --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_loop_inv_a2_preserved
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import A_schedule_cpumask.A_schedule_cpumask
use import Compound.Compound
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint

(*
goal WP "expl:Preservation of Invariant 'a2' (file c11.c, line 143)":
*)
goal goal15:
  forall i_3 i_2 i_1 i : int.
  forall t : map int int.
  forall t_3 t_2 t_1 : map addr int.
  forall t_4 : map addr addr.
  forall a_1 a : addr.
  let a_2 = (shiftfield_f5_lb_env_idle a_1) in
  let x = t_3[a_2] in
  let a_3 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_4 = t_4[a_3] in
  let a_5 = (shiftfield_f1_cpumask_bits a_4) in
  let a_6 = t_4[a_5] in
  let a_7 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x_1 = t_3[a_7] in
  let x_2 = t_3[(shift_uint8 a_6 x_1)] in
  let a_8 = (shift_cpumask a i) in
  let a_9 = (shiftfield_f1_cpumask_bits a_8) in
  let a_10 = t_4[a_9] in
  let a_11 = (shift_uint8 a_10 0) in
  let a_12 = (havoc t_2 t_3 a_11 l_size) in
  let a_13 = (shiftfield_f5_lb_env_sd a_1) in
  let a_14 = t_4[a_13] in
  let a_15 = (shiftfield_f3_sched_domain_groups a_14) in
  let a_16 = t_4[a_15] in
  let a_17 = (l_group_balance_mask a_16) in
  let a_18 = t_4[(shiftfield_f1_cpumask_bits a_17)] in
  let a_19 = (shiftfield_f3_sched_domain_flags a_14) in
  let a_20 = (shift_uint8 a_6 0) in
  let a_21 = (havoc t_1 t_3 a_11 l_size) in
  let a_22 = (shift_uint8 a_6 (-1)) in
  let a_23 = (shift_uint8 a_18 (-1)) in
  let a_24 = a_12[(shift_uint8 a_10 i_2)] in
  let a_25 = a_12[(shift_uint8 a_6 i_2)] in
  let a_26 = (shift_uint8 a_18 0) in
  let x_3 = (to_uint32 i_3) in
  (((l_idle_cpu i_2)) = 0) ->
  (x <> 2) ->
  (x_2 <> 0) ->
  (a_12[(shift_uint8 a_18 i_1)] <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= i_1) ->
  (i_1 < l_size) ->
  (0 <= i_2) ->
  (i_2 < l_size) ->
  (0 <= i_3) ->
  (i_3 <= l_size) ->
  (((to_uint32 i_2)) < l_size) ->
  (0 <= x_1) ->
  (x_1 < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  (i_2 <= 2147483646) ->
  ((framed t_4)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((is_sint32 i_2)) ->
  ((is_sint32 i_3)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 x)) ->
  ((is_sint32 x_1)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_7 1)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t a_13 1)) ->
  ((valid_rd t a_8 1)) ->
  ((valid_rd t a_4 1)) ->
  ((valid_rd t t_4[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_14 2)) ->
  ((is_sint32 t_3[a_19])) ->
  ((valid_rd t a_9 1)) ->
  ((valid_rd t a_5 1)) ->
  ((valid_rd t a_15 1)) ->
  ((valid_rd t a_16 1)) ->
  ((valid_rd t a_17 1)) ->
  ((is_uint8 x_2)) ->
  ((valid_rd t a_11 l_size)) ->
  ((valid_rd t a_20 l_size)) ->
  ((valid_rw t a_11 l_size)) ->
  ((is_uint8 a_21[a_22])) ->
  ((is_uint8 a_21[a_23])) ->
  ((is_uint8 a_24)) ->
  ((is_uint8 a_12[a_22])) ->
  ((is_uint8 a_25)) ->
  ((is_uint8 a_12[a_23])) ->
  ((is_sint32 a_21[a_19])) ->
  ((is_sint32 a_12[a_19])) ->
  ((valid_rd t a_26 l_size)) ->
  ((separated a_11 l_size a_26 l_size)) ->
  ((exists i_4 : int. (a_12[(shift_uint8 a_10 i_4)] <> 0) /\
    (a_12[(shift_uint8 a_6 i_4)] <> 0) /\ (i_4 < l_size) /\ (x_3 <= i_4)) ->
   (x_3 <= i_2)) ->
  ((exists i_4 : int. (a_12[(shift_uint8 a_10 i_4)] <> 0) /\
    (a_12[(shift_uint8 a_6 i_4)] <> 0) /\ (i_4 < l_size) /\ (x_3 <= i_4)) ->
   ((a_24 <> 0) /\ (a_25 <> 0))) ->
  ((forall i_4 : int. (i_4 < l_size) -> (x_3 <= i_4) ->
    ((a_12[(shift_uint8 a_10 i_4)] = 0) \/ (a_12[(shift_uint8 a_6 i_4)] = 0))) ->
   (l_size = i_2)) ->
  ((exists i_4 : int. (a_12[(shift_uint8 a_10 i_4)] <> 0) /\
    (a_12[(shift_uint8 a_6 i_4)] <> 0) /\ (i_4 < l_size) /\ (x_3 <= i_4)) ->
   (forall i_4 : int. (i_4 < i_2) -> (x_3 <= i_4) ->
    ((a_12[(shift_uint8 a_10 i_4)] = 0) \/ (a_12[(shift_uint8 a_6 i_4)] = 0)))) ->
  (forall i_4 : int. (0 <= i_4) -> (i_4 < l_size) ->
   ((separated a_20 l_size
      ((shift_uint8 t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_4)))]
         0)) l_size))) ->
  (forall i_4 : int. let a_27 = (shift_cpumask a i_4) in (0 <= i_4) ->
   (i_4 < l_size) ->
   (((valid_rd t a_27 1)) /\
    ((valid_rw t ((shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_27)] 0))
       l_size)))) ->
  (forall i_4 : int. (0 <= i_4) -> (i_4 < l_size) ->
   ((a_21[(shift_uint8 a_18 i_4)] <> 0) <->
    (a_21[(shift_uint8 a_10 i_4)] <> 0))) ->
  (forall i_4 : int. (a_12[(shift_uint8 a_18 i_4)] <> 0) -> (0 <= i_4) ->
   (i_4 < l_size) -> (a_12[(shift_uint8 a_10 i_4)] <> 0)) ->
  (forall i_4 : int. (a_12[(shift_uint8 a_10 i_4)] <> 0) -> (0 <= i_4) ->
   (i_4 < l_size) -> (a_12[(shift_uint8 a_18 i_4)] <> 0)) ->
  (forall i_4 : int. (a_12[(shift_uint8 a_6 i_4)] <> 0) ->
   (a_12[(shift_uint8 a_18 i_4)] <> 0) -> (0 <= i_4) -> (i_4 < i_3) ->
   (i_4 < l_size) -> (((l_idle_cpu i_4)) = 0)) ->
  (forall a_27 : addr. let a_28 = (l_sched_group_cpus a_27) in
   let a_29 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_28)] 0) in
   ((valid_rd t a_28 1)) /\ ((valid_rd t a_29 l_size)) /\
   (forall i_4 : int. (0 <= i_4) -> (i_4 < l_size) ->
    ((separated a_29 l_size
       ((shift_uint8
          t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_4)))] 0))
       l_size)))) ->
  (forall a_27 : addr. let a_28 = (l_sched_group_mask a_27) in
   let a_29 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_28)] 0) in
   ((valid_rd t a_28 1)) /\ ((valid_rd t a_29 l_size)) /\
   (forall i_4 : int. (0 <= i_4) -> (i_4 < l_size) ->
    ((separated a_29 l_size
       ((shift_uint8
          t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_4)))] 0))
       l_size)))) ->
  (forall a_27 : addr. let a_28 = (l_group_balance_mask a_27) in
   let a_29 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_28)] 0) in
   ((valid_rd t a_28 1)) /\ ((valid_rd t a_29 l_size)) /\
   (forall i_4 : int. (0 <= i_4) -> (i_4 < l_size) ->
    ((separated a_29 l_size
       ((shift_uint8
          t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_4)))] 0))
       l_size)))) ->
  (forall i_4 : int. let a_27 = (l_cpu_smt_mask i_4) in
   let a_28 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_27)] 0) in
   (0 <= i_4) -> (i_4 < l_size) ->
   (((valid_rd t a_27 1)) /\ ((valid_rd t a_28 l_size)) /\
    (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
     ((separated a_28 l_size
        ((shift_uint8
           t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_5)))] 0))
        l_size))))) ->
  (a_12[(shift_uint8 a_10 i_1)] <> 0)

end

(* ---------------------------------------------------------- *)
(* --- Establishment of Invariant 'a2' (file c11.c, line 143) --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_loop_inv_a2_established
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import Compound.Compound
use import A_thread_variables_properties.A_thread_variables_properties
use import A_schedule_cpumask.A_schedule_cpumask
use import Cint.Cint

(*
goal WP "expl:Establishment of Invariant 'a2' (file c11.c, line 143)":
*)
goal goal16:
  forall i_1 i : int.
  forall t : map int int.
  forall t_2 t_1 : map addr int.
  forall t_3 : map addr addr.
  forall a_1 a : addr.
  let a_2 = (shiftfield_f5_lb_env_idle a_1) in
  let x = t_2[a_2] in
  let a_3 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_4 = t_3[a_3] in
  let a_5 = t_3[(shiftfield_f1_cpumask_bits a_4)] in
  let a_6 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x_1 = t_2[a_6] in
  let x_2 = t_2[(shift_uint8 a_5 x_1)] in
  let a_7 = (shift_cpumask a i) in
  let a_8 = t_3[(shiftfield_f1_cpumask_bits a_7)] in
  let a_9 = (shift_uint8 a_8 0) in
  let a_10 = (havoc t_1 t_2 a_9 l_size) in
  let a_11 = (shiftfield_f5_lb_env_sd a_1) in
  let a_12 = t_3[a_11] in
  let a_13 = (shiftfield_f3_sched_domain_groups a_12) in
  let a_14 = t_3[a_13] in
  let a_15 = (l_group_balance_mask a_14) in
  let a_16 = t_3[(shiftfield_f1_cpumask_bits a_15)] in
  let a_17 = (shift_uint8 a_5 0) in
  let a_18 = (shift_uint8 a_16 0) in
  (x <> 2) ->
  (x_2 <> 0) ->
  (a_10[(shift_uint8 a_16 i_1)] <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= i_1) ->
  (i_1 < l_size) ->
  (0 <= x_1) ->
  (x_1 < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_3)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 x)) ->
  ((is_sint32 x_1)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_6 1)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t a_11 1)) ->
  ((valid_rd t a_7 1)) ->
  ((valid_rd t a_4 1)) ->
  ((valid_rd t t_3[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_12 2)) ->
  ((is_sint32 t_2[(shiftfield_f3_sched_domain_flags a_12)])) ->
  ((valid_rd t a_13 1)) ->
  ((valid_rd t a_14 1)) ->
  ((valid_rd t a_15 1)) ->
  ((is_uint8 x_2)) ->
  ((valid_rd t a_17 l_size)) ->
  ((valid_rw t a_9 l_size)) ->
  ((valid_rd t a_18 l_size)) ->
  ((separated a_9 l_size a_18 l_size)) ->
  (forall i_2 : int. (0 <= i_2) -> (i_2 < l_size) ->
   ((separated a_17 l_size
      ((shift_uint8 t_3[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_2)))]
         0)) l_size))) ->
  (forall i_2 : int. let a_19 = (shift_cpumask a i_2) in (0 <= i_2) ->
   (i_2 < l_size) ->
   (((valid_rd t a_19 1)) /\
    ((valid_rw t ((shift_uint8 t_3[(shiftfield_f1_cpumask_bits a_19)] 0))
       l_size)))) ->
  (forall i_2 : int. (0 <= i_2) -> (i_2 < l_size) ->
   ((a_10[(shift_uint8 a_16 i_2)] <> 0) <->
    (a_10[(shift_uint8 a_8 i_2)] <> 0))) ->
  (forall a_19 : addr. let a_20 = (l_sched_group_cpus a_19) in
   let a_21 = (shift_uint8 t_3[(shiftfield_f1_cpumask_bits a_20)] 0) in
   ((valid_rd t a_20 1)) /\ ((valid_rd t a_21 l_size)) /\
   (forall i_2 : int. (0 <= i_2) -> (i_2 < l_size) ->
    ((separated a_21 l_size
       ((shift_uint8
          t_3[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_2)))] 0))
       l_size)))) ->
  (forall a_19 : addr. let a_20 = (l_sched_group_mask a_19) in
   let a_21 = (shift_uint8 t_3[(shiftfield_f1_cpumask_bits a_20)] 0) in
   ((valid_rd t a_20 1)) /\ ((valid_rd t a_21 l_size)) /\
   (forall i_2 : int. (0 <= i_2) -> (i_2 < l_size) ->
    ((separated a_21 l_size
       ((shift_uint8
          t_3[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_2)))] 0))
       l_size)))) ->
  (forall a_19 : addr. let a_20 = (l_group_balance_mask a_19) in
   let a_21 = (shift_uint8 t_3[(shiftfield_f1_cpumask_bits a_20)] 0) in
   ((valid_rd t a_20 1)) /\ ((valid_rd t a_21 l_size)) /\
   (forall i_2 : int. (0 <= i_2) -> (i_2 < l_size) ->
    ((separated a_21 l_size
       ((shift_uint8
          t_3[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_2)))] 0))
       l_size)))) ->
  (forall i_2 : int. let a_19 = (l_cpu_smt_mask i_2) in
   let a_20 = (shift_uint8 t_3[(shiftfield_f1_cpumask_bits a_19)] 0) in
   (0 <= i_2) -> (i_2 < l_size) ->
   (((valid_rd t a_19 1)) /\ ((valid_rd t a_20 l_size)) /\
    (forall i_3 : int. (0 <= i_3) -> (i_3 < l_size) ->
     ((separated a_20 l_size
        ((shift_uint8
           t_3[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_3)))] 0))
        l_size))))) ->
  (a_10[(shift_uint8 a_8 i_1)] <> 0)

end

(* ---------------------------------------------------------- *)
(* --- Preservation of Invariant 'a3' (file c11.c, line 144) --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_loop_inv_a3_preserved
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import A_schedule_cpumask.A_schedule_cpumask
use import Compound.Compound
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import Cbits.Cbits

(*
goal WP "expl:Preservation of Invariant 'a3' (file c11.c, line 144)":
*)
goal goal17:
  forall p : bool.
  forall i_7 i_6 i_5 i_4 i_3 i_2 i_1 i : int.
  forall t : map int int.
  forall t_4 t_3 t_2 t_1 : map addr int.
  forall t_5 : map addr addr.
  forall a_2 a_1 a : addr.
  let x = (l_idle_cpu i_6) in
  let a_3 = (shiftfield_f5_lb_env_idle a_1) in
  let x_1 = t_3[a_3] in
  let a_4 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_5 = t_5[a_4] in
  let a_6 = (shiftfield_f1_cpumask_bits a_5) in
  let a_7 = t_5[a_6] in
  let a_8 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x_2 = t_3[a_8] in
  let x_3 = t_3[(shift_uint8 a_7 x_2)] in
  let a_9 = (shift_cpumask a i) in
  let a_10 = (shiftfield_f1_cpumask_bits a_9) in
  let a_11 = t_5[a_10] in
  let a_12 = (shift_uint8 a_11 0) in
  let a_13 = (havoc t_2 t_3 a_12 l_size) in
  let a_14 = (shiftfield_f5_lb_env_sd a_1) in
  let a_15 = t_5[a_14] in
  let a_16 = (shiftfield_f3_sched_domain_groups a_15) in
  let a_17 = t_5[a_16] in
  let a_18 = (l_group_balance_mask a_17) in
  let a_19 = t_5[(shiftfield_f1_cpumask_bits a_18)] in
  let a_20 = (shiftfield_f3_sched_domain_flags a_15) in
  let a_21 = (shiftfield_f5_lb_env_sd a_2) in
  let a_22 = (shiftfield_f3_sched_domain_flags t_5[a_21]) in
  let x_4 = t_4[a_22] in
  let a_23 = (shift_uint8 a_7 0) in
  let a_24 = (havoc t_1 t_3 a_12 l_size) in
  let a_25 = a_13[(shift_uint8 a_11 i_6)] in
  let a_26 = a_13[(shift_uint8 a_7 i_1)] in
  let a_27 = a_13[(shift_uint8 a_7 i_6)] in
  let a_28 = a_13[(shift_uint8 a_19 i_1)] in
  let a_29 = a_13[a_20] in
  let a_30 = (shift_uint8 a_19 0) in
  let x_5 = (to_uint32 i_7) in
  (i_3 <> (-1)) ->
  ((x <> 0) <-> (i_4 <> 0)) ->
  (x_1 <> 2) ->
  (x_3 <> 0) ->
  (a_13[(shift_uint8 a_19 i_5)] <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= i_5) ->
  (i_5 < l_size) ->
  (0 <= i_6) ->
  (i_6 < l_size) ->
  (0 <= i_7) ->
  (i_7 <= l_size) ->
  (((to_uint32 i_6)) < l_size) ->
  (0 <= x_2) ->
  (x_2 < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_5)) ->
  ((linked t)) ->
  ((is_uint8 i_4)) ->
  ((is_uint32 i)) ->
  ((is_sint32 i_1)) ->
  ((is_sint32 i_2)) ->
  ((is_sint32 i_3)) ->
  ((is_sint32 i_6)) ->
  ((is_sint32 i_7)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 x_1)) ->
  ((is_sint32 x_2)) ->
  ((valid_rd t a_4 1)) ->
  ((valid_rd t a_8 1)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_14 1)) ->
  ((valid_rd t a_9 1)) ->
  ((valid_rd t a_5 1)) ->
  ((valid_rd t t_5[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_15 2)) ->
  ((is_sint32 t_3[a_20])) ->
  ((is_sint32 x_4)) ->
  ((valid_rd t a_10 1)) ->
  ((valid_rd t a_6 1)) ->
  ((valid_rd t a_16 1)) ->
  ((valid_rd t a_17 1)) ->
  ((valid_rd t a_18 1)) ->
  ((is_uint8 x_3)) ->
  ((valid_rd t a_12 l_size)) ->
  ((valid_rd t a_23 l_size)) ->
  ((valid_rw t a_12 l_size)) ->
  ((is_uint8 a_24[(shift_uint8 a_7 (-1))])) ->
  ((is_uint8 a_24[(shift_uint8 a_19 (-1))])) ->
  ((is_uint8 a_25)) ->
  ((is_uint8 a_26)) ->
  ((is_uint8 a_27)) ->
  ((is_uint8 a_28)) ->
  ((is_sint32 a_24[a_20])) ->
  ((is_sint32 a_29)) ->
  ((valid_rd t a_30 l_size)) ->
  ((separated a_12 l_size a_30 l_size)) ->
  (if (i_4 = 0) then ((i_3 = i_1) /\ (i_6 <= 2147483646))
   else ((p=False) /\ (i_2 = i_1) /\ (a_2 = a_1) /\ (x <> 0) /\
         (((land 7 x_4)) = 0) /\ (a_13 = t_4) /\ (i_6 <= 2147483646) /\
         (not (p_idle_core t_5 t_4 i_6)) /\ ((valid_rd t a_21 1)) /\
         ((valid_rd t a_22 1)) /\
         (if (i_2 = (-1)) then (i_6 = i_3) else (i_3 = i_2)))) ->
  ((((land 7 a_29)) <> 0) -> (i_1 = (-1))) ->
  ((i_1 <> (-1)) ->
   ((((l_idle_cpu i_1)) <> 0) /\ (a_26 <> 0) /\ (a_28 <> 0) /\ (0 <= i_1) /\
    (i_1 < l_size))) ->
  ((i_1 = (-1)) ->
   (forall i_8 : int. (a_13[(shift_uint8 a_19 i_8)] <> 0) -> (0 <= i_8) ->
    (i_8 < l_size) -> (a_13[(shift_uint8 a_11 i_8)] <> 0))) ->
  ((exists i_8 : int. (a_13[(shift_uint8 a_11 i_8)] <> 0) /\
    (a_13[(shift_uint8 a_7 i_8)] <> 0) /\ (i_8 < l_size) /\ (x_5 <= i_8)) ->
   (x_5 <= i_6)) ->
  ((exists i_8 : int. (a_13[(shift_uint8 a_11 i_8)] <> 0) /\
    (a_13[(shift_uint8 a_7 i_8)] <> 0) /\ (i_8 < l_size) /\ (x_5 <= i_8)) ->
   ((a_25 <> 0) /\ (a_27 <> 0))) ->
  ((forall i_8 : int. (i_8 < l_size) -> (x_5 <= i_8) ->
    ((a_13[(shift_uint8 a_11 i_8)] = 0) \/ (a_13[(shift_uint8 a_7 i_8)] = 0))) ->
   (l_size = i_6)) ->
  ((i_1 <> (-1)) ->
   (forall i_8 : int. (a_13[(shift_uint8 a_7 i_8)] <> 0) ->
    (a_13[(shift_uint8 a_19 i_8)] <> 0) -> (0 <= i_8) -> (i_8 < i_1) ->
    (i_8 < l_size) -> (((l_idle_cpu i_8)) = 0))) ->
  ((i_1 = (-1)) ->
   (forall i_8 : int. (a_13[(shift_uint8 a_7 i_8)] <> 0) ->
    (a_13[(shift_uint8 a_19 i_8)] <> 0) -> (0 <= i_8) -> (i_8 < i_7) ->
    (i_8 < l_size) -> (((l_idle_cpu i_8)) = 0))) ->
  ((exists i_8 : int. (a_13[(shift_uint8 a_11 i_8)] <> 0) /\
    (a_13[(shift_uint8 a_7 i_8)] <> 0) /\ (i_8 < l_size) /\ (x_5 <= i_8)) ->
   (forall i_8 : int. (i_8 < i_6) -> (x_5 <= i_8) ->
    ((a_13[(shift_uint8 a_11 i_8)] = 0) \/ (a_13[(shift_uint8 a_7 i_8)] = 0)))) ->
  ((i_1 <> (-1)) ->
   (forall i_8 : int. (a_13[(shift_uint8 a_7 i_8)] <> 0) ->
    (a_13[(shift_uint8 a_19 i_8)] <> 0) -> (0 <= i_8) -> (i_1 <= i_8) ->
    (i_8 < i_7) -> (i_8 < l_size) -> (not (p_idle_core t_5 a_13 i_8)))) ->
  ((i_1 <> (-1)) ->
   (forall i_8 : int. (a_13[(shift_uint8 a_19 i_8)] <> 0) -> (0 <= i_8) ->
    (i_8 < l_size) ->
    ((a_13[(shift_uint8 a_11 i_8)] <> 0) \/ (not (p_idle_core t_5 a_13 i_8))))) ->
  ((i_4 = 0) \/ (i_4 = 1)) ->
  (forall i_8 : int. (0 <= i_8) -> (i_8 < l_size) ->
   ((separated a_23 l_size
      ((shift_uint8 t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_8)))]
         0)) l_size))) ->
  (forall i_8 : int. let a_31 = (shift_cpumask a i_8) in (0 <= i_8) ->
   (i_8 < l_size) ->
   (((valid_rd t a_31 1)) /\
    ((valid_rw t ((shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_31)] 0))
       l_size)))) ->
  (forall i_8 : int. (0 <= i_8) -> (i_8 < l_size) ->
   ((a_24[(shift_uint8 a_19 i_8)] <> 0) <->
    (a_24[(shift_uint8 a_11 i_8)] <> 0))) ->
  (forall i_8 : int. (a_13[(shift_uint8 a_11 i_8)] <> 0) -> (0 <= i_8) ->
   (i_8 < l_size) -> (a_13[(shift_uint8 a_19 i_8)] <> 0)) ->
  (forall a_31 : addr. let a_32 = (l_sched_group_cpus a_31) in
   let a_33 = (shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_32)] 0) in
   ((valid_rd t a_32 1)) /\ ((valid_rd t a_33 l_size)) /\
   (forall i_8 : int. (0 <= i_8) -> (i_8 < l_size) ->
    ((separated a_33 l_size
       ((shift_uint8
          t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_8)))] 0))
       l_size)))) ->
  (forall a_31 : addr. let a_32 = (l_sched_group_mask a_31) in
   let a_33 = (shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_32)] 0) in
   ((valid_rd t a_32 1)) /\ ((valid_rd t a_33 l_size)) /\
   (forall i_8 : int. (0 <= i_8) -> (i_8 < l_size) ->
    ((separated a_33 l_size
       ((shift_uint8
          t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_8)))] 0))
       l_size)))) ->
  (forall a_31 : addr. let a_32 = (l_group_balance_mask a_31) in
   let a_33 = (shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_32)] 0) in
   ((valid_rd t a_32 1)) /\ ((valid_rd t a_33 l_size)) /\
   (forall i_8 : int. (0 <= i_8) -> (i_8 < l_size) ->
    ((separated a_33 l_size
       ((shift_uint8
          t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_8)))] 0))
       l_size)))) ->
  (forall i_8 : int. let a_31 = (l_cpu_smt_mask i_8) in
   let a_32 = (shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_31)] 0) in
   (0 <= i_8) -> (i_8 < l_size) ->
   (((valid_rd t a_31 1)) /\ ((valid_rd t a_32 l_size)) /\
    (forall i_9 : int. (0 <= i_9) -> (i_9 < l_size) ->
     ((separated a_32 l_size
        ((shift_uint8
           t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_9)))] 0))
        l_size))))) ->
  ((a_13[(shift_uint8 a_11 i_5)] <> 0) \/ (not (p_idle_core t_5 a_13 i_5)))

end

(* ---------------------------------------------------------- *)
(* --- Preservation of Invariant 'i2' (file c11.c, line 147) --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_loop_inv_i2_preserved
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import A_schedule_cpumask.A_schedule_cpumask
use import Compound.Compound
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint

(*
goal WP "expl:Preservation of Invariant 'i2' (file c11.c, line 147)":
*)
goal goal18:
  forall i_3 i_2 i_1 i : int.
  forall t : map int int.
  forall t_3 t_2 t_1 : map addr int.
  forall t_4 : map addr addr.
  forall a_1 a : addr.
  let a_2 = (shiftfield_f5_lb_env_idle a_1) in
  let x = t_3[a_2] in
  let a_3 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_4 = t_4[a_3] in
  let a_5 = (shiftfield_f1_cpumask_bits a_4) in
  let a_6 = t_4[a_5] in
  let a_7 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x_1 = t_3[a_7] in
  let x_2 = t_3[(shift_uint8 a_6 x_1)] in
  let a_8 = (shift_cpumask a i) in
  let a_9 = (shiftfield_f1_cpumask_bits a_8) in
  let a_10 = t_4[a_9] in
  let a_11 = (shift_uint8 a_10 0) in
  let a_12 = (havoc t_2 t_3 a_11 l_size) in
  let a_13 = (shiftfield_f5_lb_env_sd a_1) in
  let a_14 = t_4[a_13] in
  let a_15 = (shiftfield_f3_sched_domain_groups a_14) in
  let a_16 = t_4[a_15] in
  let a_17 = (l_group_balance_mask a_16) in
  let a_18 = t_4[(shiftfield_f1_cpumask_bits a_17)] in
  let a_19 = (shiftfield_f3_sched_domain_flags a_14) in
  let a_20 = (shift_uint8 a_6 0) in
  let a_21 = (havoc t_1 t_3 a_11 l_size) in
  let a_22 = (shift_uint8 a_6 (-1)) in
  let a_23 = (shift_uint8 a_18 (-1)) in
  let a_24 = a_12[(shift_uint8 a_10 i_2)] in
  let a_25 = a_12[(shift_uint8 a_6 i_2)] in
  let a_26 = (shift_uint8 a_18 0) in
  let x_3 = (to_uint32 i_3) in
  (((l_idle_cpu i_2)) = 0) ->
  (x <> 2) ->
  (x_2 <> 0) ->
  (a_12[(shift_uint8 a_6 i_1)] <> 0) ->
  (a_12[(shift_uint8 a_18 i_1)] <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= i_1) ->
  (i_1 < l_size) ->
  (0 <= i_2) ->
  (i_1 <= i_2) ->
  (i_2 < l_size) ->
  (0 <= i_3) ->
  (i_3 <= l_size) ->
  (((to_uint32 i_2)) < l_size) ->
  (0 <= x_1) ->
  (x_1 < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  (i_2 <= 2147483646) ->
  ((framed t_4)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((is_sint32 i_2)) ->
  ((is_sint32 i_3)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 x)) ->
  ((is_sint32 (1 + i_2))) ->
  ((is_sint32 x_1)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_7 1)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t a_13 1)) ->
  ((valid_rd t a_8 1)) ->
  ((valid_rd t a_4 1)) ->
  ((valid_rd t t_4[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_14 2)) ->
  ((is_sint32 t_3[a_19])) ->
  ((valid_rd t a_9 1)) ->
  ((valid_rd t a_5 1)) ->
  ((valid_rd t a_15 1)) ->
  ((valid_rd t a_16 1)) ->
  ((valid_rd t a_17 1)) ->
  ((is_uint8 x_2)) ->
  ((valid_rd t a_11 l_size)) ->
  ((valid_rd t a_20 l_size)) ->
  ((valid_rw t a_11 l_size)) ->
  ((is_uint8 a_21[a_22])) ->
  ((is_uint8 a_21[a_23])) ->
  ((is_uint8 a_24)) ->
  ((is_uint8 a_12[a_22])) ->
  ((is_uint8 a_25)) ->
  ((is_uint8 a_12[a_23])) ->
  ((is_sint32 a_21[a_19])) ->
  ((is_sint32 a_12[a_19])) ->
  ((valid_rd t a_26 l_size)) ->
  ((separated a_11 l_size a_26 l_size)) ->
  ((exists i_4 : int. (a_12[(shift_uint8 a_10 i_4)] <> 0) /\
    (a_12[(shift_uint8 a_6 i_4)] <> 0) /\ (i_4 < l_size) /\ (x_3 <= i_4)) ->
   (x_3 <= i_2)) ->
  ((exists i_4 : int. (a_12[(shift_uint8 a_10 i_4)] <> 0) /\
    (a_12[(shift_uint8 a_6 i_4)] <> 0) /\ (i_4 < l_size) /\ (x_3 <= i_4)) ->
   ((a_24 <> 0) /\ (a_25 <> 0))) ->
  ((forall i_4 : int. (i_4 < l_size) -> (x_3 <= i_4) ->
    ((a_12[(shift_uint8 a_10 i_4)] = 0) \/ (a_12[(shift_uint8 a_6 i_4)] = 0))) ->
   (l_size = i_2)) ->
  ((exists i_4 : int. (a_12[(shift_uint8 a_10 i_4)] <> 0) /\
    (a_12[(shift_uint8 a_6 i_4)] <> 0) /\ (i_4 < l_size) /\ (x_3 <= i_4)) ->
   (forall i_4 : int. (i_4 < i_2) -> (x_3 <= i_4) ->
    ((a_12[(shift_uint8 a_10 i_4)] = 0) \/ (a_12[(shift_uint8 a_6 i_4)] = 0)))) ->
  (forall i_4 : int. (0 <= i_4) -> (i_4 < l_size) ->
   ((separated a_20 l_size
      ((shift_uint8 t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_4)))]
         0)) l_size))) ->
  (forall i_4 : int. let a_27 = (shift_cpumask a i_4) in (0 <= i_4) ->
   (i_4 < l_size) ->
   (((valid_rd t a_27 1)) /\
    ((valid_rw t ((shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_27)] 0))
       l_size)))) ->
  (forall i_4 : int. (0 <= i_4) -> (i_4 < l_size) ->
   ((a_21[(shift_uint8 a_18 i_4)] <> 0) <->
    (a_21[(shift_uint8 a_10 i_4)] <> 0))) ->
  (forall i_4 : int. (a_12[(shift_uint8 a_18 i_4)] <> 0) -> (0 <= i_4) ->
   (i_4 < l_size) -> (a_12[(shift_uint8 a_10 i_4)] <> 0)) ->
  (forall i_4 : int. (a_12[(shift_uint8 a_10 i_4)] <> 0) -> (0 <= i_4) ->
   (i_4 < l_size) -> (a_12[(shift_uint8 a_18 i_4)] <> 0)) ->
  (forall i_4 : int. (a_12[(shift_uint8 a_6 i_4)] <> 0) ->
   (a_12[(shift_uint8 a_18 i_4)] <> 0) -> (0 <= i_4) -> (i_4 < i_3) ->
   (i_4 < l_size) -> (((l_idle_cpu i_4)) = 0)) ->
  (forall a_27 : addr. let a_28 = (l_sched_group_cpus a_27) in
   let a_29 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_28)] 0) in
   ((valid_rd t a_28 1)) /\ ((valid_rd t a_29 l_size)) /\
   (forall i_4 : int. (0 <= i_4) -> (i_4 < l_size) ->
    ((separated a_29 l_size
       ((shift_uint8
          t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_4)))] 0))
       l_size)))) ->
  (forall a_27 : addr. let a_28 = (l_sched_group_mask a_27) in
   let a_29 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_28)] 0) in
   ((valid_rd t a_28 1)) /\ ((valid_rd t a_29 l_size)) /\
   (forall i_4 : int. (0 <= i_4) -> (i_4 < l_size) ->
    ((separated a_29 l_size
       ((shift_uint8
          t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_4)))] 0))
       l_size)))) ->
  (forall a_27 : addr. let a_28 = (l_group_balance_mask a_27) in
   let a_29 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_28)] 0) in
   ((valid_rd t a_28 1)) /\ ((valid_rd t a_29 l_size)) /\
   (forall i_4 : int. (0 <= i_4) -> (i_4 < l_size) ->
    ((separated a_29 l_size
       ((shift_uint8
          t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_4)))] 0))
       l_size)))) ->
  (forall i_4 : int. let a_27 = (l_cpu_smt_mask i_4) in
   let a_28 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_27)] 0) in
   (0 <= i_4) -> (i_4 < l_size) ->
   (((valid_rd t a_27 1)) /\ ((valid_rd t a_28 l_size)) /\
    (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
     ((separated a_28 l_size
        ((shift_uint8
           t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_5)))] 0))
        l_size))))) ->
  (((l_idle_cpu i_1)) = 0)

end

(* ---------------------------------------------------------- *)
(* --- Preservation of Invariant 'i3' (file c11.c, line 148) --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_loop_inv_i3_preserved
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import A_schedule_cpumask.A_schedule_cpumask
use import Compound.Compound
use import Cint.Cint
use import Cbits.Cbits
use import A_thread_variables_properties.A_thread_variables_properties

(*
goal WP "expl:Preservation of Invariant 'i3' (file c11.c, line 148)":
*)
goal goal19:
  forall i_2 i_1 i : int.
  forall t : map int int.
  forall t_3 t_2 t_1 : map addr int.
  forall t_4 : map addr addr.
  forall a_1 a : addr.
  let a_2 = (shiftfield_f5_lb_env_idle a_1) in
  let x = t_3[a_2] in
  let a_3 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_4 = t_4[a_3] in
  let a_5 = (shiftfield_f1_cpumask_bits a_4) in
  let a_6 = t_4[a_5] in
  let a_7 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x_1 = t_3[a_7] in
  let x_2 = t_3[(shift_uint8 a_6 x_1)] in
  let a_8 = (shift_cpumask a i) in
  let a_9 = (shiftfield_f1_cpumask_bits a_8) in
  let a_10 = t_4[a_9] in
  let a_11 = (shift_uint8 a_10 0) in
  let a_12 = (havoc t_2 t_3 a_11 l_size) in
  let a_13 = (shiftfield_f5_lb_env_sd a_1) in
  let a_14 = t_4[a_13] in
  let a_15 = (shiftfield_f3_sched_domain_flags a_14) in
  let a_16 = a_12[a_15] in
  let a_17 = (shiftfield_f3_sched_domain_groups a_14) in
  let a_18 = t_4[a_17] in
  let a_19 = (l_group_balance_mask a_18) in
  let a_20 = (shift_uint8 a_6 0) in
  let a_21 = (havoc t_1 t_3 a_11 l_size) in
  let a_22 = (shift_uint8 a_6 (-1)) in
  let a_23 = t_4[(shiftfield_f1_cpumask_bits a_19)] in
  let a_24 = (shift_uint8 a_23 (-1)) in
  let a_25 = a_12[(shift_uint8 a_10 i_1)] in
  let a_26 = a_12[(shift_uint8 a_6 i_1)] in
  let a_27 = a_12[(shift_uint8 a_23 i_1)] in
  let a_28 = (shift_uint8 a_23 0) in
  let x_3 = (to_uint32 i_2) in
  (i_1 <> (-1)) ->
  (((l_idle_cpu i_1)) <> 0) ->
  (x <> 2) ->
  (x_2 <> 0) ->
  (((land 7 a_16)) = 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= i_1) ->
  (i_1 < l_size) ->
  (0 <= i_2) ->
  (i_2 <= l_size) ->
  (((to_uint32 i_1)) < l_size) ->
  (0 <= x_1) ->
  (x_1 < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  (i_1 <= 2147483646) ->
  ((framed t_4)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((is_sint32 i_1)) ->
  ((is_sint32 i_2)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 x)) ->
  ((is_sint32 x_1)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_7 1)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t a_13 1)) ->
  ((valid_rd t a_8 1)) ->
  ((valid_rd t a_4 1)) ->
  ((valid_rd t t_4[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_14 2)) ->
  ((is_sint32 t_3[a_15])) ->
  ((valid_rd t a_9 1)) ->
  ((valid_rd t a_5 1)) ->
  ((valid_rd t a_15 1)) ->
  ((valid_rd t a_17 1)) ->
  ((valid_rd t a_18 1)) ->
  ((valid_rd t a_19 1)) ->
  ((is_uint8 x_2)) ->
  ((valid_rd t a_11 l_size)) ->
  ((valid_rd t a_20 l_size)) ->
  ((valid_rw t a_11 l_size)) ->
  ((is_uint8 a_21[a_22])) ->
  ((is_uint8 a_21[a_24])) ->
  ((is_uint8 a_25)) ->
  ((is_uint8 a_12[a_22])) ->
  ((is_uint8 a_26)) ->
  ((is_uint8 a_12[a_24])) ->
  ((is_uint8 a_27)) ->
  ((is_sint32 a_21[a_15])) ->
  ((is_sint32 a_16)) ->
  ((valid_rd t a_28 l_size)) ->
  (not (p_idle_core t_4 a_12 i_1)) ->
  ((separated a_11 l_size a_28 l_size)) ->
  ((exists i_3 : int. (a_12[(shift_uint8 a_10 i_3)] <> 0) /\
    (a_12[(shift_uint8 a_6 i_3)] <> 0) /\ (i_3 < l_size) /\ (x_3 <= i_3)) ->
   (x_3 <= i_1)) ->
  ((exists i_3 : int. (a_12[(shift_uint8 a_10 i_3)] <> 0) /\
    (a_12[(shift_uint8 a_6 i_3)] <> 0) /\ (i_3 < l_size) /\ (x_3 <= i_3)) ->
   ((a_25 <> 0) /\ (a_26 <> 0))) ->
  ((forall i_3 : int. (i_3 < l_size) -> (x_3 <= i_3) ->
    ((a_12[(shift_uint8 a_10 i_3)] = 0) \/ (a_12[(shift_uint8 a_6 i_3)] = 0))) ->
   (l_size = i_1)) ->
  ((exists i_3 : int. (a_12[(shift_uint8 a_10 i_3)] <> 0) /\
    (a_12[(shift_uint8 a_6 i_3)] <> 0) /\ (i_3 < l_size) /\ (x_3 <= i_3)) ->
   (forall i_3 : int. (i_3 < i_1) -> (x_3 <= i_3) ->
    ((a_12[(shift_uint8 a_10 i_3)] = 0) \/ (a_12[(shift_uint8 a_6 i_3)] = 0)))) ->
  (forall i_3 : int. (0 <= i_3) -> (i_3 < l_size) ->
   ((separated a_20 l_size
      ((shift_uint8 t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_3)))]
         0)) l_size))) ->
  (forall i_3 : int. let a_29 = (shift_cpumask a i_3) in (0 <= i_3) ->
   (i_3 < l_size) ->
   (((valid_rd t a_29 1)) /\
    ((valid_rw t ((shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_29)] 0))
       l_size)))) ->
  (forall i_3 : int. (0 <= i_3) -> (i_3 < l_size) ->
   ((a_21[(shift_uint8 a_23 i_3)] <> 0) <->
    (a_21[(shift_uint8 a_10 i_3)] <> 0))) ->
  (forall i_3 : int. (a_12[(shift_uint8 a_23 i_3)] <> 0) -> (0 <= i_3) ->
   (i_3 < l_size) -> (a_12[(shift_uint8 a_10 i_3)] <> 0)) ->
  (forall i_3 : int. (a_12[(shift_uint8 a_10 i_3)] <> 0) -> (0 <= i_3) ->
   (i_3 < l_size) -> (a_12[(shift_uint8 a_23 i_3)] <> 0)) ->
  (forall i_3 : int. (a_12[(shift_uint8 a_6 i_3)] <> 0) ->
   (a_12[(shift_uint8 a_23 i_3)] <> 0) -> (0 <= i_3) -> (i_3 < i_2) ->
   (i_3 < l_size) -> (((l_idle_cpu i_3)) = 0)) ->
  (forall a_29 : addr. let a_30 = (l_sched_group_cpus a_29) in
   let a_31 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_30)] 0) in
   ((valid_rd t a_30 1)) /\ ((valid_rd t a_31 l_size)) /\
   (forall i_3 : int. (0 <= i_3) -> (i_3 < l_size) ->
    ((separated a_31 l_size
       ((shift_uint8
          t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_3)))] 0))
       l_size)))) ->
  (forall a_29 : addr. let a_30 = (l_sched_group_mask a_29) in
   let a_31 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_30)] 0) in
   ((valid_rd t a_30 1)) /\ ((valid_rd t a_31 l_size)) /\
   (forall i_3 : int. (0 <= i_3) -> (i_3 < l_size) ->
    ((separated a_31 l_size
       ((shift_uint8
          t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_3)))] 0))
       l_size)))) ->
  (forall a_29 : addr. let a_30 = (l_group_balance_mask a_29) in
   let a_31 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_30)] 0) in
   ((valid_rd t a_30 1)) /\ ((valid_rd t a_31 l_size)) /\
   (forall i_3 : int. (0 <= i_3) -> (i_3 < l_size) ->
    ((separated a_31 l_size
       ((shift_uint8
          t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_3)))] 0))
       l_size)))) ->
  (forall i_3 : int. let a_29 = (l_cpu_smt_mask i_3) in
   let a_30 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_29)] 0) in
   (0 <= i_3) -> (i_3 < l_size) ->
   (((valid_rd t a_29 1)) /\ ((valid_rd t a_30 l_size)) /\
    (forall i_4 : int. (0 <= i_4) -> (i_4 < l_size) ->
     ((separated a_30 l_size
        ((shift_uint8
           t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_4)))] 0))
        l_size))))) ->
  ((a_26 <> 0) /\ (a_27 <> 0))

end

(* ---------------------------------------------------------- *)
(* --- Preservation of Invariant 'i4' (file c11.c, line 149) --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_loop_inv_i4_preserved
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import A_schedule_cpumask.A_schedule_cpumask
use import Compound.Compound
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import Cbits.Cbits

(*
goal WP "expl:Preservation of Invariant 'i4' (file c11.c, line 149)":
*)
goal goal20:
  forall p : bool.
  forall i_7 i_6 i_5 i_4 i_3 i_2 i_1 i : int.
  forall t : map int int.
  forall t_4 t_3 t_2 t_1 : map addr int.
  forall t_5 : map addr addr.
  forall a_1 a : addr.
  let x = (l_idle_cpu i_6) in
  let a_2 = (shiftfield_f5_lb_env_idle a_1) in
  let x_1 = t_3[a_2] in
  let a_3 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_4 = t_5[a_3] in
  let a_5 = (shiftfield_f1_cpumask_bits a_4) in
  let a_6 = t_5[a_5] in
  let a_7 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x_2 = t_3[a_7] in
  let x_3 = t_3[(shift_uint8 a_6 x_2)] in
  let a_8 = (shift_cpumask a i) in
  let a_9 = (shiftfield_f1_cpumask_bits a_8) in
  let a_10 = t_5[a_9] in
  let a_11 = (shift_uint8 a_10 0) in
  let a_12 = (havoc t_2 t_3 a_11 l_size) in
  let a_13 = (shiftfield_f5_lb_env_sd a_1) in
  let a_14 = t_5[a_13] in
  let a_15 = (shiftfield_f3_sched_domain_groups a_14) in
  let a_16 = t_5[a_15] in
  let a_17 = (l_group_balance_mask a_16) in
  let a_18 = t_5[(shiftfield_f1_cpumask_bits a_17)] in
  let a_19 = (shiftfield_f3_sched_domain_flags a_14) in
  let a_20 = (shift_uint8 a_6 0) in
  let a_21 = (havoc t_1 t_3 a_11 l_size) in
  let a_22 = a_12[(shift_uint8 a_10 i_6)] in
  let a_23 = a_12[(shift_uint8 a_6 i_1)] in
  let a_24 = a_12[(shift_uint8 a_6 i_6)] in
  let a_25 = a_12[(shift_uint8 a_18 i_1)] in
  let a_26 = a_12[a_19] in
  let a_27 = (shift_uint8 a_18 0) in
  let x_4 = (to_uint32 i_7) in
  (i_3 <> (-1)) ->
  ((x <> 0) <-> (i_4 <> 0)) ->
  (x_1 <> 2) ->
  (x_3 <> 0) ->
  (a_12[(shift_uint8 a_6 i_5)] <> 0) ->
  (a_12[(shift_uint8 a_18 i_5)] <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= i_5) ->
  (i_5 < i_3) ->
  (i_5 < l_size) ->
  (0 <= i_6) ->
  (i_6 < l_size) ->
  (0 <= i_7) ->
  (i_7 <= l_size) ->
  (((to_uint32 i_6)) < l_size) ->
  (0 <= x_2) ->
  (x_2 < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_5)) ->
  ((linked t)) ->
  ((is_uint8 i_4)) ->
  ((is_uint32 i)) ->
  ((is_sint32 i_1)) ->
  ((is_sint32 i_2)) ->
  ((is_sint32 i_3)) ->
  ((is_sint32 i_6)) ->
  ((is_sint32 i_7)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 x_1)) ->
  ((is_sint32 x_2)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_7 1)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t a_13 1)) ->
  ((valid_rd t a_8 1)) ->
  ((valid_rd t a_4 1)) ->
  ((valid_rd t t_5[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_14 2)) ->
  ((is_sint32 t_3[a_19])) ->
  ((valid_rd t a_9 1)) ->
  ((valid_rd t a_5 1)) ->
  ((valid_rd t a_15 1)) ->
  ((valid_rd t a_16 1)) ->
  ((valid_rd t a_17 1)) ->
  ((is_uint8 x_3)) ->
  ((valid_rd t a_11 l_size)) ->
  ((valid_rd t a_20 l_size)) ->
  ((valid_rw t a_11 l_size)) ->
  ((is_uint8 a_21[(shift_uint8 a_6 (-1))])) ->
  ((is_uint8 a_21[(shift_uint8 a_18 (-1))])) ->
  ((is_uint8 a_22)) ->
  ((is_uint8 a_23)) ->
  ((is_uint8 a_12[(shift_uint8 a_6 i_3)])) ->
  ((is_uint8 a_24)) ->
  ((is_uint8 a_25)) ->
  ((is_uint8 a_12[(shift_uint8 a_18 i_3)])) ->
  ((is_sint32 a_21[a_19])) ->
  ((is_sint32 a_26)) ->
  ((valid_rd t a_27 l_size)) ->
  ((separated a_11 l_size a_27 l_size)) ->
  (if (i_4 = 0) then ((i_3 = i_1) /\ (i_6 <= 2147483646))
   else ((p=False) /\ (i_2 = i_1) /\ (x <> 0) /\
         (((land 7 t_4[a_19])) = 0) /\ (a_12 = t_4) /\ (i_6 <= 2147483646) /\
         (not (p_idle_core t_5 t_4 i_6)) /\ ((valid_rd t a_19 1)) /\
         (if (i_2 = (-1)) then (i_6 = i_3) else (i_3 = i_2)))) ->
  ((((land 7 a_26)) <> 0) -> (i_1 = (-1))) ->
  ((i_1 <> (-1)) ->
   ((((l_idle_cpu i_1)) <> 0) /\ (a_23 <> 0) /\ (a_25 <> 0) /\ (0 <= i_1) /\
    (i_1 < l_size))) ->
  ((i_1 = (-1)) ->
   (forall i_8 : int. (a_12[(shift_uint8 a_18 i_8)] <> 0) -> (0 <= i_8) ->
    (i_8 < l_size) -> (a_12[(shift_uint8 a_10 i_8)] <> 0))) ->
  ((exists i_8 : int. (a_12[(shift_uint8 a_10 i_8)] <> 0) /\
    (a_12[(shift_uint8 a_6 i_8)] <> 0) /\ (i_8 < l_size) /\ (x_4 <= i_8)) ->
   (x_4 <= i_6)) ->
  ((exists i_8 : int. (a_12[(shift_uint8 a_10 i_8)] <> 0) /\
    (a_12[(shift_uint8 a_6 i_8)] <> 0) /\ (i_8 < l_size) /\ (x_4 <= i_8)) ->
   ((a_22 <> 0) /\ (a_24 <> 0))) ->
  ((forall i_8 : int. (i_8 < l_size) -> (x_4 <= i_8) ->
    ((a_12[(shift_uint8 a_10 i_8)] = 0) \/ (a_12[(shift_uint8 a_6 i_8)] = 0))) ->
   (l_size = i_6)) ->
  ((i_1 <> (-1)) ->
   (forall i_8 : int. (a_12[(shift_uint8 a_6 i_8)] <> 0) ->
    (a_12[(shift_uint8 a_18 i_8)] <> 0) -> (0 <= i_8) -> (i_8 < i_1) ->
    (i_8 < l_size) -> (((l_idle_cpu i_8)) = 0))) ->
  ((i_1 = (-1)) ->
   (forall i_8 : int. (a_12[(shift_uint8 a_6 i_8)] <> 0) ->
    (a_12[(shift_uint8 a_18 i_8)] <> 0) -> (0 <= i_8) -> (i_8 < i_7) ->
    (i_8 < l_size) -> (((l_idle_cpu i_8)) = 0))) ->
  ((exists i_8 : int. (a_12[(shift_uint8 a_10 i_8)] <> 0) /\
    (a_12[(shift_uint8 a_6 i_8)] <> 0) /\ (i_8 < l_size) /\ (x_4 <= i_8)) ->
   (forall i_8 : int. (i_8 < i_6) -> (x_4 <= i_8) ->
    ((a_12[(shift_uint8 a_10 i_8)] = 0) \/ (a_12[(shift_uint8 a_6 i_8)] = 0)))) ->
  ((i_1 <> (-1)) ->
   (forall i_8 : int. (a_12[(shift_uint8 a_6 i_8)] <> 0) ->
    (a_12[(shift_uint8 a_18 i_8)] <> 0) -> (0 <= i_8) -> (i_1 <= i_8) ->
    (i_8 < i_7) -> (i_8 < l_size) -> (not (p_idle_core t_5 a_12 i_8)))) ->
  ((i_1 <> (-1)) ->
   (forall i_8 : int. (a_12[(shift_uint8 a_18 i_8)] <> 0) -> (0 <= i_8) ->
    (i_8 < l_size) ->
    ((a_12[(shift_uint8 a_10 i_8)] <> 0) \/ (not (p_idle_core t_5 a_12 i_8))))) ->
  ((i_4 = 0) \/ (i_4 = 1)) ->
  (forall i_8 : int. (0 <= i_8) -> (i_8 < l_size) ->
   ((separated a_20 l_size
      ((shift_uint8 t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_8)))]
         0)) l_size))) ->
  (forall i_8 : int. let a_28 = (shift_cpumask a i_8) in (0 <= i_8) ->
   (i_8 < l_size) ->
   (((valid_rd t a_28 1)) /\
    ((valid_rw t ((shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_28)] 0))
       l_size)))) ->
  (forall i_8 : int. (0 <= i_8) -> (i_8 < l_size) ->
   ((a_21[(shift_uint8 a_18 i_8)] <> 0) <->
    (a_21[(shift_uint8 a_10 i_8)] <> 0))) ->
  (forall i_8 : int. (a_12[(shift_uint8 a_10 i_8)] <> 0) -> (0 <= i_8) ->
   (i_8 < l_size) -> (a_12[(shift_uint8 a_18 i_8)] <> 0)) ->
  (forall a_28 : addr. let a_29 = (l_sched_group_cpus a_28) in
   let a_30 = (shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_29)] 0) in
   ((valid_rd t a_29 1)) /\ ((valid_rd t a_30 l_size)) /\
   (forall i_8 : int. (0 <= i_8) -> (i_8 < l_size) ->
    ((separated a_30 l_size
       ((shift_uint8
          t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_8)))] 0))
       l_size)))) ->
  (forall a_28 : addr. let a_29 = (l_sched_group_mask a_28) in
   let a_30 = (shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_29)] 0) in
   ((valid_rd t a_29 1)) /\ ((valid_rd t a_30 l_size)) /\
   (forall i_8 : int. (0 <= i_8) -> (i_8 < l_size) ->
    ((separated a_30 l_size
       ((shift_uint8
          t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_8)))] 0))
       l_size)))) ->
  (forall a_28 : addr. let a_29 = (l_group_balance_mask a_28) in
   let a_30 = (shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_29)] 0) in
   ((valid_rd t a_29 1)) /\ ((valid_rd t a_30 l_size)) /\
   (forall i_8 : int. (0 <= i_8) -> (i_8 < l_size) ->
    ((separated a_30 l_size
       ((shift_uint8
          t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_8)))] 0))
       l_size)))) ->
  (forall i_8 : int. let a_28 = (l_cpu_smt_mask i_8) in
   let a_29 = (shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_28)] 0) in
   (0 <= i_8) -> (i_8 < l_size) ->
   (((valid_rd t a_28 1)) /\ ((valid_rd t a_29 l_size)) /\
    (forall i_9 : int. (0 <= i_9) -> (i_9 < l_size) ->
     ((separated a_29 l_size
        ((shift_uint8
           t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_9)))] 0))
        l_size))))) ->
  (((l_idle_cpu i_5)) = 0)

end

(* ---------------------------------------------------------- *)
(* --- Preservation of Invariant 'i5' (file c11.c, line 150) --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_loop_inv_i5_preserved
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import A_schedule_cpumask.A_schedule_cpumask
use import Compound.Compound
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import Cbits.Cbits

(*
goal WP "expl:Preservation of Invariant 'i5' (file c11.c, line 150)":
*)
goal goal21:
  forall p : bool.
  forall i_7 i_6 i_5 i_4 i_3 i_2 i_1 i : int.
  forall t : map int int.
  forall t_4 t_3 t_2 t_1 : map addr int.
  forall t_5 : map addr addr.
  forall a_1 a : addr.
  let x = (l_idle_cpu i_6) in
  let a_2 = (shiftfield_f5_lb_env_idle a_1) in
  let x_1 = t_3[a_2] in
  let a_3 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_4 = t_5[a_3] in
  let a_5 = (shiftfield_f1_cpumask_bits a_4) in
  let a_6 = t_5[a_5] in
  let a_7 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x_2 = t_3[a_7] in
  let x_3 = t_3[(shift_uint8 a_6 x_2)] in
  let a_8 = (shift_cpumask a i) in
  let a_9 = (shiftfield_f1_cpumask_bits a_8) in
  let a_10 = t_5[a_9] in
  let a_11 = (shift_uint8 a_10 0) in
  let a_12 = (havoc t_2 t_3 a_11 l_size) in
  let a_13 = (shiftfield_f5_lb_env_sd a_1) in
  let a_14 = t_5[a_13] in
  let a_15 = (shiftfield_f3_sched_domain_groups a_14) in
  let a_16 = t_5[a_15] in
  let a_17 = (l_group_balance_mask a_16) in
  let a_18 = t_5[(shiftfield_f1_cpumask_bits a_17)] in
  let a_19 = (shiftfield_f3_sched_domain_flags a_14) in
  let a_20 = (shift_uint8 a_6 0) in
  let a_21 = (havoc t_1 t_3 a_11 l_size) in
  let a_22 = a_12[(shift_uint8 a_10 i_6)] in
  let a_23 = a_12[(shift_uint8 a_6 i_1)] in
  let a_24 = a_12[(shift_uint8 a_6 i_6)] in
  let a_25 = a_12[(shift_uint8 a_18 i_1)] in
  let a_26 = a_12[a_19] in
  let a_27 = (shift_uint8 a_18 0) in
  let x_4 = (to_uint32 i_7) in
  (i_3 <> (-1)) ->
  ((x <> 0) <-> (i_4 <> 0)) ->
  (x_1 <> 2) ->
  (x_3 <> 0) ->
  (a_12[(shift_uint8 a_6 i_5)] <> 0) ->
  (a_12[(shift_uint8 a_18 i_5)] <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= i_5) ->
  (i_3 <= i_5) ->
  (i_5 < l_size) ->
  (0 <= i_6) ->
  (i_5 <= i_6) ->
  (i_6 < l_size) ->
  (0 <= i_7) ->
  (i_7 <= l_size) ->
  (((to_uint32 i_6)) < l_size) ->
  (0 <= x_2) ->
  (x_2 < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_5)) ->
  ((linked t)) ->
  ((is_uint8 i_4)) ->
  ((is_uint32 i)) ->
  ((is_sint32 i_1)) ->
  ((is_sint32 i_2)) ->
  ((is_sint32 i_3)) ->
  ((is_sint32 i_6)) ->
  ((is_sint32 i_7)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 x_1)) ->
  ((is_sint32 (1 + i_6))) ->
  ((is_sint32 x_2)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_7 1)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t a_13 1)) ->
  ((valid_rd t a_8 1)) ->
  ((valid_rd t a_4 1)) ->
  ((valid_rd t t_5[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_14 2)) ->
  ((is_sint32 t_3[a_19])) ->
  ((valid_rd t a_9 1)) ->
  ((valid_rd t a_5 1)) ->
  ((valid_rd t a_15 1)) ->
  ((valid_rd t a_16 1)) ->
  ((valid_rd t a_17 1)) ->
  ((is_uint8 x_3)) ->
  ((valid_rd t a_11 l_size)) ->
  ((valid_rd t a_20 l_size)) ->
  ((valid_rw t a_11 l_size)) ->
  ((is_uint8 a_21[(shift_uint8 a_6 (-1))])) ->
  ((is_uint8 a_21[(shift_uint8 a_18 (-1))])) ->
  ((is_uint8 a_22)) ->
  ((is_uint8 a_23)) ->
  ((is_uint8 a_12[(shift_uint8 a_6 i_3)])) ->
  ((is_uint8 a_24)) ->
  ((is_uint8 a_25)) ->
  ((is_uint8 a_12[(shift_uint8 a_18 i_3)])) ->
  ((is_sint32 a_21[a_19])) ->
  ((is_sint32 a_26)) ->
  ((valid_rd t a_27 l_size)) ->
  ((separated a_11 l_size a_27 l_size)) ->
  (if (i_4 = 0) then ((i_3 = i_1) /\ (i_6 <= 2147483646))
   else ((p=False) /\ (i_2 = i_1) /\ (x <> 0) /\
         (((land 7 t_4[a_19])) = 0) /\ (a_12 = t_4) /\ (i_6 <= 2147483646) /\
         (not (p_idle_core t_5 t_4 i_6)) /\ ((valid_rd t a_19 1)) /\
         (if (i_2 = (-1)) then (i_6 = i_3) else (i_3 = i_2)))) ->
  ((((land 7 a_26)) <> 0) -> (i_1 = (-1))) ->
  ((i_1 <> (-1)) ->
   ((((l_idle_cpu i_1)) <> 0) /\ (a_23 <> 0) /\ (a_25 <> 0) /\ (0 <= i_1) /\
    (i_1 < l_size))) ->
  ((i_1 = (-1)) ->
   (forall i_8 : int. (a_12[(shift_uint8 a_18 i_8)] <> 0) -> (0 <= i_8) ->
    (i_8 < l_size) -> (a_12[(shift_uint8 a_10 i_8)] <> 0))) ->
  ((exists i_8 : int. (a_12[(shift_uint8 a_10 i_8)] <> 0) /\
    (a_12[(shift_uint8 a_6 i_8)] <> 0) /\ (i_8 < l_size) /\ (x_4 <= i_8)) ->
   (x_4 <= i_6)) ->
  ((exists i_8 : int. (a_12[(shift_uint8 a_10 i_8)] <> 0) /\
    (a_12[(shift_uint8 a_6 i_8)] <> 0) /\ (i_8 < l_size) /\ (x_4 <= i_8)) ->
   ((a_22 <> 0) /\ (a_24 <> 0))) ->
  ((forall i_8 : int. (i_8 < l_size) -> (x_4 <= i_8) ->
    ((a_12[(shift_uint8 a_10 i_8)] = 0) \/ (a_12[(shift_uint8 a_6 i_8)] = 0))) ->
   (l_size = i_6)) ->
  ((i_1 <> (-1)) ->
   (forall i_8 : int. (a_12[(shift_uint8 a_6 i_8)] <> 0) ->
    (a_12[(shift_uint8 a_18 i_8)] <> 0) -> (0 <= i_8) -> (i_8 < i_1) ->
    (i_8 < l_size) -> (((l_idle_cpu i_8)) = 0))) ->
  ((i_1 = (-1)) ->
   (forall i_8 : int. (a_12[(shift_uint8 a_6 i_8)] <> 0) ->
    (a_12[(shift_uint8 a_18 i_8)] <> 0) -> (0 <= i_8) -> (i_8 < i_7) ->
    (i_8 < l_size) -> (((l_idle_cpu i_8)) = 0))) ->
  ((exists i_8 : int. (a_12[(shift_uint8 a_10 i_8)] <> 0) /\
    (a_12[(shift_uint8 a_6 i_8)] <> 0) /\ (i_8 < l_size) /\ (x_4 <= i_8)) ->
   (forall i_8 : int. (i_8 < i_6) -> (x_4 <= i_8) ->
    ((a_12[(shift_uint8 a_10 i_8)] = 0) \/ (a_12[(shift_uint8 a_6 i_8)] = 0)))) ->
  ((i_1 <> (-1)) ->
   (forall i_8 : int. (a_12[(shift_uint8 a_6 i_8)] <> 0) ->
    (a_12[(shift_uint8 a_18 i_8)] <> 0) -> (0 <= i_8) -> (i_1 <= i_8) ->
    (i_8 < i_7) -> (i_8 < l_size) -> (not (p_idle_core t_5 a_12 i_8)))) ->
  ((i_1 <> (-1)) ->
   (forall i_8 : int. (a_12[(shift_uint8 a_18 i_8)] <> 0) -> (0 <= i_8) ->
    (i_8 < l_size) ->
    ((a_12[(shift_uint8 a_10 i_8)] <> 0) \/ (not (p_idle_core t_5 a_12 i_8))))) ->
  ((i_4 = 0) \/ (i_4 = 1)) ->
  (forall i_8 : int. (0 <= i_8) -> (i_8 < l_size) ->
   ((separated a_20 l_size
      ((shift_uint8 t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_8)))]
         0)) l_size))) ->
  (forall i_8 : int. let a_28 = (shift_cpumask a i_8) in (0 <= i_8) ->
   (i_8 < l_size) ->
   (((valid_rd t a_28 1)) /\
    ((valid_rw t ((shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_28)] 0))
       l_size)))) ->
  (forall i_8 : int. (0 <= i_8) -> (i_8 < l_size) ->
   ((a_21[(shift_uint8 a_18 i_8)] <> 0) <->
    (a_21[(shift_uint8 a_10 i_8)] <> 0))) ->
  (forall i_8 : int. (a_12[(shift_uint8 a_10 i_8)] <> 0) -> (0 <= i_8) ->
   (i_8 < l_size) -> (a_12[(shift_uint8 a_18 i_8)] <> 0)) ->
  (forall a_28 : addr. let a_29 = (l_sched_group_cpus a_28) in
   let a_30 = (shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_29)] 0) in
   ((valid_rd t a_29 1)) /\ ((valid_rd t a_30 l_size)) /\
   (forall i_8 : int. (0 <= i_8) -> (i_8 < l_size) ->
    ((separated a_30 l_size
       ((shift_uint8
          t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_8)))] 0))
       l_size)))) ->
  (forall a_28 : addr. let a_29 = (l_sched_group_mask a_28) in
   let a_30 = (shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_29)] 0) in
   ((valid_rd t a_29 1)) /\ ((valid_rd t a_30 l_size)) /\
   (forall i_8 : int. (0 <= i_8) -> (i_8 < l_size) ->
    ((separated a_30 l_size
       ((shift_uint8
          t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_8)))] 0))
       l_size)))) ->
  (forall a_28 : addr. let a_29 = (l_group_balance_mask a_28) in
   let a_30 = (shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_29)] 0) in
   ((valid_rd t a_29 1)) /\ ((valid_rd t a_30 l_size)) /\
   (forall i_8 : int. (0 <= i_8) -> (i_8 < l_size) ->
    ((separated a_30 l_size
       ((shift_uint8
          t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_8)))] 0))
       l_size)))) ->
  (forall i_8 : int. let a_28 = (l_cpu_smt_mask i_8) in
   let a_29 = (shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_28)] 0) in
   (0 <= i_8) -> (i_8 < l_size) ->
   (((valid_rd t a_28 1)) /\ ((valid_rd t a_29 l_size)) /\
    (forall i_9 : int. (0 <= i_9) -> (i_9 < l_size) ->
     ((separated a_29 l_size
        ((shift_uint8
           t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_9)))] 0))
        l_size))))) ->
  (not (p_idle_core t_5 a_12 i_5))

end

(* ---------------------------------------------------------- *)
(* --- Assertion 'rte,mem_access' (file c11.c, line 156)  --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_assert_rte_mem_access_10
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import Compound.Compound
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import A_schedule_cpumask.A_schedule_cpumask
use import Cbits.Cbits

(*
goal WP "expl:Assertion 'rte,mem_access' (file c11.c, line 156)":
*)
goal goal22:
  forall i_2 i_1 i : int.
  forall t : map int int.
  forall t_3 t_2 t_1 : map addr int.
  forall t_4 : map addr addr.
  forall a_1 a : addr.
  let a_2 = (shiftfield_f5_lb_env_idle a_1) in
  let x = t_3[a_2] in
  let a_3 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_4 = t_4[a_3] in
  let a_5 = t_4[(shiftfield_f1_cpumask_bits a_4)] in
  let a_6 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x_1 = t_3[a_6] in
  let x_2 = t_3[(shift_uint8 a_5 x_1)] in
  let a_7 = (shiftfield_f5_lb_env_sd a_1) in
  let a_8 = (shift_cpumask a i) in
  let a_9 = t_4[a_7] in
  let a_10 = (shiftfield_f3_sched_domain_flags a_9) in
  let a_11 = (shiftfield_f3_sched_domain_groups a_9) in
  let a_12 = t_4[a_11] in
  let a_13 = (l_group_balance_mask a_12) in
  let a_14 = (shift_uint8 a_5 0) in
  let a_15 = (shiftfield_f1_cpumask_bits a_8) in
  let a_16 = t_4[a_15] in
  let a_17 = (shift_uint8 a_16 0) in
  let a_18 = (havoc t_1 t_3 a_17 l_size) in
  let a_19 = t_4[(shiftfield_f1_cpumask_bits a_13)] in
  let a_20 = (havoc t_2 t_3 a_17 l_size) in
  let a_21 = a_20[(shift_uint8 a_5 i_1)] in
  let a_22 = a_20[(shift_uint8 a_19 i_1)] in
  let a_23 = a_20[a_10] in
  let a_24 = (shift_uint8 a_19 0) in
  (x <> 2) ->
  (x_2 <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= i_2) ->
  (i_2 <= l_size) ->
  (0 <= x_1) ->
  (x_1 < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_4)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((is_sint32 i_1)) ->
  ((is_sint32 i_2)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 x)) ->
  ((is_sint32 x_1)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_6 1)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t a_7 1)) ->
  ((valid_rd t a_8 1)) ->
  ((valid_rd t a_4 1)) ->
  ((valid_rd t t_4[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_9 2)) ->
  ((is_sint32 t_3[a_10])) ->
  ((valid_rd t a_11 1)) ->
  ((valid_rd t a_12 1)) ->
  ((valid_rd t a_13 1)) ->
  ((is_uint8 x_2)) ->
  ((valid_rd t a_14 l_size)) ->
  ((valid_rw t a_17 l_size)) ->
  ((is_uint8 a_18[(shift_uint8 a_5 (-1))])) ->
  ((is_uint8 a_18[(shift_uint8 a_19 (-1))])) ->
  ((is_uint8 a_21)) ->
  ((is_uint8 a_22)) ->
  ((is_sint32 a_18[a_10])) ->
  ((is_sint32 a_23)) ->
  ((valid_rd t a_24 l_size)) ->
  ((separated a_17 l_size a_24 l_size)) ->
  ((((land 7 a_23)) <> 0) -> (i_1 = (-1))) ->
  ((i_1 <> (-1)) ->
   ((((l_idle_cpu i_1)) <> 0) /\ (a_21 <> 0) /\ (a_22 <> 0) /\ (0 <= i_1) /\
    (i_1 < l_size))) ->
  ((i_1 = (-1)) ->
   (forall i_3 : int. (a_20[(shift_uint8 a_19 i_3)] <> 0) -> (0 <= i_3) ->
    (i_3 < l_size) -> (a_20[(shift_uint8 a_16 i_3)] <> 0))) ->
  ((i_1 <> (-1)) ->
   (forall i_3 : int. (a_20[(shift_uint8 a_5 i_3)] <> 0) ->
    (a_20[(shift_uint8 a_19 i_3)] <> 0) -> (0 <= i_3) -> (i_3 < i_1) ->
    (i_3 < l_size) -> (((l_idle_cpu i_3)) = 0))) ->
  ((i_1 = (-1)) ->
   (forall i_3 : int. (a_20[(shift_uint8 a_5 i_3)] <> 0) ->
    (a_20[(shift_uint8 a_19 i_3)] <> 0) -> (0 <= i_3) -> (i_3 < i_2) ->
    (i_3 < l_size) -> (((l_idle_cpu i_3)) = 0))) ->
  ((i_1 <> (-1)) ->
   (forall i_3 : int. (a_20[(shift_uint8 a_5 i_3)] <> 0) ->
    (a_20[(shift_uint8 a_19 i_3)] <> 0) -> (0 <= i_3) -> (i_1 <= i_3) ->
    (i_3 < i_2) -> (i_3 < l_size) -> (not (p_idle_core t_4 a_20 i_3)))) ->
  ((i_1 <> (-1)) ->
   (forall i_3 : int. (a_20[(shift_uint8 a_19 i_3)] <> 0) -> (0 <= i_3) ->
    (i_3 < l_size) ->
    ((a_20[(shift_uint8 a_16 i_3)] <> 0) \/ (not (p_idle_core t_4 a_20 i_3))))) ->
  (forall i_3 : int. (0 <= i_3) -> (i_3 < l_size) ->
   ((separated a_14 l_size
      ((shift_uint8 t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_3)))]
         0)) l_size))) ->
  (forall i_3 : int. let a_25 = (shift_cpumask a i_3) in (0 <= i_3) ->
   (i_3 < l_size) ->
   (((valid_rd t a_25 1)) /\
    ((valid_rw t ((shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_25)] 0))
       l_size)))) ->
  (forall i_3 : int. (0 <= i_3) -> (i_3 < l_size) ->
   ((a_18[(shift_uint8 a_19 i_3)] <> 0) <->
    (a_18[(shift_uint8 a_16 i_3)] <> 0))) ->
  (forall i_3 : int. (a_20[(shift_uint8 a_16 i_3)] <> 0) -> (0 <= i_3) ->
   (i_3 < l_size) -> (a_20[(shift_uint8 a_19 i_3)] <> 0)) ->
  (forall a_25 : addr. let a_26 = (l_sched_group_cpus a_25) in
   let a_27 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_26)] 0) in
   ((valid_rd t a_26 1)) /\ ((valid_rd t a_27 l_size)) /\
   (forall i_3 : int. (0 <= i_3) -> (i_3 < l_size) ->
    ((separated a_27 l_size
       ((shift_uint8
          t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_3)))] 0))
       l_size)))) ->
  (forall a_25 : addr. let a_26 = (l_sched_group_mask a_25) in
   let a_27 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_26)] 0) in
   ((valid_rd t a_26 1)) /\ ((valid_rd t a_27 l_size)) /\
   (forall i_3 : int. (0 <= i_3) -> (i_3 < l_size) ->
    ((separated a_27 l_size
       ((shift_uint8
          t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_3)))] 0))
       l_size)))) ->
  (forall a_25 : addr. let a_26 = (l_group_balance_mask a_25) in
   let a_27 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_26)] 0) in
   ((valid_rd t a_26 1)) /\ ((valid_rd t a_27 l_size)) /\
   (forall i_3 : int. (0 <= i_3) -> (i_3 < l_size) ->
    ((separated a_27 l_size
       ((shift_uint8
          t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_3)))] 0))
       l_size)))) ->
  (forall i_3 : int. let a_25 = (l_cpu_smt_mask i_3) in
   let a_26 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_25)] 0) in
   (0 <= i_3) -> (i_3 < l_size) ->
   (((valid_rd t a_25 1)) /\ ((valid_rd t a_26 l_size)) /\
    (forall i_4 : int. (0 <= i_4) -> (i_4 < l_size) ->
     ((separated a_26 l_size
        ((shift_uint8
           t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_4)))] 0))
        l_size))))) ->
  ((valid_rd t a_15 1))

end

(* ---------------------------------------------------------- *)
(* --- Assertion 'rte,mem_access' (file c11.c, line 156)  --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_assert_rte_mem_access_12
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import Compound.Compound
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import A_schedule_cpumask.A_schedule_cpumask
use import Cbits.Cbits

(*
goal WP "expl:Assertion 'rte,mem_access' (file c11.c, line 156)":
*)
goal goal23:
  forall i_2 i_1 i : int.
  forall t : map int int.
  forall t_3 t_2 t_1 : map addr int.
  forall t_4 : map addr addr.
  forall a_1 a : addr.
  let a_2 = (shiftfield_f5_lb_env_idle a_1) in
  let x = t_3[a_2] in
  let a_3 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_4 = t_4[a_3] in
  let a_5 = (shiftfield_f1_cpumask_bits a_4) in
  let a_6 = t_4[a_5] in
  let a_7 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x_1 = t_3[a_7] in
  let x_2 = t_3[(shift_uint8 a_6 x_1)] in
  let a_8 = (shiftfield_f5_lb_env_sd a_1) in
  let a_9 = (shift_cpumask a i) in
  let a_10 = t_4[a_8] in
  let a_11 = (shiftfield_f3_sched_domain_flags a_10) in
  let a_12 = (shiftfield_f3_sched_domain_groups a_10) in
  let a_13 = t_4[a_12] in
  let a_14 = (l_group_balance_mask a_13) in
  let a_15 = (shift_uint8 a_6 0) in
  let a_16 = t_4[(shiftfield_f1_cpumask_bits a_9)] in
  let a_17 = (shift_uint8 a_16 0) in
  let a_18 = (havoc t_1 t_3 a_17 l_size) in
  let a_19 = t_4[(shiftfield_f1_cpumask_bits a_14)] in
  let a_20 = (havoc t_2 t_3 a_17 l_size) in
  let a_21 = a_20[(shift_uint8 a_6 i_1)] in
  let a_22 = a_20[(shift_uint8 a_19 i_1)] in
  let a_23 = a_20[a_11] in
  let a_24 = (shift_uint8 a_19 0) in
  (x <> 2) ->
  (x_2 <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= i_2) ->
  (i_2 <= l_size) ->
  (0 <= x_1) ->
  (x_1 < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_4)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((is_sint32 i_1)) ->
  ((is_sint32 i_2)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 x)) ->
  ((is_sint32 x_1)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_7 1)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t a_8 1)) ->
  ((valid_rd t a_9 1)) ->
  ((valid_rd t a_4 1)) ->
  ((valid_rd t t_4[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_10 2)) ->
  ((is_sint32 t_3[a_11])) ->
  ((valid_rd t a_12 1)) ->
  ((valid_rd t a_13 1)) ->
  ((valid_rd t a_14 1)) ->
  ((is_uint8 x_2)) ->
  ((valid_rd t a_15 l_size)) ->
  ((valid_rw t a_17 l_size)) ->
  ((is_uint8 a_18[(shift_uint8 a_6 (-1))])) ->
  ((is_uint8 a_18[(shift_uint8 a_19 (-1))])) ->
  ((is_uint8 a_21)) ->
  ((is_uint8 a_22)) ->
  ((is_sint32 a_18[a_11])) ->
  ((is_sint32 a_23)) ->
  ((valid_rd t a_24 l_size)) ->
  ((separated a_17 l_size a_24 l_size)) ->
  ((((land 7 a_23)) <> 0) -> (i_1 = (-1))) ->
  ((i_1 <> (-1)) ->
   ((((l_idle_cpu i_1)) <> 0) /\ (a_21 <> 0) /\ (a_22 <> 0) /\ (0 <= i_1) /\
    (i_1 < l_size))) ->
  ((i_1 = (-1)) ->
   (forall i_3 : int. (a_20[(shift_uint8 a_19 i_3)] <> 0) -> (0 <= i_3) ->
    (i_3 < l_size) -> (a_20[(shift_uint8 a_16 i_3)] <> 0))) ->
  ((i_1 <> (-1)) ->
   (forall i_3 : int. (a_20[(shift_uint8 a_6 i_3)] <> 0) ->
    (a_20[(shift_uint8 a_19 i_3)] <> 0) -> (0 <= i_3) -> (i_3 < i_1) ->
    (i_3 < l_size) -> (((l_idle_cpu i_3)) = 0))) ->
  ((i_1 = (-1)) ->
   (forall i_3 : int. (a_20[(shift_uint8 a_6 i_3)] <> 0) ->
    (a_20[(shift_uint8 a_19 i_3)] <> 0) -> (0 <= i_3) -> (i_3 < i_2) ->
    (i_3 < l_size) -> (((l_idle_cpu i_3)) = 0))) ->
  ((i_1 <> (-1)) ->
   (forall i_3 : int. (a_20[(shift_uint8 a_6 i_3)] <> 0) ->
    (a_20[(shift_uint8 a_19 i_3)] <> 0) -> (0 <= i_3) -> (i_1 <= i_3) ->
    (i_3 < i_2) -> (i_3 < l_size) -> (not (p_idle_core t_4 a_20 i_3)))) ->
  ((i_1 <> (-1)) ->
   (forall i_3 : int. (a_20[(shift_uint8 a_19 i_3)] <> 0) -> (0 <= i_3) ->
    (i_3 < l_size) ->
    ((a_20[(shift_uint8 a_16 i_3)] <> 0) \/ (not (p_idle_core t_4 a_20 i_3))))) ->
  (forall i_3 : int. (0 <= i_3) -> (i_3 < l_size) ->
   ((separated a_15 l_size
      ((shift_uint8 t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_3)))]
         0)) l_size))) ->
  (forall i_3 : int. let a_25 = (shift_cpumask a i_3) in (0 <= i_3) ->
   (i_3 < l_size) ->
   (((valid_rd t a_25 1)) /\
    ((valid_rw t ((shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_25)] 0))
       l_size)))) ->
  (forall i_3 : int. (0 <= i_3) -> (i_3 < l_size) ->
   ((a_18[(shift_uint8 a_19 i_3)] <> 0) <->
    (a_18[(shift_uint8 a_16 i_3)] <> 0))) ->
  (forall i_3 : int. (a_20[(shift_uint8 a_16 i_3)] <> 0) -> (0 <= i_3) ->
   (i_3 < l_size) -> (a_20[(shift_uint8 a_19 i_3)] <> 0)) ->
  (forall a_25 : addr. let a_26 = (l_sched_group_cpus a_25) in
   let a_27 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_26)] 0) in
   ((valid_rd t a_26 1)) /\ ((valid_rd t a_27 l_size)) /\
   (forall i_3 : int. (0 <= i_3) -> (i_3 < l_size) ->
    ((separated a_27 l_size
       ((shift_uint8
          t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_3)))] 0))
       l_size)))) ->
  (forall a_25 : addr. let a_26 = (l_sched_group_mask a_25) in
   let a_27 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_26)] 0) in
   ((valid_rd t a_26 1)) /\ ((valid_rd t a_27 l_size)) /\
   (forall i_3 : int. (0 <= i_3) -> (i_3 < l_size) ->
    ((separated a_27 l_size
       ((shift_uint8
          t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_3)))] 0))
       l_size)))) ->
  (forall a_25 : addr. let a_26 = (l_group_balance_mask a_25) in
   let a_27 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_26)] 0) in
   ((valid_rd t a_26 1)) /\ ((valid_rd t a_27 l_size)) /\
   (forall i_3 : int. (0 <= i_3) -> (i_3 < l_size) ->
    ((separated a_27 l_size
       ((shift_uint8
          t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_3)))] 0))
       l_size)))) ->
  (forall i_3 : int. let a_25 = (l_cpu_smt_mask i_3) in
   let a_26 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_25)] 0) in
   (0 <= i_3) -> (i_3 < l_size) ->
   (((valid_rd t a_25 1)) /\ ((valid_rd t a_26 l_size)) /\
    (forall i_4 : int. (0 <= i_4) -> (i_4 < l_size) ->
     ((separated a_26 l_size
        ((shift_uint8
           t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_4)))] 0))
        l_size))))) ->
  ((valid_rd t a_5 1))

end

(* ---------------------------------------------------------- *)
(* --- Assertion 'rte,bool_value' (file c11.c, line 157)  --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_assert_rte_bool_value_2
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import A_schedule_cpumask.A_schedule_cpumask
use import Compound.Compound
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import Cbits.Cbits

(*
goal WP "expl:Assertion 'rte,bool_value' (file c11.c, line 157)":
*)
goal goal24:
  forall i_4 i_3 i_2 i_1 i : int.
  forall t : map int int.
  forall t_3 t_2 t_1 : map addr int.
  forall t_4 : map addr addr.
  forall a_1 a : addr.
  let a_2 = (shiftfield_f5_lb_env_idle a_1) in
  let x = t_3[a_2] in
  let a_3 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_4 = t_4[a_3] in
  let a_5 = (shiftfield_f1_cpumask_bits a_4) in
  let a_6 = t_4[a_5] in
  let a_7 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x_1 = t_3[a_7] in
  let x_2 = t_3[(shift_uint8 a_6 x_1)] in
  let a_8 = (shiftfield_f5_lb_env_sd a_1) in
  let a_9 = (shift_cpumask a i_1) in
  let a_10 = t_4[a_8] in
  let a_11 = (shiftfield_f3_sched_domain_flags a_10) in
  let a_12 = (shiftfield_f1_cpumask_bits a_9) in
  let a_13 = (shiftfield_f3_sched_domain_groups a_10) in
  let a_14 = t_4[a_13] in
  let a_15 = (l_group_balance_mask a_14) in
  let a_16 = t_4[a_12] in
  let a_17 = (shift_uint8 a_16 0) in
  let a_18 = (shift_uint8 a_6 0) in
  let a_19 = (havoc t_1 t_3 a_17 l_size) in
  let a_20 = t_4[(shiftfield_f1_cpumask_bits a_15)] in
  let a_21 = (havoc t_2 t_3 a_17 l_size) in
  let a_22 = a_21[(shift_uint8 a_16 i_3)] in
  let a_23 = a_21[(shift_uint8 a_6 i_2)] in
  let a_24 = a_21[(shift_uint8 a_6 i_3)] in
  let a_25 = a_21[(shift_uint8 a_20 i_2)] in
  let a_26 = a_21[a_11] in
  let a_27 = (shift_uint8 a_20 0) in
  let x_3 = (to_uint32 i_4) in
  ((((l_idle_cpu i_3)) <> 0) <-> (i <> 0)) ->
  (x <> 2) ->
  (x_2 <> 0) ->
  (0 <= i_1) ->
  (i_1 < l_size) ->
  (0 <= i_3) ->
  (i_3 < l_size) ->
  (0 <= i_4) ->
  (i_4 <= l_size) ->
  (((to_uint32 i_3)) < l_size) ->
  (0 <= x_1) ->
  (x_1 < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_4)) ->
  ((linked t)) ->
  ((is_uint8 i)) ->
  ((is_uint32 i_1)) ->
  ((is_sint32 i_2)) ->
  ((is_sint32 i_3)) ->
  ((is_sint32 i_4)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 x)) ->
  ((is_sint32 x_1)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_7 1)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t a_8 1)) ->
  ((valid_rd t a_9 1)) ->
  ((valid_rd t a_4 1)) ->
  ((valid_rd t t_4[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_10 2)) ->
  ((is_sint32 t_3[a_11])) ->
  ((valid_rd t a_12 1)) ->
  ((valid_rd t a_5 1)) ->
  ((valid_rd t a_13 1)) ->
  ((valid_rd t a_14 1)) ->
  ((valid_rd t a_15 1)) ->
  ((is_uint8 x_2)) ->
  ((valid_rd t a_17 l_size)) ->
  ((valid_rd t a_18 l_size)) ->
  ((valid_rw t a_17 l_size)) ->
  ((is_uint8 a_19[(shift_uint8 a_6 (-1))])) ->
  ((is_uint8 a_19[(shift_uint8 a_20 (-1))])) ->
  ((is_uint8 a_22)) ->
  ((is_uint8 a_23)) ->
  ((is_uint8 a_24)) ->
  ((is_uint8 a_25)) ->
  ((is_sint32 a_19[a_11])) ->
  ((is_sint32 a_26)) ->
  ((valid_rd t a_27 l_size)) ->
  ((separated a_17 l_size a_27 l_size)) ->
  ((((land 7 a_26)) <> 0) -> (i_2 = (-1))) ->
  ((i_2 <> (-1)) ->
   ((((l_idle_cpu i_2)) <> 0) /\ (a_23 <> 0) /\ (a_25 <> 0) /\ (0 <= i_2) /\
    (i_2 < l_size))) ->
  ((i_2 = (-1)) ->
   (forall i_5 : int. (a_21[(shift_uint8 a_20 i_5)] <> 0) -> (0 <= i_5) ->
    (i_5 < l_size) -> (a_21[(shift_uint8 a_16 i_5)] <> 0))) ->
  ((exists i_5 : int. (a_21[(shift_uint8 a_16 i_5)] <> 0) /\
    (a_21[(shift_uint8 a_6 i_5)] <> 0) /\ (i_5 < l_size) /\ (x_3 <= i_5)) ->
   (x_3 <= i_3)) ->
  ((exists i_5 : int. (a_21[(shift_uint8 a_16 i_5)] <> 0) /\
    (a_21[(shift_uint8 a_6 i_5)] <> 0) /\ (i_5 < l_size) /\ (x_3 <= i_5)) ->
   ((a_22 <> 0) /\ (a_24 <> 0))) ->
  ((forall i_5 : int. (i_5 < l_size) -> (x_3 <= i_5) ->
    ((a_21[(shift_uint8 a_16 i_5)] = 0) \/ (a_21[(shift_uint8 a_6 i_5)] = 0))) ->
   (l_size = i_3)) ->
  ((i_2 <> (-1)) ->
   (forall i_5 : int. (a_21[(shift_uint8 a_6 i_5)] <> 0) ->
    (a_21[(shift_uint8 a_20 i_5)] <> 0) -> (0 <= i_5) -> (i_5 < i_2) ->
    (i_5 < l_size) -> (((l_idle_cpu i_5)) = 0))) ->
  ((i_2 = (-1)) ->
   (forall i_5 : int. (a_21[(shift_uint8 a_6 i_5)] <> 0) ->
    (a_21[(shift_uint8 a_20 i_5)] <> 0) -> (0 <= i_5) -> (i_5 < i_4) ->
    (i_5 < l_size) -> (((l_idle_cpu i_5)) = 0))) ->
  ((exists i_5 : int. (a_21[(shift_uint8 a_16 i_5)] <> 0) /\
    (a_21[(shift_uint8 a_6 i_5)] <> 0) /\ (i_5 < l_size) /\ (x_3 <= i_5)) ->
   (forall i_5 : int. (i_5 < i_3) -> (x_3 <= i_5) ->
    ((a_21[(shift_uint8 a_16 i_5)] = 0) \/ (a_21[(shift_uint8 a_6 i_5)] = 0)))) ->
  ((i_2 <> (-1)) ->
   (forall i_5 : int. (a_21[(shift_uint8 a_6 i_5)] <> 0) ->
    (a_21[(shift_uint8 a_20 i_5)] <> 0) -> (0 <= i_5) -> (i_2 <= i_5) ->
    (i_5 < i_4) -> (i_5 < l_size) -> (not (p_idle_core t_4 a_21 i_5)))) ->
  ((i_2 <> (-1)) ->
   (forall i_5 : int. (a_21[(shift_uint8 a_20 i_5)] <> 0) -> (0 <= i_5) ->
    (i_5 < l_size) ->
    ((a_21[(shift_uint8 a_16 i_5)] <> 0) \/ (not (p_idle_core t_4 a_21 i_5))))) ->
  (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
   ((separated a_18 l_size
      ((shift_uint8 t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_5)))]
         0)) l_size))) ->
  (forall i_5 : int. let a_28 = (shift_cpumask a i_5) in (0 <= i_5) ->
   (i_5 < l_size) ->
   (((valid_rd t a_28 1)) /\
    ((valid_rw t ((shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_28)] 0))
       l_size)))) ->
  (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
   ((a_19[(shift_uint8 a_20 i_5)] <> 0) <->
    (a_19[(shift_uint8 a_16 i_5)] <> 0))) ->
  (forall i_5 : int. (a_21[(shift_uint8 a_16 i_5)] <> 0) -> (0 <= i_5) ->
   (i_5 < l_size) -> (a_21[(shift_uint8 a_20 i_5)] <> 0)) ->
  (forall a_28 : addr. let a_29 = (l_sched_group_cpus a_28) in
   let a_30 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_29)] 0) in
   ((valid_rd t a_29 1)) /\ ((valid_rd t a_30 l_size)) /\
   (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
    ((separated a_30 l_size
       ((shift_uint8
          t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_5)))] 0))
       l_size)))) ->
  (forall a_28 : addr. let a_29 = (l_sched_group_mask a_28) in
   let a_30 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_29)] 0) in
   ((valid_rd t a_29 1)) /\ ((valid_rd t a_30 l_size)) /\
   (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
    ((separated a_30 l_size
       ((shift_uint8
          t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_5)))] 0))
       l_size)))) ->
  (forall a_28 : addr. let a_29 = (l_group_balance_mask a_28) in
   let a_30 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_29)] 0) in
   ((valid_rd t a_29 1)) /\ ((valid_rd t a_30 l_size)) /\
   (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
    ((separated a_30 l_size
       ((shift_uint8
          t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_5)))] 0))
       l_size)))) ->
  (forall i_5 : int. let a_28 = (l_cpu_smt_mask i_5) in
   let a_29 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_28)] 0) in
   (0 <= i_5) -> (i_5 < l_size) ->
   (((valid_rd t a_28 1)) /\ ((valid_rd t a_29 l_size)) /\
    (forall i_6 : int. (0 <= i_6) -> (i_6 < l_size) ->
     ((separated a_29 l_size
        ((shift_uint8
           t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_6)))] 0))
        l_size))))) ->
  ((i = 0) \/ (i = 1))

end

(* ---------------------------------------------------------- *)
(* --- Assertion 'rte,mem_access' (file c11.c, line 170)  --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_assert_rte_mem_access_14
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import A_schedule_cpumask.A_schedule_cpumask
use import Compound.Compound
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import Cbits.Cbits

(*
goal WP "expl:Assertion 'rte,mem_access' (file c11.c, line 170)":
*)
goal goal25:
  forall i_3 i_2 i_1 i : int.
  forall t : map int int.
  forall t_3 t_2 t_1 : map addr int.
  forall t_4 : map addr addr.
  forall a_1 a : addr.
  let a_2 = (shiftfield_f5_lb_env_idle a_1) in
  let x = t_3[a_2] in
  let a_3 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_4 = t_4[a_3] in
  let a_5 = (shiftfield_f1_cpumask_bits a_4) in
  let a_6 = t_4[a_5] in
  let a_7 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x_1 = t_3[a_7] in
  let x_2 = t_3[(shift_uint8 a_6 x_1)] in
  let a_8 = (shiftfield_f5_lb_env_sd a_1) in
  let a_9 = (shift_cpumask a i) in
  let a_10 = t_4[a_8] in
  let a_11 = (shiftfield_f3_sched_domain_flags a_10) in
  let a_12 = (shiftfield_f1_cpumask_bits a_9) in
  let a_13 = (shiftfield_f3_sched_domain_groups a_10) in
  let a_14 = t_4[a_13] in
  let a_15 = (l_group_balance_mask a_14) in
  let a_16 = t_4[a_12] in
  let a_17 = (shift_uint8 a_16 0) in
  let a_18 = (shift_uint8 a_6 0) in
  let a_19 = (havoc t_1 t_3 a_17 l_size) in
  let a_20 = t_4[(shiftfield_f1_cpumask_bits a_15)] in
  let a_21 = (havoc t_2 t_3 a_17 l_size) in
  let a_22 = a_21[(shift_uint8 a_16 i_2)] in
  let a_23 = a_21[(shift_uint8 a_6 i_1)] in
  let a_24 = a_21[(shift_uint8 a_6 i_2)] in
  let a_25 = a_21[(shift_uint8 a_20 i_1)] in
  let a_26 = a_21[a_11] in
  let a_27 = (shift_uint8 a_20 0) in
  let x_3 = (to_uint32 i_3) in
  (((l_idle_cpu i_2)) <> 0) ->
  (x <> 2) ->
  (x_2 <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= i_2) ->
  (i_2 < l_size) ->
  (0 <= i_3) ->
  (i_3 <= l_size) ->
  (((to_uint32 i_2)) < l_size) ->
  (0 <= x_1) ->
  (x_1 < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_4)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((is_sint32 i_1)) ->
  ((is_sint32 i_2)) ->
  ((is_sint32 i_3)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 x)) ->
  ((is_sint32 x_1)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_7 1)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t a_8 1)) ->
  ((valid_rd t a_9 1)) ->
  ((valid_rd t a_4 1)) ->
  ((valid_rd t t_4[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_10 2)) ->
  ((is_sint32 t_3[a_11])) ->
  ((valid_rd t a_12 1)) ->
  ((valid_rd t a_5 1)) ->
  ((valid_rd t a_13 1)) ->
  ((valid_rd t a_14 1)) ->
  ((valid_rd t a_15 1)) ->
  ((is_uint8 x_2)) ->
  ((valid_rd t a_17 l_size)) ->
  ((valid_rd t a_18 l_size)) ->
  ((valid_rw t a_17 l_size)) ->
  ((is_uint8 a_19[(shift_uint8 a_6 (-1))])) ->
  ((is_uint8 a_19[(shift_uint8 a_20 (-1))])) ->
  ((is_uint8 a_22)) ->
  ((is_uint8 a_23)) ->
  ((is_uint8 a_24)) ->
  ((is_uint8 a_25)) ->
  ((is_sint32 a_19[a_11])) ->
  ((is_sint32 a_26)) ->
  ((valid_rd t a_27 l_size)) ->
  ((separated a_17 l_size a_27 l_size)) ->
  ((((land 7 a_26)) <> 0) -> (i_1 = (-1))) ->
  ((i_1 <> (-1)) ->
   ((((l_idle_cpu i_1)) <> 0) /\ (a_23 <> 0) /\ (a_25 <> 0) /\ (0 <= i_1) /\
    (i_1 < l_size))) ->
  ((i_1 = (-1)) ->
   (forall i_4 : int. (a_21[(shift_uint8 a_20 i_4)] <> 0) -> (0 <= i_4) ->
    (i_4 < l_size) -> (a_21[(shift_uint8 a_16 i_4)] <> 0))) ->
  ((exists i_4 : int. (a_21[(shift_uint8 a_16 i_4)] <> 0) /\
    (a_21[(shift_uint8 a_6 i_4)] <> 0) /\ (i_4 < l_size) /\ (x_3 <= i_4)) ->
   (x_3 <= i_2)) ->
  ((exists i_4 : int. (a_21[(shift_uint8 a_16 i_4)] <> 0) /\
    (a_21[(shift_uint8 a_6 i_4)] <> 0) /\ (i_4 < l_size) /\ (x_3 <= i_4)) ->
   ((a_22 <> 0) /\ (a_24 <> 0))) ->
  ((forall i_4 : int. (i_4 < l_size) -> (x_3 <= i_4) ->
    ((a_21[(shift_uint8 a_16 i_4)] = 0) \/ (a_21[(shift_uint8 a_6 i_4)] = 0))) ->
   (l_size = i_2)) ->
  ((i_1 <> (-1)) ->
   (forall i_4 : int. (a_21[(shift_uint8 a_6 i_4)] <> 0) ->
    (a_21[(shift_uint8 a_20 i_4)] <> 0) -> (0 <= i_4) -> (i_4 < i_1) ->
    (i_4 < l_size) -> (((l_idle_cpu i_4)) = 0))) ->
  ((i_1 = (-1)) ->
   (forall i_4 : int. (a_21[(shift_uint8 a_6 i_4)] <> 0) ->
    (a_21[(shift_uint8 a_20 i_4)] <> 0) -> (0 <= i_4) -> (i_4 < i_3) ->
    (i_4 < l_size) -> (((l_idle_cpu i_4)) = 0))) ->
  ((exists i_4 : int. (a_21[(shift_uint8 a_16 i_4)] <> 0) /\
    (a_21[(shift_uint8 a_6 i_4)] <> 0) /\ (i_4 < l_size) /\ (x_3 <= i_4)) ->
   (forall i_4 : int. (i_4 < i_2) -> (x_3 <= i_4) ->
    ((a_21[(shift_uint8 a_16 i_4)] = 0) \/ (a_21[(shift_uint8 a_6 i_4)] = 0)))) ->
  ((i_1 <> (-1)) ->
   (forall i_4 : int. (a_21[(shift_uint8 a_6 i_4)] <> 0) ->
    (a_21[(shift_uint8 a_20 i_4)] <> 0) -> (0 <= i_4) -> (i_1 <= i_4) ->
    (i_4 < i_3) -> (i_4 < l_size) -> (not (p_idle_core t_4 a_21 i_4)))) ->
  ((i_1 <> (-1)) ->
   (forall i_4 : int. (a_21[(shift_uint8 a_20 i_4)] <> 0) -> (0 <= i_4) ->
    (i_4 < l_size) ->
    ((a_21[(shift_uint8 a_16 i_4)] <> 0) \/ (not (p_idle_core t_4 a_21 i_4))))) ->
  (forall i_4 : int. (0 <= i_4) -> (i_4 < l_size) ->
   ((separated a_18 l_size
      ((shift_uint8 t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_4)))]
         0)) l_size))) ->
  (forall i_4 : int. let a_28 = (shift_cpumask a i_4) in (0 <= i_4) ->
   (i_4 < l_size) ->
   (((valid_rd t a_28 1)) /\
    ((valid_rw t ((shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_28)] 0))
       l_size)))) ->
  (forall i_4 : int. (0 <= i_4) -> (i_4 < l_size) ->
   ((a_19[(shift_uint8 a_20 i_4)] <> 0) <->
    (a_19[(shift_uint8 a_16 i_4)] <> 0))) ->
  (forall i_4 : int. (a_21[(shift_uint8 a_16 i_4)] <> 0) -> (0 <= i_4) ->
   (i_4 < l_size) -> (a_21[(shift_uint8 a_20 i_4)] <> 0)) ->
  (forall a_28 : addr. let a_29 = (l_sched_group_cpus a_28) in
   let a_30 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_29)] 0) in
   ((valid_rd t a_29 1)) /\ ((valid_rd t a_30 l_size)) /\
   (forall i_4 : int. (0 <= i_4) -> (i_4 < l_size) ->
    ((separated a_30 l_size
       ((shift_uint8
          t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_4)))] 0))
       l_size)))) ->
  (forall a_28 : addr. let a_29 = (l_sched_group_mask a_28) in
   let a_30 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_29)] 0) in
   ((valid_rd t a_29 1)) /\ ((valid_rd t a_30 l_size)) /\
   (forall i_4 : int. (0 <= i_4) -> (i_4 < l_size) ->
    ((separated a_30 l_size
       ((shift_uint8
          t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_4)))] 0))
       l_size)))) ->
  (forall a_28 : addr. let a_29 = (l_group_balance_mask a_28) in
   let a_30 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_29)] 0) in
   ((valid_rd t a_29 1)) /\ ((valid_rd t a_30 l_size)) /\
   (forall i_4 : int. (0 <= i_4) -> (i_4 < l_size) ->
    ((separated a_30 l_size
       ((shift_uint8
          t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_4)))] 0))
       l_size)))) ->
  (forall i_4 : int. let a_28 = (l_cpu_smt_mask i_4) in
   let a_29 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_28)] 0) in
   (0 <= i_4) -> (i_4 < l_size) ->
   (((valid_rd t a_28 1)) /\ ((valid_rd t a_29 l_size)) /\
    (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
     ((separated a_29 l_size
        ((shift_uint8
           t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_5)))] 0))
        l_size))))) ->
  ((valid_rd t a_11 1))

end

(* ---------------------------------------------------------- *)
(* --- Assertion 'rte,bool_value' (file c11.c, line 170)  --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_assert_rte_bool_value_3
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import A_schedule_cpumask.A_schedule_cpumask
use import Compound.Compound
use import Cint.Cint
use import Cbits.Cbits
use import A_thread_variables_properties.A_thread_variables_properties

(*
goal WP "expl:Assertion 'rte,bool_value' (file c11.c, line 170)":
*)
goal goal26:
  forall i_4 i_3 i_2 i_1 i : int.
  forall t : map int int.
  forall t_3 t_2 t_1 : map addr int.
  forall t_4 : map addr addr.
  forall a_1 a : addr.
  let a_2 = (shiftfield_f5_lb_env_idle a_1) in
  let x = t_3[a_2] in
  let a_3 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_4 = t_4[a_3] in
  let a_5 = (shiftfield_f1_cpumask_bits a_4) in
  let a_6 = t_4[a_5] in
  let a_7 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x_1 = t_3[a_7] in
  let x_2 = t_3[(shift_uint8 a_6 x_1)] in
  let a_8 = (shift_cpumask a i_1) in
  let a_9 = (shiftfield_f1_cpumask_bits a_8) in
  let a_10 = t_4[a_9] in
  let a_11 = (shift_uint8 a_10 0) in
  let a_12 = (havoc t_2 t_3 a_11 l_size) in
  let a_13 = (shiftfield_f5_lb_env_sd a_1) in
  let a_14 = t_4[a_13] in
  let a_15 = (shiftfield_f3_sched_domain_flags a_14) in
  let a_16 = a_12[a_15] in
  let a_17 = (shiftfield_f3_sched_domain_groups a_14) in
  let a_18 = t_4[a_17] in
  let a_19 = (l_group_balance_mask a_18) in
  let a_20 = (shift_uint8 a_6 0) in
  let a_21 = (havoc t_1 t_3 a_11 l_size) in
  let a_22 = t_4[(shiftfield_f1_cpumask_bits a_19)] in
  let a_23 = a_12[(shift_uint8 a_10 i_3)] in
  let a_24 = a_12[(shift_uint8 a_6 i_2)] in
  let a_25 = a_12[(shift_uint8 a_6 i_3)] in
  let a_26 = a_12[(shift_uint8 a_22 i_2)] in
  let a_27 = (shift_uint8 a_22 0) in
  let x_3 = (to_uint32 i_4) in
  (((l_idle_cpu i_3)) <> 0) ->
  (x <> 2) ->
  (x_2 <> 0) ->
  (((land 7 a_16)) = 0) ->
  (((p_idle_core t_4 a_12 i_3)) <-> (i <> 0)) ->
  (0 <= i_1) ->
  (i_1 < l_size) ->
  (0 <= i_3) ->
  (i_3 < l_size) ->
  (0 <= i_4) ->
  (i_4 <= l_size) ->
  (((to_uint32 i_3)) < l_size) ->
  (0 <= x_1) ->
  (x_1 < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_4)) ->
  ((linked t)) ->
  ((is_uint8 i)) ->
  ((is_uint32 i_1)) ->
  ((is_sint32 i_2)) ->
  ((is_sint32 i_3)) ->
  ((is_sint32 i_4)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 x)) ->
  ((is_sint32 x_1)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_7 1)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t a_13 1)) ->
  ((valid_rd t a_8 1)) ->
  ((valid_rd t a_4 1)) ->
  ((valid_rd t t_4[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_14 2)) ->
  ((is_sint32 t_3[a_15])) ->
  ((valid_rd t a_9 1)) ->
  ((valid_rd t a_5 1)) ->
  ((valid_rd t a_15 1)) ->
  ((valid_rd t a_17 1)) ->
  ((valid_rd t a_18 1)) ->
  ((valid_rd t a_19 1)) ->
  ((is_uint8 x_2)) ->
  ((valid_rd t a_11 l_size)) ->
  ((valid_rd t a_20 l_size)) ->
  ((valid_rw t a_11 l_size)) ->
  ((is_uint8 a_21[(shift_uint8 a_6 (-1))])) ->
  ((is_uint8 a_21[(shift_uint8 a_22 (-1))])) ->
  ((is_uint8 a_23)) ->
  ((is_uint8 a_24)) ->
  ((is_uint8 a_25)) ->
  ((is_uint8 a_26)) ->
  ((is_sint32 a_21[a_15])) ->
  ((is_sint32 a_16)) ->
  ((valid_rd t a_27 l_size)) ->
  ((separated a_11 l_size a_27 l_size)) ->
  ((i_2 <> (-1)) ->
   ((((l_idle_cpu i_2)) <> 0) /\ (a_24 <> 0) /\ (a_26 <> 0) /\ (0 <= i_2) /\
    (i_2 < l_size))) ->
  ((i_2 = (-1)) ->
   (forall i_5 : int. (a_12[(shift_uint8 a_22 i_5)] <> 0) -> (0 <= i_5) ->
    (i_5 < l_size) -> (a_12[(shift_uint8 a_10 i_5)] <> 0))) ->
  ((exists i_5 : int. (a_12[(shift_uint8 a_10 i_5)] <> 0) /\
    (a_12[(shift_uint8 a_6 i_5)] <> 0) /\ (i_5 < l_size) /\ (x_3 <= i_5)) ->
   (x_3 <= i_3)) ->
  ((exists i_5 : int. (a_12[(shift_uint8 a_10 i_5)] <> 0) /\
    (a_12[(shift_uint8 a_6 i_5)] <> 0) /\ (i_5 < l_size) /\ (x_3 <= i_5)) ->
   ((a_23 <> 0) /\ (a_25 <> 0))) ->
  ((forall i_5 : int. (i_5 < l_size) -> (x_3 <= i_5) ->
    ((a_12[(shift_uint8 a_10 i_5)] = 0) \/ (a_12[(shift_uint8 a_6 i_5)] = 0))) ->
   (l_size = i_3)) ->
  ((i_2 <> (-1)) ->
   (forall i_5 : int. (a_12[(shift_uint8 a_6 i_5)] <> 0) ->
    (a_12[(shift_uint8 a_22 i_5)] <> 0) -> (0 <= i_5) -> (i_5 < i_2) ->
    (i_5 < l_size) -> (((l_idle_cpu i_5)) = 0))) ->
  ((i_2 = (-1)) ->
   (forall i_5 : int. (a_12[(shift_uint8 a_6 i_5)] <> 0) ->
    (a_12[(shift_uint8 a_22 i_5)] <> 0) -> (0 <= i_5) -> (i_5 < i_4) ->
    (i_5 < l_size) -> (((l_idle_cpu i_5)) = 0))) ->
  ((exists i_5 : int. (a_12[(shift_uint8 a_10 i_5)] <> 0) /\
    (a_12[(shift_uint8 a_6 i_5)] <> 0) /\ (i_5 < l_size) /\ (x_3 <= i_5)) ->
   (forall i_5 : int. (i_5 < i_3) -> (x_3 <= i_5) ->
    ((a_12[(shift_uint8 a_10 i_5)] = 0) \/ (a_12[(shift_uint8 a_6 i_5)] = 0)))) ->
  ((i_2 <> (-1)) ->
   (forall i_5 : int. (a_12[(shift_uint8 a_6 i_5)] <> 0) ->
    (a_12[(shift_uint8 a_22 i_5)] <> 0) -> (0 <= i_5) -> (i_2 <= i_5) ->
    (i_5 < i_4) -> (i_5 < l_size) -> (not (p_idle_core t_4 a_12 i_5)))) ->
  ((i_2 <> (-1)) ->
   (forall i_5 : int. (a_12[(shift_uint8 a_22 i_5)] <> 0) -> (0 <= i_5) ->
    (i_5 < l_size) ->
    ((a_12[(shift_uint8 a_10 i_5)] <> 0) \/ (not (p_idle_core t_4 a_12 i_5))))) ->
  (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
   ((separated a_20 l_size
      ((shift_uint8 t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_5)))]
         0)) l_size))) ->
  (forall i_5 : int. let a_28 = (shift_cpumask a i_5) in (0 <= i_5) ->
   (i_5 < l_size) ->
   (((valid_rd t a_28 1)) /\
    ((valid_rw t ((shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_28)] 0))
       l_size)))) ->
  (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
   ((a_21[(shift_uint8 a_22 i_5)] <> 0) <->
    (a_21[(shift_uint8 a_10 i_5)] <> 0))) ->
  (forall i_5 : int. (a_12[(shift_uint8 a_10 i_5)] <> 0) -> (0 <= i_5) ->
   (i_5 < l_size) -> (a_12[(shift_uint8 a_22 i_5)] <> 0)) ->
  (forall a_28 : addr. let a_29 = (l_sched_group_cpus a_28) in
   let a_30 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_29)] 0) in
   ((valid_rd t a_29 1)) /\ ((valid_rd t a_30 l_size)) /\
   (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
    ((separated a_30 l_size
       ((shift_uint8
          t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_5)))] 0))
       l_size)))) ->
  (forall a_28 : addr. let a_29 = (l_sched_group_mask a_28) in
   let a_30 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_29)] 0) in
   ((valid_rd t a_29 1)) /\ ((valid_rd t a_30 l_size)) /\
   (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
    ((separated a_30 l_size
       ((shift_uint8
          t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_5)))] 0))
       l_size)))) ->
  (forall a_28 : addr. let a_29 = (l_group_balance_mask a_28) in
   let a_30 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_29)] 0) in
   ((valid_rd t a_29 1)) /\ ((valid_rd t a_30 l_size)) /\
   (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
    ((separated a_30 l_size
       ((shift_uint8
          t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_5)))] 0))
       l_size)))) ->
  (forall i_5 : int. let a_28 = (l_cpu_smt_mask i_5) in
   let a_29 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_28)] 0) in
   (0 <= i_5) -> (i_5 < l_size) ->
   (((valid_rd t a_28 1)) /\ ((valid_rd t a_29 l_size)) /\
    (forall i_6 : int. (0 <= i_6) -> (i_6 < l_size) ->
     ((separated a_29 l_size
        ((shift_uint8
           t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_6)))] 0))
        l_size))))) ->
  ((i = 0) \/ (i = 1))

end

(* ---------------------------------------------------------- *)
(* --- Assertion 'rte,signed_overflow' (file c11.c, line 156) --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_assert_rte_signed_overflow
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import A_schedule_cpumask.A_schedule_cpumask
use import Compound.Compound
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import Cbits.Cbits

(*
goal WP "expl:Assertion 'rte,signed_overflow' (file c11.c, line 156)":
*)
goal goal27:
  forall p_1 p : bool.
  forall i_5 i_4 i_3 i_2 i_1 i : int.
  forall t : map int int.
  forall t_4 t_3 t_2 t_1 : map addr int.
  forall t_5 : map addr addr.
  forall a_2 a_1 a : addr.
  let x = (l_idle_cpu i_4) in
  let a_3 = (shiftfield_f5_lb_env_idle a_1) in
  let x_1 = t_3[a_3] in
  let a_4 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_5 = t_5[a_4] in
  let a_6 = (shiftfield_f1_cpumask_bits a_5) in
  let a_7 = t_5[a_6] in
  let a_8 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x_2 = t_3[a_8] in
  let x_3 = t_3[(shift_uint8 a_7 x_2)] in
  let a_9 = (shiftfield_f5_lb_env_sd a_1) in
  let a_10 = (shift_cpumask a i) in
  let a_11 = t_5[a_9] in
  let a_12 = (shiftfield_f3_sched_domain_flags a_11) in
  let a_13 = (shiftfield_f5_lb_env_sd a_2) in
  let a_14 = (shiftfield_f3_sched_domain_flags t_5[a_13]) in
  let x_4 = t_4[a_14] in
  let a_15 = (shiftfield_f1_cpumask_bits a_10) in
  let a_16 = (shiftfield_f3_sched_domain_groups a_11) in
  let a_17 = t_5[a_16] in
  let a_18 = (l_group_balance_mask a_17) in
  let a_19 = t_5[a_15] in
  let a_20 = (shift_uint8 a_19 0) in
  let a_21 = (shift_uint8 a_7 0) in
  let a_22 = (havoc t_1 t_3 a_20 l_size) in
  let a_23 = t_5[(shiftfield_f1_cpumask_bits a_18)] in
  let a_24 = (havoc t_2 t_3 a_20 l_size) in
  let a_25 = a_24[(shift_uint8 a_19 i_4)] in
  let a_26 = a_24[(shift_uint8 a_7 i_1)] in
  let a_27 = a_24[(shift_uint8 a_7 i_4)] in
  let a_28 = a_24[(shift_uint8 a_23 i_1)] in
  let a_29 = a_24[a_12] in
  let a_30 = (shift_uint8 a_23 0) in
  let x_5 = (to_uint32 i_5) in
  ((x <> 0) <-> (i_2 <> 0)) ->
  (x_1 <> 2) ->
  (x_3 <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= i_4) ->
  (i_4 < l_size) ->
  (0 <= i_5) ->
  (i_5 <= l_size) ->
  (((to_uint32 i_4)) < l_size) ->
  (0 <= x_2) ->
  (x_2 < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_5)) ->
  ((linked t)) ->
  ((is_uint8 i_2)) ->
  ((is_uint32 i)) ->
  ((is_sint32 i_1)) ->
  ((is_sint32 i_3)) ->
  ((is_sint32 i_4)) ->
  ((is_sint32 i_5)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 x_1)) ->
  ((is_sint32 x_2)) ->
  ((valid_rd t a_4 1)) ->
  ((valid_rd t a_8 1)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_9 1)) ->
  ((valid_rd t a_10 1)) ->
  ((valid_rd t a_5 1)) ->
  ((valid_rd t t_5[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_11 2)) ->
  ((is_sint32 t_3[a_12])) ->
  ((is_sint32 x_4)) ->
  ((valid_rd t a_15 1)) ->
  ((valid_rd t a_6 1)) ->
  ((valid_rd t a_16 1)) ->
  ((valid_rd t a_17 1)) ->
  ((valid_rd t a_18 1)) ->
  ((is_uint8 x_3)) ->
  ((valid_rd t a_20 l_size)) ->
  ((valid_rd t a_21 l_size)) ->
  ((valid_rw t a_20 l_size)) ->
  ((is_uint8 a_22[(shift_uint8 a_7 (-1))])) ->
  ((is_uint8 a_22[(shift_uint8 a_23 (-1))])) ->
  ((is_uint8 a_25)) ->
  ((is_uint8 a_26)) ->
  ((is_uint8 a_27)) ->
  ((is_uint8 a_28)) ->
  ((is_sint32 a_22[a_12])) ->
  ((is_sint32 a_29)) ->
  ((valid_rd t a_30 l_size)) ->
  ((separated a_20 l_size a_30 l_size)) ->
  (if (i_2 = 0) then ((p_1=False) /\ (i_4 = i_3))
   else ((p=False) /\ (p_1=True) /\ (a_2 = a_1) /\ (x <> 0) /\
         (((land 7 x_4)) = 0) /\ (a_24 = t_4) /\
         (not (p_idle_core t_5 t_4 i_4)) /\ ((valid_rd t a_13 1)) /\
         ((valid_rd t a_14 1)))) ->
  ((((land 7 a_29)) <> 0) -> (i_1 = (-1))) ->
  ((i_1 <> (-1)) ->
   ((((l_idle_cpu i_1)) <> 0) /\ (a_26 <> 0) /\ (a_28 <> 0) /\ (0 <= i_1) /\
    (i_1 < l_size))) ->
  ((i_1 = (-1)) ->
   (forall i_6 : int. (a_24[(shift_uint8 a_23 i_6)] <> 0) -> (0 <= i_6) ->
    (i_6 < l_size) -> (a_24[(shift_uint8 a_19 i_6)] <> 0))) ->
  ((exists i_6 : int. (a_24[(shift_uint8 a_19 i_6)] <> 0) /\
    (a_24[(shift_uint8 a_7 i_6)] <> 0) /\ (i_6 < l_size) /\ (x_5 <= i_6)) ->
   (x_5 <= i_4)) ->
  ((exists i_6 : int. (a_24[(shift_uint8 a_19 i_6)] <> 0) /\
    (a_24[(shift_uint8 a_7 i_6)] <> 0) /\ (i_6 < l_size) /\ (x_5 <= i_6)) ->
   ((a_25 <> 0) /\ (a_27 <> 0))) ->
  ((forall i_6 : int. (i_6 < l_size) -> (x_5 <= i_6) ->
    ((a_24[(shift_uint8 a_19 i_6)] = 0) \/ (a_24[(shift_uint8 a_7 i_6)] = 0))) ->
   (l_size = i_4)) ->
  ((i_1 <> (-1)) ->
   (forall i_6 : int. (a_24[(shift_uint8 a_7 i_6)] <> 0) ->
    (a_24[(shift_uint8 a_23 i_6)] <> 0) -> (0 <= i_6) -> (i_6 < i_1) ->
    (i_6 < l_size) -> (((l_idle_cpu i_6)) = 0))) ->
  ((i_1 = (-1)) ->
   (forall i_6 : int. (a_24[(shift_uint8 a_7 i_6)] <> 0) ->
    (a_24[(shift_uint8 a_23 i_6)] <> 0) -> (0 <= i_6) -> (i_6 < i_5) ->
    (i_6 < l_size) -> (((l_idle_cpu i_6)) = 0))) ->
  ((exists i_6 : int. (a_24[(shift_uint8 a_19 i_6)] <> 0) /\
    (a_24[(shift_uint8 a_7 i_6)] <> 0) /\ (i_6 < l_size) /\ (x_5 <= i_6)) ->
   (forall i_6 : int. (i_6 < i_4) -> (x_5 <= i_6) ->
    ((a_24[(shift_uint8 a_19 i_6)] = 0) \/ (a_24[(shift_uint8 a_7 i_6)] = 0)))) ->
  ((i_1 <> (-1)) ->
   (forall i_6 : int. (a_24[(shift_uint8 a_7 i_6)] <> 0) ->
    (a_24[(shift_uint8 a_23 i_6)] <> 0) -> (0 <= i_6) -> (i_1 <= i_6) ->
    (i_6 < i_5) -> (i_6 < l_size) -> (not (p_idle_core t_5 a_24 i_6)))) ->
  ((i_1 <> (-1)) ->
   (forall i_6 : int. (a_24[(shift_uint8 a_23 i_6)] <> 0) -> (0 <= i_6) ->
    (i_6 < l_size) ->
    ((a_24[(shift_uint8 a_19 i_6)] <> 0) \/ (not (p_idle_core t_5 a_24 i_6))))) ->
  ((i_2 = 0) \/ (i_2 = 1)) ->
  (forall i_6 : int. (0 <= i_6) -> (i_6 < l_size) ->
   ((separated a_21 l_size
      ((shift_uint8 t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_6)))]
         0)) l_size))) ->
  (forall i_6 : int. let a_31 = (shift_cpumask a i_6) in (0 <= i_6) ->
   (i_6 < l_size) ->
   (((valid_rd t a_31 1)) /\
    ((valid_rw t ((shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_31)] 0))
       l_size)))) ->
  (forall i_6 : int. (0 <= i_6) -> (i_6 < l_size) ->
   ((a_22[(shift_uint8 a_23 i_6)] <> 0) <->
    (a_22[(shift_uint8 a_19 i_6)] <> 0))) ->
  (forall i_6 : int. (a_24[(shift_uint8 a_19 i_6)] <> 0) -> (0 <= i_6) ->
   (i_6 < l_size) -> (a_24[(shift_uint8 a_23 i_6)] <> 0)) ->
  (forall a_31 : addr. let a_32 = (l_sched_group_cpus a_31) in
   let a_33 = (shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_32)] 0) in
   ((valid_rd t a_32 1)) /\ ((valid_rd t a_33 l_size)) /\
   (forall i_6 : int. (0 <= i_6) -> (i_6 < l_size) ->
    ((separated a_33 l_size
       ((shift_uint8
          t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_6)))] 0))
       l_size)))) ->
  (forall a_31 : addr. let a_32 = (l_sched_group_mask a_31) in
   let a_33 = (shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_32)] 0) in
   ((valid_rd t a_32 1)) /\ ((valid_rd t a_33 l_size)) /\
   (forall i_6 : int. (0 <= i_6) -> (i_6 < l_size) ->
    ((separated a_33 l_size
       ((shift_uint8
          t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_6)))] 0))
       l_size)))) ->
  (forall a_31 : addr. let a_32 = (l_group_balance_mask a_31) in
   let a_33 = (shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_32)] 0) in
   ((valid_rd t a_32 1)) /\ ((valid_rd t a_33 l_size)) /\
   (forall i_6 : int. (0 <= i_6) -> (i_6 < l_size) ->
    ((separated a_33 l_size
       ((shift_uint8
          t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_6)))] 0))
       l_size)))) ->
  (forall i_6 : int. let a_31 = (l_cpu_smt_mask i_6) in
   let a_32 = (shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_31)] 0) in
   (0 <= i_6) -> (i_6 < l_size) ->
   (((valid_rd t a_31 1)) /\ ((valid_rd t a_32 l_size)) /\
    (forall i_7 : int. (0 <= i_7) -> (i_7 < l_size) ->
     ((separated a_32 l_size
        ((shift_uint8
           t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_7)))] 0))
        l_size))))) ->
  (if (p_1=True) then (i_4 <= 2147483646) else (i_3 <= 2147483646))

end

(* ---------------------------------------------------------- *)
(* --- Decreasing of Loop variant at loop (file c11.c, line 156) --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_loop_term_decrease
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import A_schedule_cpumask.A_schedule_cpumask
use import Compound.Compound
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import Cbits.Cbits

(*
goal WP "expl:Decreasing of Loop variant at loop (file c11.c, line 156)":
*)
goal goal28:
  forall p : bool.
  forall i_4 i_3 i_2 i_1 i : int.
  forall t : map int int.
  forall t_4 t_3 t_2 t_1 : map addr int.
  forall t_5 : map addr addr.
  forall a_2 a_1 a : addr.
  let x = (l_idle_cpu i_3) in
  let a_3 = (shiftfield_f5_lb_env_idle a_1) in
  let x_1 = t_3[a_3] in
  let a_4 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_5 = t_5[a_4] in
  let a_6 = (shiftfield_f1_cpumask_bits a_5) in
  let a_7 = t_5[a_6] in
  let a_8 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x_2 = t_3[a_8] in
  let x_3 = t_3[(shift_uint8 a_7 x_2)] in
  let a_9 = (shiftfield_f5_lb_env_sd a_1) in
  let a_10 = (shift_cpumask a i) in
  let a_11 = t_5[a_9] in
  let a_12 = (shiftfield_f3_sched_domain_flags a_11) in
  let a_13 = (shiftfield_f5_lb_env_sd a_2) in
  let a_14 = (shiftfield_f3_sched_domain_flags t_5[a_13]) in
  let x_4 = t_4[a_14] in
  let a_15 = (shiftfield_f1_cpumask_bits a_10) in
  let a_16 = (shiftfield_f3_sched_domain_groups a_11) in
  let a_17 = t_5[a_16] in
  let a_18 = (l_group_balance_mask a_17) in
  let a_19 = t_5[a_15] in
  let a_20 = (shift_uint8 a_19 0) in
  let a_21 = (shift_uint8 a_7 0) in
  let a_22 = (havoc t_1 t_3 a_20 l_size) in
  let a_23 = t_5[(shiftfield_f1_cpumask_bits a_18)] in
  let a_24 = (havoc t_2 t_3 a_20 l_size) in
  let a_25 = a_24[(shift_uint8 a_19 i_3)] in
  let a_26 = a_24[(shift_uint8 a_7 i_1)] in
  let a_27 = a_24[(shift_uint8 a_7 i_3)] in
  let a_28 = a_24[(shift_uint8 a_23 i_1)] in
  let a_29 = a_24[a_12] in
  let a_30 = (shift_uint8 a_23 0) in
  let x_5 = (to_uint32 i_4) in
  ((x <> 0) <-> (i_2 <> 0)) ->
  (x_1 <> 2) ->
  (x_3 <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= i_3) ->
  (i_3 < l_size) ->
  (0 <= i_4) ->
  (i_4 <= l_size) ->
  (((to_uint32 i_3)) < l_size) ->
  (0 <= x_2) ->
  (x_2 < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_5)) ->
  ((linked t)) ->
  ((is_uint8 i_2)) ->
  ((is_uint32 i)) ->
  ((is_sint32 i_1)) ->
  ((is_sint32 i_3)) ->
  ((is_sint32 i_4)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 x_1)) ->
  ((is_sint32 (1 + i_3))) ->
  ((is_sint32 x_2)) ->
  ((valid_rd t a_4 1)) ->
  ((valid_rd t a_8 1)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_9 1)) ->
  ((valid_rd t a_10 1)) ->
  ((valid_rd t a_5 1)) ->
  ((valid_rd t t_5[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_11 2)) ->
  ((is_sint32 t_3[a_12])) ->
  ((is_sint32 x_4)) ->
  ((valid_rd t a_15 1)) ->
  ((valid_rd t a_6 1)) ->
  ((valid_rd t a_16 1)) ->
  ((valid_rd t a_17 1)) ->
  ((valid_rd t a_18 1)) ->
  ((is_uint8 x_3)) ->
  ((valid_rd t a_20 l_size)) ->
  ((valid_rd t a_21 l_size)) ->
  ((valid_rw t a_20 l_size)) ->
  ((is_uint8 a_22[(shift_uint8 a_7 (-1))])) ->
  ((is_uint8 a_22[(shift_uint8 a_23 (-1))])) ->
  ((is_uint8 a_25)) ->
  ((is_uint8 a_26)) ->
  ((is_uint8 a_27)) ->
  ((is_uint8 a_28)) ->
  ((is_sint32 a_22[a_12])) ->
  ((is_sint32 a_29)) ->
  ((valid_rd t a_30 l_size)) ->
  ((separated a_20 l_size a_30 l_size)) ->
  (if (i_2 = 0) then (i_3 <= 2147483646)
   else ((p=False) /\ (a_2 = a_1) /\ (x <> 0) /\ (((land 7 x_4)) = 0) /\
         (a_24 = t_4) /\ (i_3 <= 2147483646) /\
         (not (p_idle_core t_5 t_4 i_3)) /\ ((valid_rd t a_13 1)) /\
         ((valid_rd t a_14 1)))) ->
  ((((land 7 a_29)) <> 0) -> (i_1 = (-1))) ->
  ((i_1 <> (-1)) ->
   ((((l_idle_cpu i_1)) <> 0) /\ (a_26 <> 0) /\ (a_28 <> 0) /\ (0 <= i_1) /\
    (i_1 < l_size))) ->
  ((i_1 = (-1)) ->
   (forall i_5 : int. (a_24[(shift_uint8 a_23 i_5)] <> 0) -> (0 <= i_5) ->
    (i_5 < l_size) -> (a_24[(shift_uint8 a_19 i_5)] <> 0))) ->
  ((exists i_5 : int. (a_24[(shift_uint8 a_19 i_5)] <> 0) /\
    (a_24[(shift_uint8 a_7 i_5)] <> 0) /\ (i_5 < l_size) /\ (x_5 <= i_5)) ->
   (x_5 <= i_3)) ->
  ((exists i_5 : int. (a_24[(shift_uint8 a_19 i_5)] <> 0) /\
    (a_24[(shift_uint8 a_7 i_5)] <> 0) /\ (i_5 < l_size) /\ (x_5 <= i_5)) ->
   ((a_25 <> 0) /\ (a_27 <> 0))) ->
  ((forall i_5 : int. (i_5 < l_size) -> (x_5 <= i_5) ->
    ((a_24[(shift_uint8 a_19 i_5)] = 0) \/ (a_24[(shift_uint8 a_7 i_5)] = 0))) ->
   (l_size = i_3)) ->
  ((i_1 <> (-1)) ->
   (forall i_5 : int. (a_24[(shift_uint8 a_7 i_5)] <> 0) ->
    (a_24[(shift_uint8 a_23 i_5)] <> 0) -> (0 <= i_5) -> (i_5 < i_1) ->
    (i_5 < l_size) -> (((l_idle_cpu i_5)) = 0))) ->
  ((i_1 = (-1)) ->
   (forall i_5 : int. (a_24[(shift_uint8 a_7 i_5)] <> 0) ->
    (a_24[(shift_uint8 a_23 i_5)] <> 0) -> (0 <= i_5) -> (i_5 < i_4) ->
    (i_5 < l_size) -> (((l_idle_cpu i_5)) = 0))) ->
  ((exists i_5 : int. (a_24[(shift_uint8 a_19 i_5)] <> 0) /\
    (a_24[(shift_uint8 a_7 i_5)] <> 0) /\ (i_5 < l_size) /\ (x_5 <= i_5)) ->
   (forall i_5 : int. (i_5 < i_3) -> (x_5 <= i_5) ->
    ((a_24[(shift_uint8 a_19 i_5)] = 0) \/ (a_24[(shift_uint8 a_7 i_5)] = 0)))) ->
  ((i_1 <> (-1)) ->
   (forall i_5 : int. (a_24[(shift_uint8 a_7 i_5)] <> 0) ->
    (a_24[(shift_uint8 a_23 i_5)] <> 0) -> (0 <= i_5) -> (i_1 <= i_5) ->
    (i_5 < i_4) -> (i_5 < l_size) -> (not (p_idle_core t_5 a_24 i_5)))) ->
  ((i_1 <> (-1)) ->
   (forall i_5 : int. (a_24[(shift_uint8 a_23 i_5)] <> 0) -> (0 <= i_5) ->
    (i_5 < l_size) ->
    ((a_24[(shift_uint8 a_19 i_5)] <> 0) \/ (not (p_idle_core t_5 a_24 i_5))))) ->
  ((i_2 = 0) \/ (i_2 = 1)) ->
  (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
   ((separated a_21 l_size
      ((shift_uint8 t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_5)))]
         0)) l_size))) ->
  (forall i_5 : int. let a_31 = (shift_cpumask a i_5) in (0 <= i_5) ->
   (i_5 < l_size) ->
   (((valid_rd t a_31 1)) /\
    ((valid_rw t ((shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_31)] 0))
       l_size)))) ->
  (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
   ((a_22[(shift_uint8 a_23 i_5)] <> 0) <->
    (a_22[(shift_uint8 a_19 i_5)] <> 0))) ->
  (forall i_5 : int. (a_24[(shift_uint8 a_19 i_5)] <> 0) -> (0 <= i_5) ->
   (i_5 < l_size) -> (a_24[(shift_uint8 a_23 i_5)] <> 0)) ->
  (forall a_31 : addr. let a_32 = (l_sched_group_cpus a_31) in
   let a_33 = (shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_32)] 0) in
   ((valid_rd t a_32 1)) /\ ((valid_rd t a_33 l_size)) /\
   (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
    ((separated a_33 l_size
       ((shift_uint8
          t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_5)))] 0))
       l_size)))) ->
  (forall a_31 : addr. let a_32 = (l_sched_group_mask a_31) in
   let a_33 = (shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_32)] 0) in
   ((valid_rd t a_32 1)) /\ ((valid_rd t a_33 l_size)) /\
   (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
    ((separated a_33 l_size
       ((shift_uint8
          t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_5)))] 0))
       l_size)))) ->
  (forall a_31 : addr. let a_32 = (l_group_balance_mask a_31) in
   let a_33 = (shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_32)] 0) in
   ((valid_rd t a_32 1)) /\ ((valid_rd t a_33 l_size)) /\
   (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
    ((separated a_33 l_size
       ((shift_uint8
          t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_5)))] 0))
       l_size)))) ->
  (forall i_5 : int. let a_31 = (l_cpu_smt_mask i_5) in
   let a_32 = (shift_uint8 t_5[(shiftfield_f1_cpumask_bits a_31)] 0) in
   (0 <= i_5) -> (i_5 < l_size) ->
   (((valid_rd t a_31 1)) /\ ((valid_rd t a_32 l_size)) /\
    (forall i_6 : int. (0 <= i_6) -> (i_6 < l_size) ->
     ((separated a_32 l_size
        ((shift_uint8
           t_5[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_6)))] 0))
        l_size))))) ->
  (i_4 <= i_3)

end

(* ---------------------------------------------------------- *)
(* --- Instance of 'Pre-condition (file masks.c, line 120) in 'cpumask_copy'' in 'should_we_balance' at call 'cpumask_copy' (file c11.c, line 137)
 --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_call_cpumask_copy_pre_2
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import Compound.Compound
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import A_schedule_cpumask.A_schedule_cpumask

(*
goal WP "expl:Instance of 'Pre-condition (file masks.c, line 120) in 'cpumask_copy'' in 'should_we_balance' at call 'cpumask_copy' (file c11.c, line 137)
":
*)
goal goal29:
  forall i : int.
  forall t : map int int.
  forall t_1 : map addr int.
  forall t_2 : map addr addr.
  forall a_1 a : addr.
  let a_2 = (shiftfield_f5_lb_env_idle a_1) in
  let x = t_1[a_2] in
  let a_3 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_4 = t_2[a_3] in
  let a_5 = t_2[(shiftfield_f1_cpumask_bits a_4)] in
  let a_6 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x_1 = t_1[a_6] in
  let x_2 = t_1[(shift_uint8 a_5 x_1)] in
  let a_7 = (shiftfield_f5_lb_env_sd a_1) in
  let a_8 = t_2[a_7] in
  let a_9 = (shiftfield_f3_sched_domain_groups a_8) in
  let a_10 = (shift_uint8 a_5 0) in
  let a_11 = (shift_cpumask a i) in
  (x <> 2) ->
  (x_2 <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= x_1) ->
  (x_1 < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_2)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 x)) ->
  ((is_sint32 x_1)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_6 1)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t a_7 1)) ->
  ((valid_rd t a_4 1)) ->
  ((valid_rd t t_2[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_8 2)) ->
  ((is_sint32 t_1[(shiftfield_f3_sched_domain_flags a_8)])) ->
  ((valid_rd t a_9 1)) ->
  ((valid_rd t t_2[a_9] 1)) ->
  ((is_uint8 x_2)) ->
  ((valid_rd t a_10 l_size)) ->
  (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
   ((separated a_10 l_size
      ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))]
         0)) l_size))) ->
  (forall i_1 : int. let a_12 = (shift_cpumask a i_1) in (0 <= i_1) ->
   (i_1 < l_size) ->
   (((valid_rd t a_12 1)) /\
    ((valid_rw t ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_12)] 0))
       l_size)))) ->
  (forall a_12 : addr. let a_13 = (l_sched_group_cpus a_12) in
   let a_14 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_13)] 0) in
   ((valid_rd t a_13 1)) /\ ((valid_rd t a_14 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_14 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall a_12 : addr. let a_13 = (l_sched_group_mask a_12) in
   let a_14 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_13)] 0) in
   ((valid_rd t a_13 1)) /\ ((valid_rd t a_14 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_14 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall a_12 : addr. let a_13 = (l_group_balance_mask a_12) in
   let a_14 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_13)] 0) in
   ((valid_rd t a_13 1)) /\ ((valid_rd t a_14 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_14 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall i_1 : int. let a_12 = (l_cpu_smt_mask i_1) in
   let a_13 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_12)] 0) in
   (0 <= i_1) -> (i_1 < l_size) ->
   (((valid_rd t a_12 1)) /\ ((valid_rd t a_13 l_size)) /\
    (forall i_2 : int. (0 <= i_2) -> (i_2 < l_size) ->
     ((separated a_13 l_size
        ((shift_uint8
           t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_2)))] 0))
        l_size))))) ->
  (((valid_rd t a_11 1)) /\
   ((valid_rw t ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_11)] 0))
      l_size)))

end

(* ---------------------------------------------------------- *)
(* --- Instance of 'Pre-condition (file masks.c, line 121) in 'cpumask_copy'' in 'should_we_balance' at call 'cpumask_copy' (file c11.c, line 137)
 --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_call_cpumask_copy_pre_3
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import Compound.Compound
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import A_schedule_cpumask.A_schedule_cpumask

(*
goal WP "expl:Instance of 'Pre-condition (file masks.c, line 121) in 'cpumask_copy'' in 'should_we_balance' at call 'cpumask_copy' (file c11.c, line 137)
":
*)
goal goal30:
  forall i : int.
  forall t : map int int.
  forall t_1 : map addr int.
  forall t_2 : map addr addr.
  forall a_1 a : addr.
  let a_2 = (shiftfield_f5_lb_env_idle a_1) in
  let x = t_1[a_2] in
  let a_3 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_4 = t_2[a_3] in
  let a_5 = t_2[(shiftfield_f1_cpumask_bits a_4)] in
  let a_6 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x_1 = t_1[a_6] in
  let x_2 = t_1[(shift_uint8 a_5 x_1)] in
  let a_7 = (shiftfield_f5_lb_env_sd a_1) in
  let a_8 = t_2[a_7] in
  let a_9 = (shiftfield_f3_sched_domain_groups a_8) in
  let a_10 = t_2[a_9] in
  let a_11 = (shift_uint8 a_5 0) in
  let a_12 = (l_group_balance_mask a_10) in
  (x <> 2) ->
  (x_2 <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= x_1) ->
  (x_1 < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_2)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 x)) ->
  ((is_sint32 x_1)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_6 1)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t a_7 1)) ->
  ((valid_rd t a_4 1)) ->
  ((valid_rd t t_2[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_8 2)) ->
  ((is_sint32 t_1[(shiftfield_f3_sched_domain_flags a_8)])) ->
  ((valid_rd t a_9 1)) ->
  ((valid_rd t a_10 1)) ->
  ((is_uint8 x_2)) ->
  ((valid_rd t a_11 l_size)) ->
  (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
   ((separated a_11 l_size
      ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))]
         0)) l_size))) ->
  (forall i_1 : int. let a_13 = (shift_cpumask a i_1) in (0 <= i_1) ->
   (i_1 < l_size) ->
   (((valid_rd t a_13 1)) /\
    ((valid_rw t ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_13)] 0))
       l_size)))) ->
  (forall a_13 : addr. let a_14 = (l_sched_group_cpus a_13) in
   let a_15 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_14)] 0) in
   ((valid_rd t a_14 1)) /\ ((valid_rd t a_15 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_15 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall a_13 : addr. let a_14 = (l_sched_group_mask a_13) in
   let a_15 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_14)] 0) in
   ((valid_rd t a_14 1)) /\ ((valid_rd t a_15 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_15 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall a_13 : addr. let a_14 = (l_group_balance_mask a_13) in
   let a_15 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_14)] 0) in
   ((valid_rd t a_14 1)) /\ ((valid_rd t a_15 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_15 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall i_1 : int. let a_13 = (l_cpu_smt_mask i_1) in
   let a_14 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_13)] 0) in
   (0 <= i_1) -> (i_1 < l_size) ->
   (((valid_rd t a_13 1)) /\ ((valid_rd t a_14 l_size)) /\
    (forall i_2 : int. (0 <= i_2) -> (i_2 < l_size) ->
     ((separated a_14 l_size
        ((shift_uint8
           t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_2)))] 0))
        l_size))))) ->
  (((valid_rd t a_12 1)) /\
   ((valid_rd t ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_12)] 0))
      l_size)))

end

(* ---------------------------------------------------------- *)
(* --- Instance of 'Pre-condition (file masks.c, line 122) in 'cpumask_copy'' in 'should_we_balance' at call 'cpumask_copy' (file c11.c, line 137)
 --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_call_cpumask_copy_pre_4
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import Compound.Compound
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import A_schedule_cpumask.A_schedule_cpumask

(*
goal WP "expl:Instance of 'Pre-condition (file masks.c, line 122) in 'cpumask_copy'' in 'should_we_balance' at call 'cpumask_copy' (file c11.c, line 137)
":
*)
goal goal31:
  forall i : int.
  forall t : map int int.
  forall t_1 : map addr int.
  forall t_2 : map addr addr.
  forall a_1 a : addr.
  let a_2 = (shiftfield_f5_lb_env_idle a_1) in
  let x = t_1[a_2] in
  let a_3 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_4 = t_2[a_3] in
  let a_5 = t_2[(shiftfield_f1_cpumask_bits a_4)] in
  let a_6 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x_1 = t_1[a_6] in
  let x_2 = t_1[(shift_uint8 a_5 x_1)] in
  let a_7 = (shiftfield_f5_lb_env_sd a_1) in
  let a_8 = t_2[a_7] in
  let a_9 = (shiftfield_f3_sched_domain_groups a_8) in
  let a_10 = t_2[a_9] in
  let a_11 = (shift_uint8 a_5 0) in
  (x <> 2) ->
  (x_2 <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= x_1) ->
  (x_1 < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_2)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 x)) ->
  ((is_sint32 x_1)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_6 1)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t a_7 1)) ->
  ((valid_rd t a_4 1)) ->
  ((valid_rd t t_2[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_8 2)) ->
  ((is_sint32 t_1[(shiftfield_f3_sched_domain_flags a_8)])) ->
  ((valid_rd t a_9 1)) ->
  ((valid_rd t a_10 1)) ->
  ((is_uint8 x_2)) ->
  ((valid_rd t a_11 l_size)) ->
  (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
   ((separated a_11 l_size
      ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))]
         0)) l_size))) ->
  (forall i_1 : int. let a_12 = (shift_cpumask a i_1) in (0 <= i_1) ->
   (i_1 < l_size) ->
   (((valid_rd t a_12 1)) /\
    ((valid_rw t ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_12)] 0))
       l_size)))) ->
  (forall a_12 : addr. let a_13 = (l_sched_group_cpus a_12) in
   let a_14 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_13)] 0) in
   ((valid_rd t a_13 1)) /\ ((valid_rd t a_14 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_14 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall a_12 : addr. let a_13 = (l_sched_group_mask a_12) in
   let a_14 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_13)] 0) in
   ((valid_rd t a_13 1)) /\ ((valid_rd t a_14 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_14 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall a_12 : addr. let a_13 = (l_group_balance_mask a_12) in
   let a_14 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_13)] 0) in
   ((valid_rd t a_13 1)) /\ ((valid_rd t a_14 l_size)) /\
   (forall i_1 : int. (0 <= i_1) -> (i_1 < l_size) ->
    ((separated a_14 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_1)))] 0))
       l_size)))) ->
  (forall i_1 : int. let a_12 = (l_cpu_smt_mask i_1) in
   let a_13 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_12)] 0) in
   (0 <= i_1) -> (i_1 < l_size) ->
   (((valid_rd t a_12 1)) /\ ((valid_rd t a_13 l_size)) /\
    (forall i_2 : int. (0 <= i_2) -> (i_2 < l_size) ->
     ((separated a_13 l_size
        ((shift_uint8
           t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_2)))] 0))
        l_size))))) ->
  ((separated
     ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i)))] 0))
     l_size
     ((shift_uint8
        t_2[(shiftfield_f1_cpumask_bits ((l_group_balance_mask a_10)))] 0))
     l_size))

end

(* ---------------------------------------------------------- *)
(* --- Instance of 'Pre-condition (file for_loops.c, line 55) in 'find_next_and_bit'' in 'should_we_balance' at call 'find_next_and_bit' (file c11.c, line 156)
 --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_call_find_next_and_bit_pre_2
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import Compound.Compound
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import A_schedule_cpumask.A_schedule_cpumask
use import Cbits.Cbits

(*
goal WP "expl:Instance of 'Pre-condition (file for_loops.c, line 55) in 'find_next_and_bit'' in 'should_we_balance' at call 'find_next_and_bit' (file c11.c, line 156)
":
*)
goal goal32:
  forall i_2 i_1 i : int.
  forall t : map int int.
  forall t_3 t_2 t_1 : map addr int.
  forall t_4 : map addr addr.
  forall a_1 a : addr.
  let a_2 = (shiftfield_f5_lb_env_idle a_1) in
  let x = t_3[a_2] in
  let a_3 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_4 = t_4[a_3] in
  let a_5 = (shiftfield_f1_cpumask_bits a_4) in
  let a_6 = t_4[a_5] in
  let a_7 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x_1 = t_3[a_7] in
  let x_2 = t_3[(shift_uint8 a_6 x_1)] in
  let a_8 = (shiftfield_f5_lb_env_sd a_1) in
  let a_9 = (shift_cpumask a i) in
  let a_10 = t_4[a_8] in
  let a_11 = (shiftfield_f3_sched_domain_flags a_10) in
  let a_12 = (shiftfield_f1_cpumask_bits a_9) in
  let a_13 = (shiftfield_f3_sched_domain_groups a_10) in
  let a_14 = t_4[a_13] in
  let a_15 = (l_group_balance_mask a_14) in
  let a_16 = (shift_uint8 a_6 0) in
  let a_17 = t_4[a_12] in
  let a_18 = (shift_uint8 a_17 0) in
  let a_19 = (havoc t_1 t_3 a_18 l_size) in
  let a_20 = t_4[(shiftfield_f1_cpumask_bits a_15)] in
  let a_21 = (havoc t_2 t_3 a_18 l_size) in
  let a_22 = a_21[(shift_uint8 a_6 i_1)] in
  let a_23 = a_21[(shift_uint8 a_20 i_1)] in
  let a_24 = a_21[a_11] in
  let a_25 = (shift_uint8 a_20 0) in
  (x <> 2) ->
  (x_2 <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= i_2) ->
  (i_2 <= l_size) ->
  (0 <= x_1) ->
  (x_1 < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_4)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((is_sint32 i_1)) ->
  ((is_sint32 i_2)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 x)) ->
  ((is_sint32 x_1)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_7 1)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t a_8 1)) ->
  ((valid_rd t a_9 1)) ->
  ((valid_rd t a_4 1)) ->
  ((valid_rd t t_4[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_10 2)) ->
  ((is_sint32 t_3[a_11])) ->
  ((valid_rd t a_12 1)) ->
  ((valid_rd t a_5 1)) ->
  ((valid_rd t a_13 1)) ->
  ((valid_rd t a_14 1)) ->
  ((valid_rd t a_15 1)) ->
  ((is_uint8 x_2)) ->
  ((valid_rd t a_16 l_size)) ->
  ((valid_rw t a_18 l_size)) ->
  ((is_uint8 a_19[(shift_uint8 a_6 (-1))])) ->
  ((is_uint8 a_19[(shift_uint8 a_20 (-1))])) ->
  ((is_uint8 a_22)) ->
  ((is_uint8 a_23)) ->
  ((is_sint32 a_19[a_11])) ->
  ((is_sint32 a_24)) ->
  ((valid_rd t a_25 l_size)) ->
  ((separated a_18 l_size a_25 l_size)) ->
  ((((land 7 a_24)) <> 0) -> (i_1 = (-1))) ->
  ((i_1 <> (-1)) ->
   ((((l_idle_cpu i_1)) <> 0) /\ (a_22 <> 0) /\ (a_23 <> 0) /\ (0 <= i_1) /\
    (i_1 < l_size))) ->
  ((i_1 = (-1)) ->
   (forall i_3 : int. (a_21[(shift_uint8 a_20 i_3)] <> 0) -> (0 <= i_3) ->
    (i_3 < l_size) -> (a_21[(shift_uint8 a_17 i_3)] <> 0))) ->
  ((i_1 <> (-1)) ->
   (forall i_3 : int. (a_21[(shift_uint8 a_6 i_3)] <> 0) ->
    (a_21[(shift_uint8 a_20 i_3)] <> 0) -> (0 <= i_3) -> (i_3 < i_1) ->
    (i_3 < l_size) -> (((l_idle_cpu i_3)) = 0))) ->
  ((i_1 = (-1)) ->
   (forall i_3 : int. (a_21[(shift_uint8 a_6 i_3)] <> 0) ->
    (a_21[(shift_uint8 a_20 i_3)] <> 0) -> (0 <= i_3) -> (i_3 < i_2) ->
    (i_3 < l_size) -> (((l_idle_cpu i_3)) = 0))) ->
  ((i_1 <> (-1)) ->
   (forall i_3 : int. (a_21[(shift_uint8 a_6 i_3)] <> 0) ->
    (a_21[(shift_uint8 a_20 i_3)] <> 0) -> (0 <= i_3) -> (i_1 <= i_3) ->
    (i_3 < i_2) -> (i_3 < l_size) -> (not (p_idle_core t_4 a_21 i_3)))) ->
  ((i_1 <> (-1)) ->
   (forall i_3 : int. (a_21[(shift_uint8 a_20 i_3)] <> 0) -> (0 <= i_3) ->
    (i_3 < l_size) ->
    ((a_21[(shift_uint8 a_17 i_3)] <> 0) \/ (not (p_idle_core t_4 a_21 i_3))))) ->
  (forall i_3 : int. (0 <= i_3) -> (i_3 < l_size) ->
   ((separated a_16 l_size
      ((shift_uint8 t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_3)))]
         0)) l_size))) ->
  (forall i_3 : int. let a_26 = (shift_cpumask a i_3) in (0 <= i_3) ->
   (i_3 < l_size) ->
   (((valid_rd t a_26 1)) /\
    ((valid_rw t ((shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_26)] 0))
       l_size)))) ->
  (forall i_3 : int. (0 <= i_3) -> (i_3 < l_size) ->
   ((a_19[(shift_uint8 a_20 i_3)] <> 0) <->
    (a_19[(shift_uint8 a_17 i_3)] <> 0))) ->
  (forall i_3 : int. (a_21[(shift_uint8 a_17 i_3)] <> 0) -> (0 <= i_3) ->
   (i_3 < l_size) -> (a_21[(shift_uint8 a_20 i_3)] <> 0)) ->
  (forall a_26 : addr. let a_27 = (l_sched_group_cpus a_26) in
   let a_28 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_27)] 0) in
   ((valid_rd t a_27 1)) /\ ((valid_rd t a_28 l_size)) /\
   (forall i_3 : int. (0 <= i_3) -> (i_3 < l_size) ->
    ((separated a_28 l_size
       ((shift_uint8
          t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_3)))] 0))
       l_size)))) ->
  (forall a_26 : addr. let a_27 = (l_sched_group_mask a_26) in
   let a_28 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_27)] 0) in
   ((valid_rd t a_27 1)) /\ ((valid_rd t a_28 l_size)) /\
   (forall i_3 : int. (0 <= i_3) -> (i_3 < l_size) ->
    ((separated a_28 l_size
       ((shift_uint8
          t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_3)))] 0))
       l_size)))) ->
  (forall a_26 : addr. let a_27 = (l_group_balance_mask a_26) in
   let a_28 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_27)] 0) in
   ((valid_rd t a_27 1)) /\ ((valid_rd t a_28 l_size)) /\
   (forall i_3 : int. (0 <= i_3) -> (i_3 < l_size) ->
    ((separated a_28 l_size
       ((shift_uint8
          t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_3)))] 0))
       l_size)))) ->
  (forall i_3 : int. let a_26 = (l_cpu_smt_mask i_3) in
   let a_27 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_26)] 0) in
   (0 <= i_3) -> (i_3 < l_size) ->
   (((valid_rd t a_26 1)) /\ ((valid_rd t a_27 l_size)) /\
    (forall i_4 : int. (0 <= i_4) -> (i_4 < l_size) ->
     ((separated a_27 l_size
        ((shift_uint8
           t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_4)))] 0))
        l_size))))) ->
  ((valid_rd t a_18 l_size))

end

(* ---------------------------------------------------------- *)
(* --- Instance of 'Pre-condition (file masks.c, line 85) in 'idle_cpu'' in 'should_we_balance' at call 'idle_cpu' (file c11.c, line 157)
 --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_call_idle_cpu_pre
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import Compound.Compound
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import A_schedule_cpumask.A_schedule_cpumask
use import Cbits.Cbits

(*
goal WP "expl:Instance of 'Pre-condition (file masks.c, line 85) in 'idle_cpu'' in 'should_we_balance' at call 'idle_cpu' (file c11.c, line 157)
":
*)
goal goal33:
  forall i_3 i_2 i_1 i : int.
  forall t : map int int.
  forall t_3 t_2 t_1 : map addr int.
  forall t_4 : map addr addr.
  forall a_1 a : addr.
  let a_2 = (shiftfield_f5_lb_env_idle a_1) in
  let x = t_3[a_2] in
  let a_3 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_4 = t_4[a_3] in
  let a_5 = (shiftfield_f1_cpumask_bits a_4) in
  let a_6 = t_4[a_5] in
  let a_7 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x_1 = t_3[a_7] in
  let x_2 = t_3[(shift_uint8 a_6 x_1)] in
  let a_8 = (shiftfield_f5_lb_env_sd a_1) in
  let a_9 = (shift_cpumask a i) in
  let a_10 = t_4[a_8] in
  let a_11 = (shiftfield_f3_sched_domain_flags a_10) in
  let a_12 = (shiftfield_f1_cpumask_bits a_9) in
  let a_13 = (shiftfield_f3_sched_domain_groups a_10) in
  let a_14 = t_4[a_13] in
  let a_15 = (l_group_balance_mask a_14) in
  let a_16 = t_4[a_12] in
  let a_17 = (shift_uint8 a_16 0) in
  let a_18 = (shift_uint8 a_6 0) in
  let a_19 = (havoc t_1 t_3 a_17 l_size) in
  let a_20 = t_4[(shiftfield_f1_cpumask_bits a_15)] in
  let a_21 = (havoc t_2 t_3 a_17 l_size) in
  let a_22 = a_21[(shift_uint8 a_16 i_2)] in
  let a_23 = a_21[(shift_uint8 a_6 i_1)] in
  let a_24 = a_21[(shift_uint8 a_6 i_2)] in
  let a_25 = a_21[(shift_uint8 a_20 i_1)] in
  let a_26 = a_21[a_11] in
  let a_27 = (shift_uint8 a_20 0) in
  let x_3 = (to_uint32 i_3) in
  (x <> 2) ->
  (x_2 <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= i_3) ->
  (i_3 <= l_size) ->
  (((to_uint32 i_2)) < l_size) ->
  (0 <= x_1) ->
  (x_1 < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_4)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((is_sint32 i_1)) ->
  ((is_sint32 i_2)) ->
  ((is_sint32 i_3)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 x)) ->
  ((is_sint32 x_1)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_7 1)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t a_8 1)) ->
  ((valid_rd t a_9 1)) ->
  ((valid_rd t a_4 1)) ->
  ((valid_rd t t_4[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_10 2)) ->
  ((is_sint32 t_3[a_11])) ->
  ((valid_rd t a_12 1)) ->
  ((valid_rd t a_5 1)) ->
  ((valid_rd t a_13 1)) ->
  ((valid_rd t a_14 1)) ->
  ((valid_rd t a_15 1)) ->
  ((is_uint8 x_2)) ->
  ((valid_rd t a_17 l_size)) ->
  ((valid_rd t a_18 l_size)) ->
  ((valid_rw t a_17 l_size)) ->
  ((is_uint8 a_19[(shift_uint8 a_6 (-1))])) ->
  ((is_uint8 a_19[(shift_uint8 a_20 (-1))])) ->
  ((is_uint8 a_22)) ->
  ((is_uint8 a_23)) ->
  ((is_uint8 a_24)) ->
  ((is_uint8 a_25)) ->
  ((is_sint32 a_19[a_11])) ->
  ((is_sint32 a_26)) ->
  ((valid_rd t a_27 l_size)) ->
  ((separated a_17 l_size a_27 l_size)) ->
  ((((land 7 a_26)) <> 0) -> (i_1 = (-1))) ->
  ((i_1 <> (-1)) ->
   ((((l_idle_cpu i_1)) <> 0) /\ (a_23 <> 0) /\ (a_25 <> 0) /\ (0 <= i_1) /\
    (i_1 < l_size))) ->
  ((i_1 = (-1)) ->
   (forall i_4 : int. (a_21[(shift_uint8 a_20 i_4)] <> 0) -> (0 <= i_4) ->
    (i_4 < l_size) -> (a_21[(shift_uint8 a_16 i_4)] <> 0))) ->
  ((exists i_4 : int. (a_21[(shift_uint8 a_16 i_4)] <> 0) /\
    (a_21[(shift_uint8 a_6 i_4)] <> 0) /\ (i_4 < l_size) /\ (x_3 <= i_4)) ->
   (i_2 < l_size)) ->
  ((exists i_4 : int. (a_21[(shift_uint8 a_16 i_4)] <> 0) /\
    (a_21[(shift_uint8 a_6 i_4)] <> 0) /\ (i_4 < l_size) /\ (x_3 <= i_4)) ->
   ((i_2 < l_size) /\ (x_3 <= i_2))) ->
  ((exists i_4 : int. (a_21[(shift_uint8 a_16 i_4)] <> 0) /\
    (a_21[(shift_uint8 a_6 i_4)] <> 0) /\ (i_4 < l_size) /\ (x_3 <= i_4)) ->
   ((a_22 <> 0) /\ (a_24 <> 0))) ->
  ((forall i_4 : int. (i_4 < l_size) -> (x_3 <= i_4) ->
    ((a_21[(shift_uint8 a_16 i_4)] = 0) \/ (a_21[(shift_uint8 a_6 i_4)] = 0))) ->
   (l_size = i_2)) ->
  ((i_1 <> (-1)) ->
   (forall i_4 : int. (a_21[(shift_uint8 a_6 i_4)] <> 0) ->
    (a_21[(shift_uint8 a_20 i_4)] <> 0) -> (0 <= i_4) -> (i_4 < i_1) ->
    (i_4 < l_size) -> (((l_idle_cpu i_4)) = 0))) ->
  ((i_1 = (-1)) ->
   (forall i_4 : int. (a_21[(shift_uint8 a_6 i_4)] <> 0) ->
    (a_21[(shift_uint8 a_20 i_4)] <> 0) -> (0 <= i_4) -> (i_4 < i_3) ->
    (i_4 < l_size) -> (((l_idle_cpu i_4)) = 0))) ->
  ((exists i_4 : int. (a_21[(shift_uint8 a_16 i_4)] <> 0) /\
    (a_21[(shift_uint8 a_6 i_4)] <> 0) /\ (i_4 < l_size) /\ (x_3 <= i_4)) ->
   (forall i_4 : int. (i_4 < i_2) -> (x_3 <= i_4) ->
    ((a_21[(shift_uint8 a_16 i_4)] = 0) \/ (a_21[(shift_uint8 a_6 i_4)] = 0)))) ->
  ((i_1 <> (-1)) ->
   (forall i_4 : int. (a_21[(shift_uint8 a_6 i_4)] <> 0) ->
    (a_21[(shift_uint8 a_20 i_4)] <> 0) -> (0 <= i_4) -> (i_1 <= i_4) ->
    (i_4 < i_3) -> (i_4 < l_size) -> (not (p_idle_core t_4 a_21 i_4)))) ->
  ((i_1 <> (-1)) ->
   (forall i_4 : int. (a_21[(shift_uint8 a_20 i_4)] <> 0) -> (0 <= i_4) ->
    (i_4 < l_size) ->
    ((a_21[(shift_uint8 a_16 i_4)] <> 0) \/ (not (p_idle_core t_4 a_21 i_4))))) ->
  (forall i_4 : int. (0 <= i_4) -> (i_4 < l_size) ->
   ((separated a_18 l_size
      ((shift_uint8 t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_4)))]
         0)) l_size))) ->
  (forall i_4 : int. let a_28 = (shift_cpumask a i_4) in (0 <= i_4) ->
   (i_4 < l_size) ->
   (((valid_rd t a_28 1)) /\
    ((valid_rw t ((shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_28)] 0))
       l_size)))) ->
  (forall i_4 : int. (0 <= i_4) -> (i_4 < l_size) ->
   ((a_19[(shift_uint8 a_20 i_4)] <> 0) <->
    (a_19[(shift_uint8 a_16 i_4)] <> 0))) ->
  (forall i_4 : int. (a_21[(shift_uint8 a_16 i_4)] <> 0) -> (0 <= i_4) ->
   (i_4 < l_size) -> (a_21[(shift_uint8 a_20 i_4)] <> 0)) ->
  (forall a_28 : addr. let a_29 = (l_sched_group_cpus a_28) in
   let a_30 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_29)] 0) in
   ((valid_rd t a_29 1)) /\ ((valid_rd t a_30 l_size)) /\
   (forall i_4 : int. (0 <= i_4) -> (i_4 < l_size) ->
    ((separated a_30 l_size
       ((shift_uint8
          t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_4)))] 0))
       l_size)))) ->
  (forall a_28 : addr. let a_29 = (l_sched_group_mask a_28) in
   let a_30 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_29)] 0) in
   ((valid_rd t a_29 1)) /\ ((valid_rd t a_30 l_size)) /\
   (forall i_4 : int. (0 <= i_4) -> (i_4 < l_size) ->
    ((separated a_30 l_size
       ((shift_uint8
          t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_4)))] 0))
       l_size)))) ->
  (forall a_28 : addr. let a_29 = (l_group_balance_mask a_28) in
   let a_30 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_29)] 0) in
   ((valid_rd t a_29 1)) /\ ((valid_rd t a_30 l_size)) /\
   (forall i_4 : int. (0 <= i_4) -> (i_4 < l_size) ->
    ((separated a_30 l_size
       ((shift_uint8
          t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_4)))] 0))
       l_size)))) ->
  (forall i_4 : int. let a_28 = (l_cpu_smt_mask i_4) in
   let a_29 = (shift_uint8 t_4[(shiftfield_f1_cpumask_bits a_28)] 0) in
   (0 <= i_4) -> (i_4 < l_size) ->
   (((valid_rd t a_28 1)) /\ ((valid_rd t a_29 l_size)) /\
    (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
     ((separated a_29 l_size
        ((shift_uint8
           t_4[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_5)))] 0))
        l_size))))) ->
  ((0 <= i_2) /\ (i_2 < l_size))

end

(* ---------------------------------------------------------- *)
(* --- Post-condition for 'not_newly_idle_with_idle' (file c11.c, line 63) in 'should_we_balance' --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_not_newly_idle_with_idle_post
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import A_schedule_cpumask.A_schedule_cpumask
use import Compound.Compound
use import Cint.Cint
use import Cbits.Cbits
use import A_thread_variables_properties.A_thread_variables_properties

(*
goal WP "expl:Post-condition for 'not_newly_idle_with_idle' (file c11.c, line 63) in 'should_we_balance'":
*)
goal goal34:
  forall i_10 i_9 i_8 i_7 i_6 i_5 i_4 i_3 i_2 i_1 i : int.
  forall t_4 t_3 t_2 t_1 t : map int int.
  forall t_7 t_6 t_5 : map addr int.
  forall t_8 : map addr addr.
  forall a_1 a : addr.
  let a_2 = (shiftfield_f5_lb_env_idle a_1) in
  let x = t_7[a_2] in
  let a_3 = (shiftfield_f5_lb_env_sd a_1) in
  let a_4 = t_8[a_3] in
  let a_5 = (shiftfield_f3_sched_domain_flags a_4) in
  let x_1 = t_7[a_5] in
  let a_6 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_7 = t_8[a_6] in
  let a_8 = (shiftfield_f1_cpumask_bits a_7) in
  let a_9 = t_8[a_8] in
  let a_10 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x_2 = t_7[a_10] in
  let x_3 = t_7[(shift_uint8 a_9 x_2)] in
  let a_11 = (shiftfield_f3_sched_domain_groups a_4) in
  let a_12 = t_8[a_11] in
  let a_13 = (l_group_balance_mask a_12) in
  let a_14 = t_8[(shiftfield_f1_cpumask_bits a_13)] in
  let a_15 = (shift_cpumask a i) in
  let a_16 = (shiftfield_f1_cpumask_bits a_15) in
  let a_17 = t_8[a_16] in
  let a_18 = (shift_uint8 a_17 0) in
  let a_19 = (havoc t_6 t_7 a_18 l_size) in
  let a_20 = (shift_uint8 a_9 0) in
  let a_21 = a_19[(shift_uint8 a_17 i_8)] in
  let a_22 = a_19[(shift_uint8 a_9 i_3)] in
  let a_23 = a_19[(shift_uint8 a_9 i_8)] in
  let a_24 = a_19[(shift_uint8 a_14 i_3)] in
  let a_25 = a_19[a_5] in
  let a_26 = (shift_uint8 a_14 0) in
  let a_27 = a_19[a_10] in
  let x_4 = (land 7 a_25) in
  let x_5 = (to_uint32 i_9) in
  let a_28 = (havoc t_5 t_7 a_18 l_size) in
  (((l_idle_cpu i_5)) <> 0) ->
  (((l_idle_cpu i_6)) <> 0) ->
  (x <> 2) ->
  (((land 7 x_1)) <> 0) ->
  (t_7[(shift_uint8 a_9 i_5)] <> 0) ->
  (x_3 <> 0) ->
  (t_7[(shift_uint8 a_14 i_5)] <> 0) ->
  (a_19[(shift_uint8 a_9 i_6)] <> 0) ->
  (a_19[(shift_uint8 a_14 i_6)] <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= i_5) ->
  (i_5 < l_size) ->
  (0 <= i_6) ->
  (i_6 < l_size) ->
  (0 <= i_9) ->
  (i_9 <= l_size) ->
  (0 <= x_2) ->
  (x_2 < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_8)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((is_uint32 i_1)) ->
  ((is_sint32 i_2)) ->
  ((is_sint32 i_3)) ->
  ((is_sint32 i_4)) ->
  ((is_sint32 i_7)) ->
  ((is_sint32 i_8)) ->
  ((is_sint32 i_9)) ->
  ((is_sint32 i_10)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 x)) ->
  ((is_sint32 x_2)) ->
  ((valid_rd t a_6 1)) ->
  ((valid_rd t a_10 1)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_15 1)) ->
  ((valid_rd t a_7 1)) ->
  ((valid_rd t t_8[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_4 2)) ->
  ((is_sint32 x_1)) ->
  ((valid_rd t a_16 1)) ->
  ((valid_rd t a_8 1)) ->
  ((valid_rd t a_11 1)) ->
  ((valid_rd t a_12 1)) ->
  ((valid_rd t a_13 1)) ->
  ((is_uint8 x_3)) ->
  ((valid_rd t a_18 l_size)) ->
  ((valid_rd t a_20 l_size)) ->
  ((valid_rw t a_18 l_size)) ->
  ((is_uint8 a_21)) ->
  ((is_uint8 a_22)) ->
  ((is_uint8 a_23)) ->
  ((is_uint8 a_24)) ->
  ((is_sint32 a_25)) ->
  ((valid_rd t a_26 l_size)) ->
  ((separated a_18 l_size a_26 l_size)) ->
  (if (((to_uint32 i_8)) < l_size)
   then ((i_10 = i_8) /\ (t_4 = t) /\ (((l_idle_cpu i_10)) <> 0) /\
         ((if (a_27 = i_10) then 1 else 0) = i_2) /\ (0 <= i_10) /\
         (i_10 < l_size) /\ ((valid_rd t_4 a_10 1)) /\
         ((valid_rd t_4 a_3 1)) /\ ((valid_rd t_4 a_5 1)) /\
         ((x_4 <> 0) \/
          ((l_size = i_1) /\
           ((p_idle_core t_8 ((havoc t_6 t_7 a_18 i_1)) i_10)) /\
           (forall i_11 : int. let a_29 = (shift_cpumask a i_11) in
            (0 <= i_11) -> (i_11 < i_1) ->
            (((valid_rd t_4 a_29 1)) /\
             ((valid_rw t_4
                ((shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_29)] 0)) i_1)))) /\
           (forall a_29 : addr. let a_30 = (l_sched_group_cpus a_29) in
            let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
            ((valid_rd t_4 a_30 1)) /\ ((valid_rd t_4 a_31 i_1)) /\
            (forall i_11 : int. (0 <= i_11) -> (i_11 < i_1) ->
             ((separated a_31 i_1
                ((shift_uint8
                   t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))]
                   0)) i_1)))) /\
           (forall a_29 : addr. let a_30 = (l_sched_group_mask a_29) in
            let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
            ((valid_rd t_4 a_30 1)) /\ ((valid_rd t_4 a_31 i_1)) /\
            (forall i_11 : int. (0 <= i_11) -> (i_11 < i_1) ->
             ((separated a_31 i_1
                ((shift_uint8
                   t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))]
                   0)) i_1)))) /\
           (forall a_29 : addr. let a_30 = (l_group_balance_mask a_29) in
            let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
            ((valid_rd t_4 a_30 1)) /\ ((valid_rd t_4 a_31 i_1)) /\
            (forall i_11 : int. (0 <= i_11) -> (i_11 < i_1) ->
             ((separated a_31 i_1
                ((shift_uint8
                   t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))]
                   0)) i_1)))) /\
           (forall i_11 : int. let a_29 = (l_cpu_smt_mask i_11) in
            let a_30 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_29)] 0) in
            (0 <= i_11) -> (i_11 < i_1) ->
            (((valid_rd t_4 a_29 1)) /\ ((valid_rd t_4 a_30 i_1)) /\
             (forall i_12 : int. (0 <= i_12) -> (i_12 < i_1) ->
              ((separated a_30 i_1
                 ((shift_uint8
                    t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_12)))]
                    0)) i_1))))))))
   else ((i_4 = i_3) /\ (t_1 = t) /\
         (if (i_4 = (-1))
          then ((t_2 = t_1) /\ (((l_group_balance_cpu a_12)) = i_7) /\
                ((if (a_27 = i_7) then 1 else 0) = i_2) /\
                ((valid_rd t_2 a_10 1)))
          else ((t_3 = t_1) /\ ((if (a_27 = i_4) then 1 else 0) = i_2) /\
                ((valid_rd t_3 a_10 1)))))) ->
  ((x_4 <> 0) -> (i_3 = (-1))) ->
  ((i_3 <> (-1)) ->
   ((((l_idle_cpu i_3)) <> 0) /\ (a_22 <> 0) /\ (a_24 <> 0) /\ (0 <= i_3) /\
    (i_3 < l_size))) ->
  ((i_3 = (-1)) ->
   (forall i_11 : int. (a_19[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) ->
    (i_11 < l_size) -> (a_19[(shift_uint8 a_17 i_11)] <> 0))) ->
  ((exists i_11 : int. (a_19[(shift_uint8 a_17 i_11)] <> 0) /\
    (a_19[(shift_uint8 a_9 i_11)] <> 0) /\ (i_11 < l_size) /\ (x_5 <= i_11)) ->
   (i_8 < l_size)) ->
  ((exists i_11 : int. (a_19[(shift_uint8 a_17 i_11)] <> 0) /\
    (a_19[(shift_uint8 a_9 i_11)] <> 0) /\ (i_11 < l_size) /\ (x_5 <= i_11)) ->
   ((i_8 < l_size) /\ (x_5 <= i_8))) ->
  ((exists i_11 : int. (a_19[(shift_uint8 a_17 i_11)] <> 0) /\
    (a_19[(shift_uint8 a_9 i_11)] <> 0) /\ (i_11 < l_size) /\ (x_5 <= i_11)) ->
   ((a_21 <> 0) /\ (a_23 <> 0))) ->
  ((forall i_11 : int. (i_11 < l_size) -> (x_5 <= i_11) ->
    ((a_19[(shift_uint8 a_17 i_11)] = 0) \/
     (a_19[(shift_uint8 a_9 i_11)] = 0))) -> (l_size = i_8)) ->
  ((i_3 <> (-1)) ->
   (forall i_11 : int. (a_19[(shift_uint8 a_9 i_11)] <> 0) ->
    (a_19[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) -> (i_11 < i_3) ->
    (i_11 < l_size) -> (((l_idle_cpu i_11)) = 0))) ->
  ((i_3 = (-1)) ->
   (forall i_11 : int. (a_19[(shift_uint8 a_9 i_11)] <> 0) ->
    (a_19[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) -> (i_11 < i_9) ->
    (i_11 < l_size) -> (((l_idle_cpu i_11)) = 0))) ->
  ((exists i_11 : int. (a_19[(shift_uint8 a_17 i_11)] <> 0) /\
    (a_19[(shift_uint8 a_9 i_11)] <> 0) /\ (i_11 < l_size) /\ (x_5 <= i_11)) ->
   (forall i_11 : int. (i_11 < i_8) -> (x_5 <= i_11) ->
    ((a_19[(shift_uint8 a_17 i_11)] = 0) \/
     (a_19[(shift_uint8 a_9 i_11)] = 0)))) ->
  ((i_3 <> (-1)) ->
   (forall i_11 : int. (a_19[(shift_uint8 a_9 i_11)] <> 0) ->
    (a_19[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) -> (i_3 <= i_11) ->
    (i_11 < i_9) -> (i_11 < l_size) -> (not (p_idle_core t_8 a_19 i_11)))) ->
  ((i_3 <> (-1)) ->
   (forall i_11 : int. (a_19[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) ->
    (i_11 < l_size) ->
    ((a_19[(shift_uint8 a_17 i_11)] <> 0) \/
     (not (p_idle_core t_8 a_19 i_11))))) ->
  (forall i_11 : int. (0 <= i_11) -> (i_11 < l_size) ->
   ((separated a_20 l_size
      ((shift_uint8
         t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))] 0))
      l_size))) ->
  (forall i_11 : int. let a_29 = (shift_cpumask a i_11) in (0 <= i_11) ->
   (i_11 < l_size) ->
   (((valid_rd t a_29 1)) /\
    ((valid_rw t ((shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_29)] 0))
       l_size)))) ->
  (forall i_11 : int. (0 <= i_11) -> (i_11 < l_size) ->
   ((a_28[(shift_uint8 a_14 i_11)] <> 0) <->
    (a_28[(shift_uint8 a_17 i_11)] <> 0))) ->
  (forall i_11 : int. (a_19[(shift_uint8 a_17 i_11)] <> 0) -> (0 <= i_11) ->
   (i_11 < l_size) -> (a_19[(shift_uint8 a_14 i_11)] <> 0)) ->
  (forall i_11 : int. (a_19[(shift_uint8 a_9 i_11)] <> 0) ->
   (a_19[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) -> (i_11 < i_6) ->
   (i_11 < l_size) -> (((l_idle_cpu i_11)) = 0)) ->
  (forall a_29 : addr. let a_30 = (l_sched_group_cpus a_29) in
   let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
   ((valid_rd t a_30 1)) /\ ((valid_rd t a_31 l_size)) /\
   (forall i_11 : int. (0 <= i_11) -> (i_11 < l_size) ->
    ((separated a_31 l_size
       ((shift_uint8
          t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))] 0))
       l_size)))) ->
  (forall a_29 : addr. let a_30 = (l_sched_group_mask a_29) in
   let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
   ((valid_rd t a_30 1)) /\ ((valid_rd t a_31 l_size)) /\
   (forall i_11 : int. (0 <= i_11) -> (i_11 < l_size) ->
    ((separated a_31 l_size
       ((shift_uint8
          t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))] 0))
       l_size)))) ->
  (forall a_29 : addr. let a_30 = (l_group_balance_mask a_29) in
   let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
   ((valid_rd t a_30 1)) /\ ((valid_rd t a_31 l_size)) /\
   (forall i_11 : int. (0 <= i_11) -> (i_11 < l_size) ->
    ((separated a_31 l_size
       ((shift_uint8
          t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))] 0))
       l_size)))) ->
  (forall i_11 : int. let a_29 = (l_cpu_smt_mask i_11) in
   let a_30 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_29)] 0) in
   (0 <= i_11) -> (i_11 < l_size) ->
   (((valid_rd t a_29 1)) /\ ((valid_rd t a_30 l_size)) /\
    (forall i_12 : int. (0 <= i_12) -> (i_12 < l_size) ->
     ((separated a_30 l_size
        ((shift_uint8
           t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_12)))] 0))
        l_size))))) ->
  ((a_27 = i_6) <-> (i_2 <> 0))

end

(* ---------------------------------------------------------- *)
(* --- Post-condition for 'not_newly_idle_with_idle' (file c11.c, line 67) in 'should_we_balance' --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_not_newly_idle_with_idle_post_2
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import A_schedule_cpumask.A_schedule_cpumask
use import Compound.Compound
use import Cint.Cint
use import Cbits.Cbits
use import A_thread_variables_properties.A_thread_variables_properties

(*
goal WP "expl:Post-condition for 'not_newly_idle_with_idle' (file c11.c, line 67) in 'should_we_balance'":
*)
goal goal35:
  forall i_10 i_9 i_8 i_7 i_6 i_5 i_4 i_3 i_2 i_1 i : int.
  forall t_4 t_3 t_2 t_1 t : map int int.
  forall t_7 t_6 t_5 : map addr int.
  forall t_8 : map addr addr.
  forall a_1 a : addr.
  let a_2 = (shiftfield_f5_lb_env_idle a_1) in
  let x = t_7[a_2] in
  let a_3 = (shiftfield_f5_lb_env_sd a_1) in
  let a_4 = t_8[a_3] in
  let a_5 = (shiftfield_f3_sched_domain_flags a_4) in
  let x_1 = t_7[a_5] in
  let a_6 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_7 = t_8[a_6] in
  let a_8 = (shiftfield_f1_cpumask_bits a_7) in
  let a_9 = t_8[a_8] in
  let a_10 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x_2 = t_7[a_10] in
  let x_3 = t_7[(shift_uint8 a_9 x_2)] in
  let a_11 = (shiftfield_f3_sched_domain_groups a_4) in
  let a_12 = t_8[a_11] in
  let a_13 = (l_group_balance_mask a_12) in
  let a_14 = t_8[(shiftfield_f1_cpumask_bits a_13)] in
  let a_15 = (shift_cpumask a i) in
  let a_16 = (shiftfield_f1_cpumask_bits a_15) in
  let a_17 = t_8[a_16] in
  let a_18 = (shift_uint8 a_17 0) in
  let a_19 = (shift_uint8 a_9 0) in
  let a_20 = (havoc t_6 t_7 a_18 l_size) in
  let a_21 = a_20[(shift_uint8 a_17 i_8)] in
  let a_22 = a_20[(shift_uint8 a_9 i_3)] in
  let a_23 = a_20[(shift_uint8 a_9 i_8)] in
  let a_24 = a_20[(shift_uint8 a_14 i_3)] in
  let a_25 = a_20[a_5] in
  let a_26 = (shift_uint8 a_14 0) in
  let a_27 = a_20[a_10] in
  let x_4 = (land 7 a_25) in
  let x_5 = (to_uint32 i_9) in
  let a_28 = (havoc t_5 t_7 a_18 l_size) in
  (((l_idle_cpu i_5)) <> 0) ->
  (((l_idle_cpu i_6)) <> 0) ->
  (x <> 2) ->
  (((land 7 x_1)) <> 0) ->
  (t_7[(shift_uint8 a_9 i_5)] <> 0) ->
  (t_7[(shift_uint8 a_9 i_6)] <> 0) ->
  (x_3 <> 0) ->
  (t_7[(shift_uint8 a_14 i_5)] <> 0) ->
  (t_7[(shift_uint8 a_14 i_6)] <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= i_5) ->
  (i_5 < l_size) ->
  (0 <= i_6) ->
  (i_6 < l_size) ->
  (0 <= i_9) ->
  (i_9 <= l_size) ->
  (0 <= x_2) ->
  (x_2 < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_8)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((is_uint32 i_1)) ->
  ((is_sint32 i_2)) ->
  ((is_sint32 i_3)) ->
  ((is_sint32 i_4)) ->
  ((is_sint32 i_7)) ->
  ((is_sint32 i_8)) ->
  ((is_sint32 i_9)) ->
  ((is_sint32 i_10)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 x)) ->
  ((is_sint32 x_2)) ->
  ((valid_rd t a_6 1)) ->
  ((valid_rd t a_10 1)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_15 1)) ->
  ((valid_rd t a_7 1)) ->
  ((valid_rd t t_8[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_4 2)) ->
  ((is_sint32 x_1)) ->
  ((valid_rd t a_16 1)) ->
  ((valid_rd t a_8 1)) ->
  ((valid_rd t a_11 1)) ->
  ((valid_rd t a_12 1)) ->
  ((valid_rd t a_13 1)) ->
  ((is_uint8 x_3)) ->
  ((valid_rd t a_18 l_size)) ->
  ((valid_rd t a_19 l_size)) ->
  ((valid_rw t a_18 l_size)) ->
  ((is_uint8 a_21)) ->
  ((is_uint8 a_22)) ->
  ((is_uint8 a_23)) ->
  ((is_uint8 a_24)) ->
  ((is_sint32 a_25)) ->
  ((valid_rd t a_26 l_size)) ->
  ((separated a_18 l_size a_26 l_size)) ->
  (if (((to_uint32 i_8)) < l_size)
   then ((i_10 = i_8) /\ (t_4 = t) /\ (((l_idle_cpu i_10)) <> 0) /\
         ((if (a_27 = i_10) then 1 else 0) = i_2) /\ (0 <= i_10) /\
         (i_10 < l_size) /\ ((valid_rd t_4 a_10 1)) /\
         ((valid_rd t_4 a_3 1)) /\ ((valid_rd t_4 a_5 1)) /\
         ((x_4 <> 0) \/
          ((l_size = i_1) /\
           ((p_idle_core t_8 ((havoc t_6 t_7 a_18 i_1)) i_10)) /\
           (forall i_11 : int. let a_29 = (shift_cpumask a i_11) in
            (0 <= i_11) -> (i_11 < i_1) ->
            (((valid_rd t_4 a_29 1)) /\
             ((valid_rw t_4
                ((shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_29)] 0)) i_1)))) /\
           (forall a_29 : addr. let a_30 = (l_sched_group_cpus a_29) in
            let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
            ((valid_rd t_4 a_30 1)) /\ ((valid_rd t_4 a_31 i_1)) /\
            (forall i_11 : int. (0 <= i_11) -> (i_11 < i_1) ->
             ((separated a_31 i_1
                ((shift_uint8
                   t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))]
                   0)) i_1)))) /\
           (forall a_29 : addr. let a_30 = (l_sched_group_mask a_29) in
            let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
            ((valid_rd t_4 a_30 1)) /\ ((valid_rd t_4 a_31 i_1)) /\
            (forall i_11 : int. (0 <= i_11) -> (i_11 < i_1) ->
             ((separated a_31 i_1
                ((shift_uint8
                   t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))]
                   0)) i_1)))) /\
           (forall a_29 : addr. let a_30 = (l_group_balance_mask a_29) in
            let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
            ((valid_rd t_4 a_30 1)) /\ ((valid_rd t_4 a_31 i_1)) /\
            (forall i_11 : int. (0 <= i_11) -> (i_11 < i_1) ->
             ((separated a_31 i_1
                ((shift_uint8
                   t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))]
                   0)) i_1)))) /\
           (forall i_11 : int. let a_29 = (l_cpu_smt_mask i_11) in
            let a_30 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_29)] 0) in
            (0 <= i_11) -> (i_11 < i_1) ->
            (((valid_rd t_4 a_29 1)) /\ ((valid_rd t_4 a_30 i_1)) /\
             (forall i_12 : int. (0 <= i_12) -> (i_12 < i_1) ->
              ((separated a_30 i_1
                 ((shift_uint8
                    t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_12)))]
                    0)) i_1))))))))
   else ((i_4 = i_3) /\ (t_1 = t) /\
         (if (i_4 = (-1))
          then ((t_2 = t_1) /\ (((l_group_balance_cpu a_12)) = i_7) /\
                ((if (a_27 = i_7) then 1 else 0) = i_2) /\
                ((valid_rd t_2 a_10 1)))
          else ((t_3 = t_1) /\ ((if (a_27 = i_4) then 1 else 0) = i_2) /\
                ((valid_rd t_3 a_10 1)))))) ->
  ((x_4 <> 0) -> (i_3 = (-1))) ->
  ((i_3 <> (-1)) ->
   ((((l_idle_cpu i_3)) <> 0) /\ (a_22 <> 0) /\ (a_24 <> 0) /\ (0 <= i_3) /\
    (i_3 < l_size))) ->
  ((i_3 = (-1)) ->
   (forall i_11 : int. (a_20[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) ->
    (i_11 < l_size) -> (a_20[(shift_uint8 a_17 i_11)] <> 0))) ->
  ((exists i_11 : int. (a_20[(shift_uint8 a_17 i_11)] <> 0) /\
    (a_20[(shift_uint8 a_9 i_11)] <> 0) /\ (i_11 < l_size) /\ (x_5 <= i_11)) ->
   (i_8 < l_size)) ->
  ((exists i_11 : int. (a_20[(shift_uint8 a_17 i_11)] <> 0) /\
    (a_20[(shift_uint8 a_9 i_11)] <> 0) /\ (i_11 < l_size) /\ (x_5 <= i_11)) ->
   ((i_8 < l_size) /\ (x_5 <= i_8))) ->
  ((exists i_11 : int. (a_20[(shift_uint8 a_17 i_11)] <> 0) /\
    (a_20[(shift_uint8 a_9 i_11)] <> 0) /\ (i_11 < l_size) /\ (x_5 <= i_11)) ->
   ((a_21 <> 0) /\ (a_23 <> 0))) ->
  ((forall i_11 : int. (i_11 < l_size) -> (x_5 <= i_11) ->
    ((a_20[(shift_uint8 a_17 i_11)] = 0) \/
     (a_20[(shift_uint8 a_9 i_11)] = 0))) -> (l_size = i_8)) ->
  ((i_3 <> (-1)) ->
   (forall i_11 : int. (a_20[(shift_uint8 a_9 i_11)] <> 0) ->
    (a_20[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) -> (i_11 < i_3) ->
    (i_11 < l_size) -> (((l_idle_cpu i_11)) = 0))) ->
  ((i_3 = (-1)) ->
   (forall i_11 : int. (a_20[(shift_uint8 a_9 i_11)] <> 0) ->
    (a_20[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) -> (i_11 < i_9) ->
    (i_11 < l_size) -> (((l_idle_cpu i_11)) = 0))) ->
  ((exists i_11 : int. (a_20[(shift_uint8 a_17 i_11)] <> 0) /\
    (a_20[(shift_uint8 a_9 i_11)] <> 0) /\ (i_11 < l_size) /\ (x_5 <= i_11)) ->
   (forall i_11 : int. (i_11 < i_8) -> (x_5 <= i_11) ->
    ((a_20[(shift_uint8 a_17 i_11)] = 0) \/
     (a_20[(shift_uint8 a_9 i_11)] = 0)))) ->
  ((i_3 <> (-1)) ->
   (forall i_11 : int. (a_20[(shift_uint8 a_9 i_11)] <> 0) ->
    (a_20[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) -> (i_3 <= i_11) ->
    (i_11 < i_9) -> (i_11 < l_size) -> (not (p_idle_core t_8 a_20 i_11)))) ->
  ((i_3 <> (-1)) ->
   (forall i_11 : int. (a_20[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) ->
    (i_11 < l_size) ->
    ((a_20[(shift_uint8 a_17 i_11)] <> 0) \/
     (not (p_idle_core t_8 a_20 i_11))))) ->
  (forall i_11 : int. (0 <= i_11) -> (i_11 < l_size) ->
   ((separated a_19 l_size
      ((shift_uint8
         t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))] 0))
      l_size))) ->
  (forall i_11 : int. let a_29 = (shift_cpumask a i_11) in (0 <= i_11) ->
   (i_11 < l_size) ->
   (((valid_rd t a_29 1)) /\
    ((valid_rw t ((shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_29)] 0))
       l_size)))) ->
  (forall i_11 : int. (0 <= i_11) -> (i_11 < l_size) ->
   ((a_28[(shift_uint8 a_14 i_11)] <> 0) <->
    (a_28[(shift_uint8 a_17 i_11)] <> 0))) ->
  (forall i_11 : int. (a_20[(shift_uint8 a_17 i_11)] <> 0) -> (0 <= i_11) ->
   (i_11 < l_size) -> (a_20[(shift_uint8 a_14 i_11)] <> 0)) ->
  (forall i_11 : int. (t_7[(shift_uint8 a_9 i_11)] <> 0) ->
   (t_7[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) -> (i_11 < i_6) ->
   (i_11 < l_size) -> (((l_idle_cpu i_11)) = 0)) ->
  (forall a_29 : addr. let a_30 = (l_sched_group_cpus a_29) in
   let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
   ((valid_rd t a_30 1)) /\ ((valid_rd t a_31 l_size)) /\
   (forall i_11 : int. (0 <= i_11) -> (i_11 < l_size) ->
    ((separated a_31 l_size
       ((shift_uint8
          t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))] 0))
       l_size)))) ->
  (forall a_29 : addr. let a_30 = (l_sched_group_mask a_29) in
   let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
   ((valid_rd t a_30 1)) /\ ((valid_rd t a_31 l_size)) /\
   (forall i_11 : int. (0 <= i_11) -> (i_11 < l_size) ->
    ((separated a_31 l_size
       ((shift_uint8
          t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))] 0))
       l_size)))) ->
  (forall a_29 : addr. let a_30 = (l_group_balance_mask a_29) in
   let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
   ((valid_rd t a_30 1)) /\ ((valid_rd t a_31 l_size)) /\
   (forall i_11 : int. (0 <= i_11) -> (i_11 < l_size) ->
    ((separated a_31 l_size
       ((shift_uint8
          t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))] 0))
       l_size)))) ->
  (forall i_11 : int. let a_29 = (l_cpu_smt_mask i_11) in
   let a_30 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_29)] 0) in
   (0 <= i_11) -> (i_11 < l_size) ->
   (((valid_rd t a_29 1)) /\ ((valid_rd t a_30 l_size)) /\
    (forall i_12 : int. (0 <= i_12) -> (i_12 < l_size) ->
     ((separated a_30 l_size
        ((shift_uint8
           t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_12)))] 0))
        l_size))))) ->
  ((x_2 = i_6) <-> (i_2 <> 0))

end

(* ---------------------------------------------------------- *)
(* --- Post-condition for 'not_newly_idle_with_idle_core' (file c11.c, line 77) in 'should_we_balance' --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_not_newly_idle_with_idle_core_post
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import Compound.Compound
use import Cint.Cint
use import Cbits.Cbits
use import A_schedule_cpumask.A_schedule_cpumask
use import A_thread_variables_properties.A_thread_variables_properties

(*
goal WP "expl:Post-condition for 'not_newly_idle_with_idle_core' (file c11.c, line 77) in 'should_we_balance'":
*)
goal goal36:
  forall i_10 i_9 i_8 i_7 i_6 i_5 i_4 i_3 i_2 i_1 i : int.
  forall t_4 t_3 t_2 t_1 t : map int int.
  forall t_8 t_7 t_6 t_5 : map addr int.
  forall t_9 : map addr addr.
  forall a_1 a : addr.
  let a_2 = (shiftfield_f5_lb_env_idle a_1) in
  let x = t_7[a_2] in
  let a_3 = (shiftfield_f5_lb_env_sd a_1) in
  let a_4 = t_9[a_3] in
  let a_5 = (shiftfield_f3_sched_domain_flags a_4) in
  let x_1 = t_7[a_5] in
  let a_6 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_7 = t_9[a_6] in
  let a_8 = (shiftfield_f1_cpumask_bits a_7) in
  let a_9 = t_9[a_8] in
  let a_10 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x_2 = t_7[a_10] in
  let x_3 = t_7[(shift_uint8 a_9 x_2)] in
  let a_11 = (shiftfield_f3_sched_domain_groups a_4) in
  let a_12 = t_9[a_11] in
  let a_13 = (l_group_balance_mask a_12) in
  let a_14 = t_9[(shiftfield_f1_cpumask_bits a_13)] in
  let a_15 = (shift_cpumask a i) in
  let a_16 = (shiftfield_f1_cpumask_bits a_15) in
  let a_17 = t_9[a_16] in
  let a_18 = (shift_uint8 a_17 0) in
  let a_19 = (havoc t_6 t_7 a_18 l_size) in
  let a_20 = (shift_uint8 a_9 0) in
  let a_21 = a_19[(shift_uint8 a_17 i_8)] in
  let a_22 = a_19[(shift_uint8 a_9 i_3)] in
  let a_23 = a_19[(shift_uint8 a_9 i_8)] in
  let a_24 = a_19[(shift_uint8 a_14 i_3)] in
  let a_25 = a_19[a_5] in
  let a_26 = (shift_uint8 a_14 0) in
  let a_27 = a_19[a_10] in
  let x_4 = (to_uint32 i_9) in
  let a_28 = (havoc t_5 t_7 a_18 l_size) in
  (x <> 2) ->
  (((land 7 x_1)) = 0) ->
  (t_7[(shift_uint8 a_9 i_5)] <> 0) ->
  (x_3 <> 0) ->
  (t_7[(shift_uint8 a_14 i_5)] <> 0) ->
  (a_19[(shift_uint8 a_9 i_6)] <> 0) ->
  (a_19[(shift_uint8 a_14 i_6)] <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= i_5) ->
  (i_5 < l_size) ->
  (0 <= i_6) ->
  (i_6 < l_size) ->
  (0 <= i_9) ->
  (i_9 <= l_size) ->
  (0 <= x_2) ->
  (x_2 < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_9)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((is_uint32 i_1)) ->
  ((is_sint32 i_2)) ->
  ((is_sint32 i_3)) ->
  ((is_sint32 i_4)) ->
  ((is_sint32 i_7)) ->
  ((is_sint32 i_8)) ->
  ((is_sint32 i_9)) ->
  ((is_sint32 i_10)) ->
  ((valid_rd t a_1 5)) ->
  ((p_idle_core t_9 t_7 i_5)) ->
  ((is_uint32 x)) ->
  ((is_sint32 x_2)) ->
  ((valid_rd t a_6 1)) ->
  ((valid_rd t a_10 1)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_15 1)) ->
  ((valid_rd t a_7 1)) ->
  ((valid_rd t t_9[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_4 2)) ->
  ((is_sint32 x_1)) ->
  ((valid_rd t a_16 1)) ->
  ((valid_rd t a_8 1)) ->
  ((valid_rd t a_11 1)) ->
  ((valid_rd t a_12 1)) ->
  ((valid_rd t a_13 1)) ->
  ((is_uint8 x_3)) ->
  ((valid_rd t a_18 l_size)) ->
  ((valid_rd t a_20 l_size)) ->
  ((valid_rw t a_18 l_size)) ->
  ((is_uint8 a_21)) ->
  ((is_uint8 a_22)) ->
  ((is_uint8 a_23)) ->
  ((is_uint8 a_24)) ->
  ((is_sint32 a_25)) ->
  ((valid_rd t a_26 l_size)) ->
  ((p_idle_core t_9 a_19 i_6)) ->
  ((separated a_18 l_size a_26 l_size)) ->
  (if (((to_uint32 i_8)) < l_size)
   then ((i_10 = i_8) /\ (t_4 = t) /\ (((l_idle_cpu i_10)) <> 0) /\
         ((if (t_8[a_10] = i_10) then 1 else 0) = i_2) /\ (a_19 = t_8) /\
         (0 <= i_10) /\ (i_10 < l_size) /\ ((valid_rd t_4 a_10 1)) /\
         ((valid_rd t_4 a_3 1)) /\ ((valid_rd t_4 a_5 1)) /\
         ((((land 7 t_8[a_5])) <> 0) \/
          ((l_size = i_1) /\
           ((p_idle_core t_9 ((havoc t_6 t_7 a_18 i_1)) i_10)) /\
           (forall i_11 : int. let a_29 = (shift_cpumask a i_11) in
            (0 <= i_11) -> (i_11 < i_1) ->
            (((valid_rd t_4 a_29 1)) /\
             ((valid_rw t_4
                ((shift_uint8 t_9[(shiftfield_f1_cpumask_bits a_29)] 0)) i_1)))) /\
           (forall a_29 : addr. let a_30 = (l_sched_group_cpus a_29) in
            let a_31 = (shift_uint8 t_9[(shiftfield_f1_cpumask_bits a_30)] 0) in
            ((valid_rd t_4 a_30 1)) /\ ((valid_rd t_4 a_31 i_1)) /\
            (forall i_11 : int. (0 <= i_11) -> (i_11 < i_1) ->
             ((separated a_31 i_1
                ((shift_uint8
                   t_9[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))]
                   0)) i_1)))) /\
           (forall a_29 : addr. let a_30 = (l_sched_group_mask a_29) in
            let a_31 = (shift_uint8 t_9[(shiftfield_f1_cpumask_bits a_30)] 0) in
            ((valid_rd t_4 a_30 1)) /\ ((valid_rd t_4 a_31 i_1)) /\
            (forall i_11 : int. (0 <= i_11) -> (i_11 < i_1) ->
             ((separated a_31 i_1
                ((shift_uint8
                   t_9[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))]
                   0)) i_1)))) /\
           (forall a_29 : addr. let a_30 = (l_group_balance_mask a_29) in
            let a_31 = (shift_uint8 t_9[(shiftfield_f1_cpumask_bits a_30)] 0) in
            ((valid_rd t_4 a_30 1)) /\ ((valid_rd t_4 a_31 i_1)) /\
            (forall i_11 : int. (0 <= i_11) -> (i_11 < i_1) ->
             ((separated a_31 i_1
                ((shift_uint8
                   t_9[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))]
                   0)) i_1)))) /\
           (forall i_11 : int. let a_29 = (l_cpu_smt_mask i_11) in
            let a_30 = (shift_uint8 t_9[(shiftfield_f1_cpumask_bits a_29)] 0) in
            (0 <= i_11) -> (i_11 < i_1) ->
            (((valid_rd t_4 a_29 1)) /\ ((valid_rd t_4 a_30 i_1)) /\
             (forall i_12 : int. (0 <= i_12) -> (i_12 < i_1) ->
              ((separated a_30 i_1
                 ((shift_uint8
                    t_9[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_12)))]
                    0)) i_1))))))))
   else ((i_4 = i_3) /\ (t_1 = t) /\
         (if (i_4 = (-1))
          then ((t_2 = t_1) /\ (((l_group_balance_cpu a_12)) = i_7) /\
                ((if (a_27 = i_7) then 1 else 0) = i_2) /\
                ((valid_rd t_2 a_10 1)))
          else ((t_3 = t_1) /\ ((if (a_27 = i_4) then 1 else 0) = i_2) /\
                ((valid_rd t_3 a_10 1)))))) ->
  ((((land 7 a_25)) <> 0) -> (i_3 = (-1))) ->
  ((i_3 <> (-1)) ->
   ((((l_idle_cpu i_3)) <> 0) /\ (a_22 <> 0) /\ (a_24 <> 0) /\ (0 <= i_3) /\
    (i_3 < l_size))) ->
  ((i_3 = (-1)) ->
   (forall i_11 : int. (a_19[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) ->
    (i_11 < l_size) -> (a_19[(shift_uint8 a_17 i_11)] <> 0))) ->
  ((exists i_11 : int. (a_19[(shift_uint8 a_17 i_11)] <> 0) /\
    (a_19[(shift_uint8 a_9 i_11)] <> 0) /\ (i_11 < l_size) /\ (x_4 <= i_11)) ->
   (i_8 < l_size)) ->
  ((exists i_11 : int. (a_19[(shift_uint8 a_17 i_11)] <> 0) /\
    (a_19[(shift_uint8 a_9 i_11)] <> 0) /\ (i_11 < l_size) /\ (x_4 <= i_11)) ->
   ((i_8 < l_size) /\ (x_4 <= i_8))) ->
  ((exists i_11 : int. (a_19[(shift_uint8 a_17 i_11)] <> 0) /\
    (a_19[(shift_uint8 a_9 i_11)] <> 0) /\ (i_11 < l_size) /\ (x_4 <= i_11)) ->
   ((a_21 <> 0) /\ (a_23 <> 0))) ->
  ((forall i_11 : int. (i_11 < l_size) -> (x_4 <= i_11) ->
    ((a_19[(shift_uint8 a_17 i_11)] = 0) \/
     (a_19[(shift_uint8 a_9 i_11)] = 0))) -> (l_size = i_8)) ->
  ((i_3 <> (-1)) ->
   (forall i_11 : int. (a_19[(shift_uint8 a_9 i_11)] <> 0) ->
    (a_19[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) -> (i_11 < i_3) ->
    (i_11 < l_size) -> (((l_idle_cpu i_11)) = 0))) ->
  ((i_3 = (-1)) ->
   (forall i_11 : int. (a_19[(shift_uint8 a_9 i_11)] <> 0) ->
    (a_19[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) -> (i_11 < i_9) ->
    (i_11 < l_size) -> (((l_idle_cpu i_11)) = 0))) ->
  ((exists i_11 : int. (a_19[(shift_uint8 a_17 i_11)] <> 0) /\
    (a_19[(shift_uint8 a_9 i_11)] <> 0) /\ (i_11 < l_size) /\ (x_4 <= i_11)) ->
   (forall i_11 : int. (i_11 < i_8) -> (x_4 <= i_11) ->
    ((a_19[(shift_uint8 a_17 i_11)] = 0) \/
     (a_19[(shift_uint8 a_9 i_11)] = 0)))) ->
  ((i_3 <> (-1)) ->
   (forall i_11 : int. (a_19[(shift_uint8 a_9 i_11)] <> 0) ->
    (a_19[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) -> (i_3 <= i_11) ->
    (i_11 < i_9) -> (i_11 < l_size) -> (not (p_idle_core t_9 a_19 i_11)))) ->
  ((i_3 <> (-1)) ->
   (forall i_11 : int. (a_19[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) ->
    (i_11 < l_size) ->
    ((a_19[(shift_uint8 a_17 i_11)] <> 0) \/
     (not (p_idle_core t_9 a_19 i_11))))) ->
  (forall i_11 : int. (0 <= i_11) -> (i_11 < l_size) ->
   ((separated a_20 l_size
      ((shift_uint8
         t_9[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))] 0))
      l_size))) ->
  (forall i_11 : int. let a_29 = (shift_cpumask a i_11) in (0 <= i_11) ->
   (i_11 < l_size) ->
   (((valid_rd t a_29 1)) /\
    ((valid_rw t ((shift_uint8 t_9[(shiftfield_f1_cpumask_bits a_29)] 0))
       l_size)))) ->
  (forall i_11 : int. (0 <= i_11) -> (i_11 < l_size) ->
   ((a_28[(shift_uint8 a_14 i_11)] <> 0) <->
    (a_28[(shift_uint8 a_17 i_11)] <> 0))) ->
  (forall i_11 : int. (a_19[(shift_uint8 a_17 i_11)] <> 0) -> (0 <= i_11) ->
   (i_11 < l_size) -> (a_19[(shift_uint8 a_14 i_11)] <> 0)) ->
  (forall a_29 : addr. let a_30 = (l_sched_group_cpus a_29) in
   let a_31 = (shift_uint8 t_9[(shiftfield_f1_cpumask_bits a_30)] 0) in
   ((valid_rd t a_30 1)) /\ ((valid_rd t a_31 l_size)) /\
   (forall i_11 : int. (0 <= i_11) -> (i_11 < l_size) ->
    ((separated a_31 l_size
       ((shift_uint8
          t_9[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))] 0))
       l_size)))) ->
  (forall a_29 : addr. let a_30 = (l_sched_group_mask a_29) in
   let a_31 = (shift_uint8 t_9[(shiftfield_f1_cpumask_bits a_30)] 0) in
   ((valid_rd t a_30 1)) /\ ((valid_rd t a_31 l_size)) /\
   (forall i_11 : int. (0 <= i_11) -> (i_11 < l_size) ->
    ((separated a_31 l_size
       ((shift_uint8
          t_9[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))] 0))
       l_size)))) ->
  (forall a_29 : addr. let a_30 = (l_group_balance_mask a_29) in
   let a_31 = (shift_uint8 t_9[(shiftfield_f1_cpumask_bits a_30)] 0) in
   ((valid_rd t a_30 1)) /\ ((valid_rd t a_31 l_size)) /\
   (forall i_11 : int. (0 <= i_11) -> (i_11 < l_size) ->
    ((separated a_31 l_size
       ((shift_uint8
          t_9[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))] 0))
       l_size)))) ->
  (forall i_11 : int. (a_19[(shift_uint8 a_9 i_11)] <> 0) ->
   (a_19[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) -> (i_11 < i_6) ->
   (i_11 < l_size) -> (not (p_idle_core t_9 a_19 i_11))) ->
  (forall i_11 : int. let a_29 = (l_cpu_smt_mask i_11) in
   let a_30 = (shift_uint8 t_9[(shiftfield_f1_cpumask_bits a_29)] 0) in
   (0 <= i_11) -> (i_11 < l_size) ->
   (((valid_rd t a_29 1)) /\ ((valid_rd t a_30 l_size)) /\
    (forall i_12 : int. (0 <= i_12) -> (i_12 < l_size) ->
     ((separated a_30 l_size
        ((shift_uint8
           t_9[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_12)))] 0))
        l_size))))) ->
  ((a_27 = i_6) <-> (i_2 <> 0))

end

(* ---------------------------------------------------------- *)
(* --- Post-condition for 'not_newly_idle_with_idle_core' (file c11.c, line 81) in 'should_we_balance' --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_not_newly_idle_with_idle_core_post_2
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import Compound.Compound
use import Cint.Cint
use import Cbits.Cbits
use import A_schedule_cpumask.A_schedule_cpumask
use import A_thread_variables_properties.A_thread_variables_properties

(*
goal WP "expl:Post-condition for 'not_newly_idle_with_idle_core' (file c11.c, line 81) in 'should_we_balance'":
*)
goal goal37:
  forall i_10 i_9 i_8 i_7 i_6 i_5 i_4 i_3 i_2 i_1 i : int.
  forall t_4 t_3 t_2 t_1 t : map int int.
  forall t_8 t_7 t_6 t_5 : map addr int.
  forall t_11 t_10 t_9 : map addr addr.
  forall a_1 a : addr.
  let a_2 = (shiftfield_f5_lb_env_idle a_1) in
  let x = t_7[a_2] in
  let a_3 = (shiftfield_f5_lb_env_sd a_1) in
  let a_4 = t_9[a_3] in
  let a_5 = (shiftfield_f3_sched_domain_flags a_4) in
  let x_1 = t_7[a_5] in
  let a_6 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_7 = t_9[a_6] in
  let a_8 = (shiftfield_f1_cpumask_bits a_7) in
  let a_9 = t_9[a_8] in
  let a_10 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x_2 = t_7[a_10] in
  let x_3 = t_7[(shift_uint8 a_9 x_2)] in
  let a_11 = (shiftfield_f3_sched_domain_groups a_4) in
  let a_12 = t_9[a_11] in
  let a_13 = (l_group_balance_mask a_12) in
  let a_14 = t_9[(shiftfield_f1_cpumask_bits a_13)] in
  let a_15 = (shift_cpumask a i) in
  let a_16 = (shiftfield_f1_cpumask_bits a_15) in
  let a_17 = t_9[a_16] in
  let a_18 = (shift_uint8 a_17 0) in
  let a_19 = (shift_uint8 a_9 0) in
  let a_20 = (havoc t_6 t_7 a_18 l_size) in
  let a_21 = a_20[(shift_uint8 a_17 i_8)] in
  let a_22 = a_20[(shift_uint8 a_9 i_3)] in
  let a_23 = a_20[(shift_uint8 a_9 i_8)] in
  let a_24 = a_20[(shift_uint8 a_14 i_3)] in
  let a_25 = a_20[a_5] in
  let a_26 = (shift_uint8 a_14 0) in
  let x_4 = t_8[a_10] in
  let a_27 = (shiftfield_f3_sched_domain_flags t_10[a_3]) in
  let x_5 = (to_uint32 i_9) in
  let a_28 = (havoc t_5 t_7 a_18 l_size) in
  (x <> 2) ->
  (((land 7 x_1)) = 0) ->
  (t_7[(shift_uint8 a_9 i_5)] <> 0) ->
  (t_7[(shift_uint8 a_9 i_6)] <> 0) ->
  (x_3 <> 0) ->
  (t_7[(shift_uint8 a_14 i_5)] <> 0) ->
  (t_7[(shift_uint8 a_14 i_6)] <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= i_5) ->
  (i_5 < l_size) ->
  (0 <= i_6) ->
  (i_6 < l_size) ->
  (0 <= i_9) ->
  (i_9 <= l_size) ->
  (0 <= x_2) ->
  (x_2 < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_9)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((is_uint32 i_1)) ->
  ((is_sint32 i_2)) ->
  ((is_sint32 i_3)) ->
  ((is_sint32 i_4)) ->
  ((is_sint32 i_7)) ->
  ((is_sint32 i_8)) ->
  ((is_sint32 i_9)) ->
  ((is_sint32 i_10)) ->
  ((valid_rd t a_1 5)) ->
  ((p_idle_core t_9 t_7 i_5)) ->
  ((p_idle_core t_9 t_7 i_6)) ->
  ((is_uint32 x)) ->
  ((is_sint32 x_2)) ->
  ((valid_rd t a_6 1)) ->
  ((valid_rd t a_10 1)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_15 1)) ->
  ((valid_rd t a_7 1)) ->
  ((valid_rd t t_9[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_4 2)) ->
  ((is_sint32 x_1)) ->
  ((valid_rd t a_16 1)) ->
  ((valid_rd t a_8 1)) ->
  ((valid_rd t a_11 1)) ->
  ((valid_rd t a_12 1)) ->
  ((valid_rd t a_13 1)) ->
  ((is_uint8 x_3)) ->
  ((valid_rd t a_18 l_size)) ->
  ((valid_rd t a_19 l_size)) ->
  ((valid_rw t a_18 l_size)) ->
  ((is_uint8 a_21)) ->
  ((is_uint8 a_22)) ->
  ((is_uint8 a_23)) ->
  ((is_uint8 a_24)) ->
  ((is_sint32 a_25)) ->
  ((valid_rd t a_26 l_size)) ->
  ((separated a_18 l_size a_26 l_size)) ->
  (if (((to_uint32 i_8)) < l_size)
   then ((i_10 = i_8) /\ (t_10 = t_9) /\ (t_4 = t) /\
         (((l_idle_cpu i_10)) <> 0) /\
         ((if (x_4 = i_10) then 1 else 0) = i_2) /\
         (((havoc t_6 t_7 ((shift_uint8 t_10[a_16] 0)) l_size)) = t_8) /\
         (0 <= i_10) /\ (i_10 < l_size) /\ ((valid_rd t_4 a_10 1)) /\
         ((valid_rd t_4 a_3 1)) /\ ((valid_rd t_4 a_27 1)) /\
         ((((land 7 t_8[a_27])) <> 0) \/
          ((t_11 = t_10) /\ (l_size = i_1) /\
           ((p_idle_core t_11
              ((havoc t_6 t_7 ((shift_uint8 t_11[a_16] 0)) i_1)) i_10)) /\
           (forall i_11 : int. let a_29 = (shift_cpumask a i_11) in
            (0 <= i_11) -> (i_11 < i_1) ->
            (((valid_rd t_4 a_29 1)) /\
             ((valid_rw t_4
                ((shift_uint8 t_11[(shiftfield_f1_cpumask_bits a_29)] 0))
                i_1)))) /\
           (forall a_29 : addr. let a_30 = (l_sched_group_cpus a_29) in
            let a_31 = (shift_uint8 t_11[(shiftfield_f1_cpumask_bits a_30)]
                         0) in ((valid_rd t_4 a_30 1)) /\
            ((valid_rd t_4 a_31 i_1)) /\
            (forall i_11 : int. (0 <= i_11) -> (i_11 < i_1) ->
             ((separated a_31 i_1
                ((shift_uint8
                   t_11[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))]
                   0)) i_1)))) /\
           (forall a_29 : addr. let a_30 = (l_sched_group_mask a_29) in
            let a_31 = (shift_uint8 t_11[(shiftfield_f1_cpumask_bits a_30)]
                         0) in ((valid_rd t_4 a_30 1)) /\
            ((valid_rd t_4 a_31 i_1)) /\
            (forall i_11 : int. (0 <= i_11) -> (i_11 < i_1) ->
             ((separated a_31 i_1
                ((shift_uint8
                   t_11[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))]
                   0)) i_1)))) /\
           (forall a_29 : addr. let a_30 = (l_group_balance_mask a_29) in
            let a_31 = (shift_uint8 t_11[(shiftfield_f1_cpumask_bits a_30)]
                         0) in ((valid_rd t_4 a_30 1)) /\
            ((valid_rd t_4 a_31 i_1)) /\
            (forall i_11 : int. (0 <= i_11) -> (i_11 < i_1) ->
             ((separated a_31 i_1
                ((shift_uint8
                   t_11[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))]
                   0)) i_1)))) /\
           (forall i_11 : int. let a_29 = (l_cpu_smt_mask i_11) in
            let a_30 = (shift_uint8 t_11[(shiftfield_f1_cpumask_bits a_29)]
                         0) in (0 <= i_11) -> (i_11 < i_1) ->
            (((valid_rd t_4 a_29 1)) /\ ((valid_rd t_4 a_30 i_1)) /\
             (forall i_12 : int. (0 <= i_12) -> (i_12 < i_1) ->
              ((separated a_30 i_1
                 ((shift_uint8
                    t_11[(shiftfield_f1_cpumask_bits
                           ((shift_cpumask a i_12)))] 0)) i_1))))))))
   else ((i_4 = i_3) /\ (t_1 = t) /\ (a_20 = t_8) /\
         (if (i_4 = (-1))
          then ((t_2 = t_1) /\ ((if (x_4 = i_7) then 1 else 0) = i_2) /\
                (((l_group_balance_cpu a_12)) = i_7) /\
                ((valid_rd t_2 a_10 1)))
          else ((t_3 = t_1) /\ ((if (x_4 = i_4) then 1 else 0) = i_2) /\
                ((valid_rd t_3 a_10 1)))))) ->
  ((((land 7 a_25)) <> 0) -> (i_3 = (-1))) ->
  ((i_3 <> (-1)) ->
   ((((l_idle_cpu i_3)) <> 0) /\ (a_22 <> 0) /\ (a_24 <> 0) /\ (0 <= i_3) /\
    (i_3 < l_size))) ->
  ((i_3 = (-1)) ->
   (forall i_11 : int. (a_20[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) ->
    (i_11 < l_size) -> (a_20[(shift_uint8 a_17 i_11)] <> 0))) ->
  ((exists i_11 : int. (a_20[(shift_uint8 a_17 i_11)] <> 0) /\
    (a_20[(shift_uint8 a_9 i_11)] <> 0) /\ (i_11 < l_size) /\ (x_5 <= i_11)) ->
   (i_8 < l_size)) ->
  ((exists i_11 : int. (a_20[(shift_uint8 a_17 i_11)] <> 0) /\
    (a_20[(shift_uint8 a_9 i_11)] <> 0) /\ (i_11 < l_size) /\ (x_5 <= i_11)) ->
   ((i_8 < l_size) /\ (x_5 <= i_8))) ->
  ((exists i_11 : int. (a_20[(shift_uint8 a_17 i_11)] <> 0) /\
    (a_20[(shift_uint8 a_9 i_11)] <> 0) /\ (i_11 < l_size) /\ (x_5 <= i_11)) ->
   ((a_21 <> 0) /\ (a_23 <> 0))) ->
  ((forall i_11 : int. (i_11 < l_size) -> (x_5 <= i_11) ->
    ((a_20[(shift_uint8 a_17 i_11)] = 0) \/
     (a_20[(shift_uint8 a_9 i_11)] = 0))) -> (l_size = i_8)) ->
  ((i_3 <> (-1)) ->
   (forall i_11 : int. (a_20[(shift_uint8 a_9 i_11)] <> 0) ->
    (a_20[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) -> (i_11 < i_3) ->
    (i_11 < l_size) -> (((l_idle_cpu i_11)) = 0))) ->
  ((i_3 = (-1)) ->
   (forall i_11 : int. (a_20[(shift_uint8 a_9 i_11)] <> 0) ->
    (a_20[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) -> (i_11 < i_9) ->
    (i_11 < l_size) -> (((l_idle_cpu i_11)) = 0))) ->
  ((exists i_11 : int. (a_20[(shift_uint8 a_17 i_11)] <> 0) /\
    (a_20[(shift_uint8 a_9 i_11)] <> 0) /\ (i_11 < l_size) /\ (x_5 <= i_11)) ->
   (forall i_11 : int. (i_11 < i_8) -> (x_5 <= i_11) ->
    ((a_20[(shift_uint8 a_17 i_11)] = 0) \/
     (a_20[(shift_uint8 a_9 i_11)] = 0)))) ->
  ((i_3 <> (-1)) ->
   (forall i_11 : int. (a_20[(shift_uint8 a_9 i_11)] <> 0) ->
    (a_20[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) -> (i_3 <= i_11) ->
    (i_11 < i_9) -> (i_11 < l_size) -> (not (p_idle_core t_9 a_20 i_11)))) ->
  ((i_3 <> (-1)) ->
   (forall i_11 : int. (a_20[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) ->
    (i_11 < l_size) ->
    ((a_20[(shift_uint8 a_17 i_11)] <> 0) \/
     (not (p_idle_core t_9 a_20 i_11))))) ->
  (forall i_11 : int. (0 <= i_11) -> (i_11 < l_size) ->
   ((separated a_19 l_size
      ((shift_uint8
         t_9[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))] 0))
      l_size))) ->
  (forall i_11 : int. let a_29 = (shift_cpumask a i_11) in (0 <= i_11) ->
   (i_11 < l_size) ->
   (((valid_rd t a_29 1)) /\
    ((valid_rw t ((shift_uint8 t_9[(shiftfield_f1_cpumask_bits a_29)] 0))
       l_size)))) ->
  (forall i_11 : int. (0 <= i_11) -> (i_11 < l_size) ->
   ((a_28[(shift_uint8 a_14 i_11)] <> 0) <->
    (a_28[(shift_uint8 a_17 i_11)] <> 0))) ->
  (forall i_11 : int. (a_20[(shift_uint8 a_17 i_11)] <> 0) -> (0 <= i_11) ->
   (i_11 < l_size) -> (a_20[(shift_uint8 a_14 i_11)] <> 0)) ->
  (forall i_11 : int. (t_7[(shift_uint8 a_9 i_11)] <> 0) ->
   (t_7[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) -> (i_11 < i_6) ->
   (i_11 < l_size) -> (not (p_idle_core t_9 t_7 i_11))) ->
  (forall a_29 : addr. let a_30 = (l_sched_group_cpus a_29) in
   let a_31 = (shift_uint8 t_9[(shiftfield_f1_cpumask_bits a_30)] 0) in
   ((valid_rd t a_30 1)) /\ ((valid_rd t a_31 l_size)) /\
   (forall i_11 : int. (0 <= i_11) -> (i_11 < l_size) ->
    ((separated a_31 l_size
       ((shift_uint8
          t_9[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))] 0))
       l_size)))) ->
  (forall a_29 : addr. let a_30 = (l_sched_group_mask a_29) in
   let a_31 = (shift_uint8 t_9[(shiftfield_f1_cpumask_bits a_30)] 0) in
   ((valid_rd t a_30 1)) /\ ((valid_rd t a_31 l_size)) /\
   (forall i_11 : int. (0 <= i_11) -> (i_11 < l_size) ->
    ((separated a_31 l_size
       ((shift_uint8
          t_9[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))] 0))
       l_size)))) ->
  (forall a_29 : addr. let a_30 = (l_group_balance_mask a_29) in
   let a_31 = (shift_uint8 t_9[(shiftfield_f1_cpumask_bits a_30)] 0) in
   ((valid_rd t a_30 1)) /\ ((valid_rd t a_31 l_size)) /\
   (forall i_11 : int. (0 <= i_11) -> (i_11 < l_size) ->
    ((separated a_31 l_size
       ((shift_uint8
          t_9[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))] 0))
       l_size)))) ->
  (forall i_11 : int. let a_29 = (l_cpu_smt_mask i_11) in
   let a_30 = (shift_uint8 t_9[(shiftfield_f1_cpumask_bits a_29)] 0) in
   (0 <= i_11) -> (i_11 < l_size) ->
   (((valid_rd t a_29 1)) /\ ((valid_rd t a_30 l_size)) /\
    (forall i_12 : int. (0 <= i_12) -> (i_12 < l_size) ->
     ((separated a_30 l_size
        ((shift_uint8
           t_9[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_12)))] 0))
        l_size))))) ->
  ((x_2 = i_6) <-> (i_2 <> 0))

end

(* ---------------------------------------------------------- *)
(* --- Post-condition for 'not_newly_idle_with_idle_cpu' (file c11.c, line 92) in 'should_we_balance' --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_not_newly_idle_with_idle_cpu_post
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import A_schedule_cpumask.A_schedule_cpumask
use import Compound.Compound
use import Cint.Cint
use import Cbits.Cbits
use import A_thread_variables_properties.A_thread_variables_properties

(*
goal WP "expl:Post-condition for 'not_newly_idle_with_idle_cpu' (file c11.c, line 92) in 'should_we_balance'":
*)
goal goal38:
  forall i_10 i_9 i_8 i_7 i_6 i_5 i_4 i_3 i_2 i_1 i : int.
  forall t_4 t_3 t_2 t_1 t : map int int.
  forall t_7 t_6 t_5 : map addr int.
  forall t_8 : map addr addr.
  forall a_1 a : addr.
  let a_2 = (shiftfield_f5_lb_env_idle a_1) in
  let x = t_7[a_2] in
  let a_3 = (shiftfield_f5_lb_env_sd a_1) in
  let a_4 = t_8[a_3] in
  let a_5 = (shiftfield_f3_sched_domain_flags a_4) in
  let x_1 = t_7[a_5] in
  let a_6 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_7 = t_8[a_6] in
  let a_8 = (shiftfield_f1_cpumask_bits a_7) in
  let a_9 = t_8[a_8] in
  let a_10 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x_2 = t_7[a_10] in
  let x_3 = t_7[(shift_uint8 a_9 x_2)] in
  let a_11 = (shiftfield_f3_sched_domain_groups a_4) in
  let a_12 = t_8[a_11] in
  let a_13 = (l_group_balance_mask a_12) in
  let a_14 = t_8[(shiftfield_f1_cpumask_bits a_13)] in
  let a_15 = (shift_cpumask a i) in
  let a_16 = (shiftfield_f1_cpumask_bits a_15) in
  let a_17 = t_8[a_16] in
  let a_18 = (shift_uint8 a_17 0) in
  let a_19 = (havoc t_6 t_7 a_18 l_size) in
  let a_20 = (shift_uint8 a_9 0) in
  let a_21 = a_19[(shift_uint8 a_17 i_8)] in
  let a_22 = a_19[(shift_uint8 a_9 i_3)] in
  let a_23 = a_19[(shift_uint8 a_9 i_8)] in
  let a_24 = a_19[(shift_uint8 a_14 i_3)] in
  let a_25 = a_19[a_5] in
  let a_26 = (shift_uint8 a_14 0) in
  let a_27 = a_19[a_10] in
  let x_4 = (land 7 a_25) in
  let x_5 = (to_uint32 i_9) in
  let a_28 = (havoc t_5 t_7 a_18 l_size) in
  (((l_idle_cpu i_5)) <> 0) ->
  (((l_idle_cpu i_6)) <> 0) ->
  (x <> 2) ->
  (((land 7 x_1)) = 0) ->
  (t_7[(shift_uint8 a_9 i_5)] <> 0) ->
  (x_3 <> 0) ->
  (t_7[(shift_uint8 a_14 i_5)] <> 0) ->
  (a_19[(shift_uint8 a_9 i_6)] <> 0) ->
  (a_19[(shift_uint8 a_14 i_6)] <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= i_5) ->
  (i_5 < l_size) ->
  (0 <= i_6) ->
  (i_6 < l_size) ->
  (0 <= i_9) ->
  (i_9 <= l_size) ->
  (0 <= x_2) ->
  (x_2 < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_8)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((is_uint32 i_1)) ->
  ((is_sint32 i_2)) ->
  ((is_sint32 i_3)) ->
  ((is_sint32 i_4)) ->
  ((is_sint32 i_7)) ->
  ((is_sint32 i_8)) ->
  ((is_sint32 i_9)) ->
  ((is_sint32 i_10)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 x)) ->
  ((is_sint32 x_2)) ->
  ((valid_rd t a_6 1)) ->
  ((valid_rd t a_10 1)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_15 1)) ->
  ((valid_rd t a_7 1)) ->
  ((valid_rd t t_8[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_4 2)) ->
  ((is_sint32 x_1)) ->
  ((valid_rd t a_16 1)) ->
  ((valid_rd t a_8 1)) ->
  ((valid_rd t a_11 1)) ->
  ((valid_rd t a_12 1)) ->
  ((valid_rd t a_13 1)) ->
  ((is_uint8 x_3)) ->
  ((valid_rd t a_18 l_size)) ->
  ((valid_rd t a_20 l_size)) ->
  ((valid_rw t a_18 l_size)) ->
  ((is_uint8 a_21)) ->
  ((is_uint8 a_22)) ->
  ((is_uint8 a_23)) ->
  ((is_uint8 a_24)) ->
  ((is_sint32 a_25)) ->
  ((valid_rd t a_26 l_size)) ->
  ((separated a_18 l_size a_26 l_size)) ->
  (if (((to_uint32 i_8)) < l_size)
   then ((i_10 = i_8) /\ (t_4 = t) /\ (((l_idle_cpu i_10)) <> 0) /\
         ((if (a_27 = i_10) then 1 else 0) = i_2) /\ (0 <= i_10) /\
         (i_10 < l_size) /\ ((valid_rd t_4 a_10 1)) /\
         ((valid_rd t_4 a_3 1)) /\ ((valid_rd t_4 a_5 1)) /\
         ((x_4 <> 0) \/
          ((l_size = i_1) /\
           ((p_idle_core t_8 ((havoc t_6 t_7 a_18 i_1)) i_10)) /\
           (forall i_11 : int. let a_29 = (shift_cpumask a i_11) in
            (0 <= i_11) -> (i_11 < i_1) ->
            (((valid_rd t_4 a_29 1)) /\
             ((valid_rw t_4
                ((shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_29)] 0)) i_1)))) /\
           (forall a_29 : addr. let a_30 = (l_sched_group_cpus a_29) in
            let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
            ((valid_rd t_4 a_30 1)) /\ ((valid_rd t_4 a_31 i_1)) /\
            (forall i_11 : int. (0 <= i_11) -> (i_11 < i_1) ->
             ((separated a_31 i_1
                ((shift_uint8
                   t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))]
                   0)) i_1)))) /\
           (forall a_29 : addr. let a_30 = (l_sched_group_mask a_29) in
            let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
            ((valid_rd t_4 a_30 1)) /\ ((valid_rd t_4 a_31 i_1)) /\
            (forall i_11 : int. (0 <= i_11) -> (i_11 < i_1) ->
             ((separated a_31 i_1
                ((shift_uint8
                   t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))]
                   0)) i_1)))) /\
           (forall a_29 : addr. let a_30 = (l_group_balance_mask a_29) in
            let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
            ((valid_rd t_4 a_30 1)) /\ ((valid_rd t_4 a_31 i_1)) /\
            (forall i_11 : int. (0 <= i_11) -> (i_11 < i_1) ->
             ((separated a_31 i_1
                ((shift_uint8
                   t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))]
                   0)) i_1)))) /\
           (forall i_11 : int. let a_29 = (l_cpu_smt_mask i_11) in
            let a_30 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_29)] 0) in
            (0 <= i_11) -> (i_11 < i_1) ->
            (((valid_rd t_4 a_29 1)) /\ ((valid_rd t_4 a_30 i_1)) /\
             (forall i_12 : int. (0 <= i_12) -> (i_12 < i_1) ->
              ((separated a_30 i_1
                 ((shift_uint8
                    t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_12)))]
                    0)) i_1))))))))
   else ((i_4 = i_3) /\ (t_1 = t) /\
         (if (i_4 = (-1))
          then ((t_2 = t_1) /\ (((l_group_balance_cpu a_12)) = i_7) /\
                ((if (a_27 = i_7) then 1 else 0) = i_2) /\
                ((valid_rd t_2 a_10 1)))
          else ((t_3 = t_1) /\ ((if (a_27 = i_4) then 1 else 0) = i_2) /\
                ((valid_rd t_3 a_10 1)))))) ->
  ((x_4 <> 0) -> (i_3 = (-1))) ->
  ((i_3 <> (-1)) ->
   ((((l_idle_cpu i_3)) <> 0) /\ (a_22 <> 0) /\ (a_24 <> 0) /\ (0 <= i_3) /\
    (i_3 < l_size))) ->
  ((i_3 = (-1)) ->
   (forall i_11 : int. (a_19[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) ->
    (i_11 < l_size) -> (a_19[(shift_uint8 a_17 i_11)] <> 0))) ->
  ((exists i_11 : int. (a_19[(shift_uint8 a_17 i_11)] <> 0) /\
    (a_19[(shift_uint8 a_9 i_11)] <> 0) /\ (i_11 < l_size) /\ (x_5 <= i_11)) ->
   (i_8 < l_size)) ->
  ((exists i_11 : int. (a_19[(shift_uint8 a_17 i_11)] <> 0) /\
    (a_19[(shift_uint8 a_9 i_11)] <> 0) /\ (i_11 < l_size) /\ (x_5 <= i_11)) ->
   ((i_8 < l_size) /\ (x_5 <= i_8))) ->
  ((exists i_11 : int. (a_19[(shift_uint8 a_17 i_11)] <> 0) /\
    (a_19[(shift_uint8 a_9 i_11)] <> 0) /\ (i_11 < l_size) /\ (x_5 <= i_11)) ->
   ((a_21 <> 0) /\ (a_23 <> 0))) ->
  ((forall i_11 : int. (i_11 < l_size) -> (x_5 <= i_11) ->
    ((a_19[(shift_uint8 a_17 i_11)] = 0) \/
     (a_19[(shift_uint8 a_9 i_11)] = 0))) -> (l_size = i_8)) ->
  ((i_3 <> (-1)) ->
   (forall i_11 : int. (a_19[(shift_uint8 a_9 i_11)] <> 0) ->
    (a_19[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) -> (i_11 < i_3) ->
    (i_11 < l_size) -> (((l_idle_cpu i_11)) = 0))) ->
  ((i_3 = (-1)) ->
   (forall i_11 : int. (a_19[(shift_uint8 a_9 i_11)] <> 0) ->
    (a_19[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) -> (i_11 < i_9) ->
    (i_11 < l_size) -> (((l_idle_cpu i_11)) = 0))) ->
  ((exists i_11 : int. (a_19[(shift_uint8 a_17 i_11)] <> 0) /\
    (a_19[(shift_uint8 a_9 i_11)] <> 0) /\ (i_11 < l_size) /\ (x_5 <= i_11)) ->
   (forall i_11 : int. (i_11 < i_8) -> (x_5 <= i_11) ->
    ((a_19[(shift_uint8 a_17 i_11)] = 0) \/
     (a_19[(shift_uint8 a_9 i_11)] = 0)))) ->
  ((i_3 <> (-1)) ->
   (forall i_11 : int. (a_19[(shift_uint8 a_9 i_11)] <> 0) ->
    (a_19[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) -> (i_3 <= i_11) ->
    (i_11 < i_9) -> (i_11 < l_size) -> (not (p_idle_core t_8 a_19 i_11)))) ->
  ((i_3 <> (-1)) ->
   (forall i_11 : int. (a_19[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) ->
    (i_11 < l_size) ->
    ((a_19[(shift_uint8 a_17 i_11)] <> 0) \/
     (not (p_idle_core t_8 a_19 i_11))))) ->
  (forall i_11 : int. (0 <= i_11) -> (i_11 < l_size) ->
   ((separated a_20 l_size
      ((shift_uint8
         t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))] 0))
      l_size))) ->
  (forall i_11 : int. let a_29 = (shift_cpumask a i_11) in (0 <= i_11) ->
   (i_11 < l_size) ->
   (((valid_rd t a_29 1)) /\
    ((valid_rw t ((shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_29)] 0))
       l_size)))) ->
  (forall i_11 : int. (0 <= i_11) -> (i_11 < l_size) ->
   ((a_28[(shift_uint8 a_14 i_11)] <> 0) <->
    (a_28[(shift_uint8 a_17 i_11)] <> 0))) ->
  (forall i_11 : int. (a_19[(shift_uint8 a_17 i_11)] <> 0) -> (0 <= i_11) ->
   (i_11 < l_size) -> (a_19[(shift_uint8 a_14 i_11)] <> 0)) ->
  (forall i_11 : int. (t_7[(shift_uint8 a_9 i_11)] <> 0) ->
   (t_7[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) -> (i_11 < l_size) ->
   (not (p_idle_core t_8 t_7 i_11))) ->
  (forall i_11 : int. (a_19[(shift_uint8 a_9 i_11)] <> 0) ->
   (a_19[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) -> (i_11 < i_6) ->
   (i_11 < l_size) -> (((l_idle_cpu i_11)) = 0)) ->
  (forall a_29 : addr. let a_30 = (l_sched_group_cpus a_29) in
   let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
   ((valid_rd t a_30 1)) /\ ((valid_rd t a_31 l_size)) /\
   (forall i_11 : int. (0 <= i_11) -> (i_11 < l_size) ->
    ((separated a_31 l_size
       ((shift_uint8
          t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))] 0))
       l_size)))) ->
  (forall a_29 : addr. let a_30 = (l_sched_group_mask a_29) in
   let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
   ((valid_rd t a_30 1)) /\ ((valid_rd t a_31 l_size)) /\
   (forall i_11 : int. (0 <= i_11) -> (i_11 < l_size) ->
    ((separated a_31 l_size
       ((shift_uint8
          t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))] 0))
       l_size)))) ->
  (forall a_29 : addr. let a_30 = (l_group_balance_mask a_29) in
   let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
   ((valid_rd t a_30 1)) /\ ((valid_rd t a_31 l_size)) /\
   (forall i_11 : int. (0 <= i_11) -> (i_11 < l_size) ->
    ((separated a_31 l_size
       ((shift_uint8
          t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))] 0))
       l_size)))) ->
  (forall i_11 : int. let a_29 = (l_cpu_smt_mask i_11) in
   let a_30 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_29)] 0) in
   (0 <= i_11) -> (i_11 < l_size) ->
   (((valid_rd t a_29 1)) /\ ((valid_rd t a_30 l_size)) /\
    (forall i_12 : int. (0 <= i_12) -> (i_12 < l_size) ->
     ((separated a_30 l_size
        ((shift_uint8
           t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_12)))] 0))
        l_size))))) ->
  ((a_27 = i_6) <-> (i_2 <> 0))

end

(* ---------------------------------------------------------- *)
(* --- Post-condition for 'not_newly_idle_with_idle_cpu' (file c11.c, line 96) in 'should_we_balance' --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_not_newly_idle_with_idle_cpu_post_2
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import A_schedule_cpumask.A_schedule_cpumask
use import Compound.Compound
use import Cint.Cint
use import Cbits.Cbits
use import A_thread_variables_properties.A_thread_variables_properties

(*
goal WP "expl:Post-condition for 'not_newly_idle_with_idle_cpu' (file c11.c, line 96) in 'should_we_balance'":
*)
goal goal39:
  forall i_10 i_9 i_8 i_7 i_6 i_5 i_4 i_3 i_2 i_1 i : int.
  forall t_4 t_3 t_2 t_1 t : map int int.
  forall t_7 t_6 t_5 : map addr int.
  forall t_8 : map addr addr.
  forall a_1 a : addr.
  let a_2 = (shiftfield_f5_lb_env_idle a_1) in
  let x = t_7[a_2] in
  let a_3 = (shiftfield_f5_lb_env_sd a_1) in
  let a_4 = t_8[a_3] in
  let a_5 = (shiftfield_f3_sched_domain_flags a_4) in
  let x_1 = t_7[a_5] in
  let a_6 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_7 = t_8[a_6] in
  let a_8 = (shiftfield_f1_cpumask_bits a_7) in
  let a_9 = t_8[a_8] in
  let a_10 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x_2 = t_7[a_10] in
  let x_3 = t_7[(shift_uint8 a_9 x_2)] in
  let a_11 = (shiftfield_f3_sched_domain_groups a_4) in
  let a_12 = t_8[a_11] in
  let a_13 = (l_group_balance_mask a_12) in
  let a_14 = t_8[(shiftfield_f1_cpumask_bits a_13)] in
  let a_15 = (shift_cpumask a i) in
  let a_16 = (shiftfield_f1_cpumask_bits a_15) in
  let a_17 = t_8[a_16] in
  let a_18 = (shift_uint8 a_17 0) in
  let a_19 = (shift_uint8 a_9 0) in
  let a_20 = (havoc t_6 t_7 a_18 l_size) in
  let a_21 = a_20[(shift_uint8 a_17 i_8)] in
  let a_22 = a_20[(shift_uint8 a_9 i_3)] in
  let a_23 = a_20[(shift_uint8 a_9 i_8)] in
  let a_24 = a_20[(shift_uint8 a_14 i_3)] in
  let a_25 = a_20[a_5] in
  let a_26 = (shift_uint8 a_14 0) in
  let a_27 = a_20[a_10] in
  let x_4 = (land 7 a_25) in
  let x_5 = (to_uint32 i_9) in
  let a_28 = (havoc t_5 t_7 a_18 l_size) in
  (((l_idle_cpu i_5)) <> 0) ->
  (((l_idle_cpu i_6)) <> 0) ->
  (x <> 2) ->
  (((land 7 x_1)) = 0) ->
  (t_7[(shift_uint8 a_9 i_5)] <> 0) ->
  (t_7[(shift_uint8 a_9 i_6)] <> 0) ->
  (x_3 <> 0) ->
  (t_7[(shift_uint8 a_14 i_5)] <> 0) ->
  (t_7[(shift_uint8 a_14 i_6)] <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= i_5) ->
  (i_5 < l_size) ->
  (0 <= i_6) ->
  (i_6 < l_size) ->
  (0 <= i_9) ->
  (i_9 <= l_size) ->
  (0 <= x_2) ->
  (x_2 < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_8)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((is_uint32 i_1)) ->
  ((is_sint32 i_2)) ->
  ((is_sint32 i_3)) ->
  ((is_sint32 i_4)) ->
  ((is_sint32 i_7)) ->
  ((is_sint32 i_8)) ->
  ((is_sint32 i_9)) ->
  ((is_sint32 i_10)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 x)) ->
  ((is_sint32 x_2)) ->
  ((valid_rd t a_6 1)) ->
  ((valid_rd t a_10 1)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_15 1)) ->
  ((valid_rd t a_7 1)) ->
  ((valid_rd t t_8[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_4 2)) ->
  ((is_sint32 x_1)) ->
  ((valid_rd t a_16 1)) ->
  ((valid_rd t a_8 1)) ->
  ((valid_rd t a_11 1)) ->
  ((valid_rd t a_12 1)) ->
  ((valid_rd t a_13 1)) ->
  ((is_uint8 x_3)) ->
  ((valid_rd t a_18 l_size)) ->
  ((valid_rd t a_19 l_size)) ->
  ((valid_rw t a_18 l_size)) ->
  ((is_uint8 a_21)) ->
  ((is_uint8 a_22)) ->
  ((is_uint8 a_23)) ->
  ((is_uint8 a_24)) ->
  ((is_sint32 a_25)) ->
  ((valid_rd t a_26 l_size)) ->
  ((separated a_18 l_size a_26 l_size)) ->
  (if (((to_uint32 i_8)) < l_size)
   then ((i_10 = i_8) /\ (t_4 = t) /\ (((l_idle_cpu i_10)) <> 0) /\
         ((if (a_27 = i_10) then 1 else 0) = i_2) /\ (0 <= i_10) /\
         (i_10 < l_size) /\ ((valid_rd t_4 a_10 1)) /\
         ((valid_rd t_4 a_3 1)) /\ ((valid_rd t_4 a_5 1)) /\
         ((x_4 <> 0) \/
          ((l_size = i_1) /\
           ((p_idle_core t_8 ((havoc t_6 t_7 a_18 i_1)) i_10)) /\
           (forall i_11 : int. let a_29 = (shift_cpumask a i_11) in
            (0 <= i_11) -> (i_11 < i_1) ->
            (((valid_rd t_4 a_29 1)) /\
             ((valid_rw t_4
                ((shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_29)] 0)) i_1)))) /\
           (forall a_29 : addr. let a_30 = (l_sched_group_cpus a_29) in
            let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
            ((valid_rd t_4 a_30 1)) /\ ((valid_rd t_4 a_31 i_1)) /\
            (forall i_11 : int. (0 <= i_11) -> (i_11 < i_1) ->
             ((separated a_31 i_1
                ((shift_uint8
                   t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))]
                   0)) i_1)))) /\
           (forall a_29 : addr. let a_30 = (l_sched_group_mask a_29) in
            let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
            ((valid_rd t_4 a_30 1)) /\ ((valid_rd t_4 a_31 i_1)) /\
            (forall i_11 : int. (0 <= i_11) -> (i_11 < i_1) ->
             ((separated a_31 i_1
                ((shift_uint8
                   t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))]
                   0)) i_1)))) /\
           (forall a_29 : addr. let a_30 = (l_group_balance_mask a_29) in
            let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
            ((valid_rd t_4 a_30 1)) /\ ((valid_rd t_4 a_31 i_1)) /\
            (forall i_11 : int. (0 <= i_11) -> (i_11 < i_1) ->
             ((separated a_31 i_1
                ((shift_uint8
                   t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))]
                   0)) i_1)))) /\
           (forall i_11 : int. let a_29 = (l_cpu_smt_mask i_11) in
            let a_30 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_29)] 0) in
            (0 <= i_11) -> (i_11 < i_1) ->
            (((valid_rd t_4 a_29 1)) /\ ((valid_rd t_4 a_30 i_1)) /\
             (forall i_12 : int. (0 <= i_12) -> (i_12 < i_1) ->
              ((separated a_30 i_1
                 ((shift_uint8
                    t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_12)))]
                    0)) i_1))))))))
   else ((i_4 = i_3) /\ (t_1 = t) /\
         (if (i_4 = (-1))
          then ((t_2 = t_1) /\ (((l_group_balance_cpu a_12)) = i_7) /\
                ((if (a_27 = i_7) then 1 else 0) = i_2) /\
                ((valid_rd t_2 a_10 1)))
          else ((t_3 = t_1) /\ ((if (a_27 = i_4) then 1 else 0) = i_2) /\
                ((valid_rd t_3 a_10 1)))))) ->
  ((x_4 <> 0) -> (i_3 = (-1))) ->
  ((i_3 <> (-1)) ->
   ((((l_idle_cpu i_3)) <> 0) /\ (a_22 <> 0) /\ (a_24 <> 0) /\ (0 <= i_3) /\
    (i_3 < l_size))) ->
  ((i_3 = (-1)) ->
   (forall i_11 : int. (a_20[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) ->
    (i_11 < l_size) -> (a_20[(shift_uint8 a_17 i_11)] <> 0))) ->
  ((exists i_11 : int. (a_20[(shift_uint8 a_17 i_11)] <> 0) /\
    (a_20[(shift_uint8 a_9 i_11)] <> 0) /\ (i_11 < l_size) /\ (x_5 <= i_11)) ->
   (i_8 < l_size)) ->
  ((exists i_11 : int. (a_20[(shift_uint8 a_17 i_11)] <> 0) /\
    (a_20[(shift_uint8 a_9 i_11)] <> 0) /\ (i_11 < l_size) /\ (x_5 <= i_11)) ->
   ((i_8 < l_size) /\ (x_5 <= i_8))) ->
  ((exists i_11 : int. (a_20[(shift_uint8 a_17 i_11)] <> 0) /\
    (a_20[(shift_uint8 a_9 i_11)] <> 0) /\ (i_11 < l_size) /\ (x_5 <= i_11)) ->
   ((a_21 <> 0) /\ (a_23 <> 0))) ->
  ((forall i_11 : int. (i_11 < l_size) -> (x_5 <= i_11) ->
    ((a_20[(shift_uint8 a_17 i_11)] = 0) \/
     (a_20[(shift_uint8 a_9 i_11)] = 0))) -> (l_size = i_8)) ->
  ((i_3 <> (-1)) ->
   (forall i_11 : int. (a_20[(shift_uint8 a_9 i_11)] <> 0) ->
    (a_20[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) -> (i_11 < i_3) ->
    (i_11 < l_size) -> (((l_idle_cpu i_11)) = 0))) ->
  ((i_3 = (-1)) ->
   (forall i_11 : int. (a_20[(shift_uint8 a_9 i_11)] <> 0) ->
    (a_20[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) -> (i_11 < i_9) ->
    (i_11 < l_size) -> (((l_idle_cpu i_11)) = 0))) ->
  ((exists i_11 : int. (a_20[(shift_uint8 a_17 i_11)] <> 0) /\
    (a_20[(shift_uint8 a_9 i_11)] <> 0) /\ (i_11 < l_size) /\ (x_5 <= i_11)) ->
   (forall i_11 : int. (i_11 < i_8) -> (x_5 <= i_11) ->
    ((a_20[(shift_uint8 a_17 i_11)] = 0) \/
     (a_20[(shift_uint8 a_9 i_11)] = 0)))) ->
  ((i_3 <> (-1)) ->
   (forall i_11 : int. (a_20[(shift_uint8 a_9 i_11)] <> 0) ->
    (a_20[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) -> (i_3 <= i_11) ->
    (i_11 < i_9) -> (i_11 < l_size) -> (not (p_idle_core t_8 a_20 i_11)))) ->
  ((i_3 <> (-1)) ->
   (forall i_11 : int. (a_20[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) ->
    (i_11 < l_size) ->
    ((a_20[(shift_uint8 a_17 i_11)] <> 0) \/
     (not (p_idle_core t_8 a_20 i_11))))) ->
  (forall i_11 : int. (0 <= i_11) -> (i_11 < l_size) ->
   ((separated a_19 l_size
      ((shift_uint8
         t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))] 0))
      l_size))) ->
  (forall i_11 : int. let a_29 = (shift_cpumask a i_11) in (0 <= i_11) ->
   (i_11 < l_size) ->
   (((valid_rd t a_29 1)) /\
    ((valid_rw t ((shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_29)] 0))
       l_size)))) ->
  (forall i_11 : int. (0 <= i_11) -> (i_11 < l_size) ->
   ((a_28[(shift_uint8 a_14 i_11)] <> 0) <->
    (a_28[(shift_uint8 a_17 i_11)] <> 0))) ->
  (forall i_11 : int. (a_20[(shift_uint8 a_17 i_11)] <> 0) -> (0 <= i_11) ->
   (i_11 < l_size) -> (a_20[(shift_uint8 a_14 i_11)] <> 0)) ->
  (forall i_11 : int. (t_7[(shift_uint8 a_9 i_11)] <> 0) ->
   (t_7[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) -> (i_11 < l_size) ->
   (not (p_idle_core t_8 t_7 i_11))) ->
  (forall i_11 : int. (t_7[(shift_uint8 a_9 i_11)] <> 0) ->
   (t_7[(shift_uint8 a_14 i_11)] <> 0) -> (0 <= i_11) -> (i_11 < i_6) ->
   (i_11 < l_size) -> (((l_idle_cpu i_11)) = 0)) ->
  (forall a_29 : addr. let a_30 = (l_sched_group_cpus a_29) in
   let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
   ((valid_rd t a_30 1)) /\ ((valid_rd t a_31 l_size)) /\
   (forall i_11 : int. (0 <= i_11) -> (i_11 < l_size) ->
    ((separated a_31 l_size
       ((shift_uint8
          t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))] 0))
       l_size)))) ->
  (forall a_29 : addr. let a_30 = (l_sched_group_mask a_29) in
   let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
   ((valid_rd t a_30 1)) /\ ((valid_rd t a_31 l_size)) /\
   (forall i_11 : int. (0 <= i_11) -> (i_11 < l_size) ->
    ((separated a_31 l_size
       ((shift_uint8
          t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))] 0))
       l_size)))) ->
  (forall a_29 : addr. let a_30 = (l_group_balance_mask a_29) in
   let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
   ((valid_rd t a_30 1)) /\ ((valid_rd t a_31 l_size)) /\
   (forall i_11 : int. (0 <= i_11) -> (i_11 < l_size) ->
    ((separated a_31 l_size
       ((shift_uint8
          t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_11)))] 0))
       l_size)))) ->
  (forall i_11 : int. let a_29 = (l_cpu_smt_mask i_11) in
   let a_30 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_29)] 0) in
   (0 <= i_11) -> (i_11 < l_size) ->
   (((valid_rd t a_29 1)) /\ ((valid_rd t a_30 l_size)) /\
    (forall i_12 : int. (0 <= i_12) -> (i_12 < l_size) ->
     ((separated a_30 l_size
        ((shift_uint8
           t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_12)))] 0))
        l_size))))) ->
  ((x_2 = i_6) <-> (i_2 <> 0))

end

(* ---------------------------------------------------------- *)
(* --- Post-condition for 'not_newly_idle_without_idle' (file c11.c, line 105) in 'should_we_balance' --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_not_newly_idle_without_idle_post
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import Compound.Compound
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import A_schedule_cpumask.A_schedule_cpumask
use import Cbits.Cbits

(*
goal WP "expl:Post-condition for 'not_newly_idle_without_idle' (file c11.c, line 105) in 'should_we_balance'":
*)
goal goal40:
  forall i_7 i_6 i_5 i_4 i_3 i_2 i_1 i : int.
  forall t_4 t_3 t_2 t_1 t : map int int.
  forall t_7 t_6 t_5 : map addr int.
  forall t_8 : map addr addr.
  forall a_1 a : addr.
  let a_2 = (shiftfield_f5_lb_env_idle a_1) in
  let x = t_7[a_2] in
  let a_3 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_4 = t_8[a_3] in
  let a_5 = (shiftfield_f1_cpumask_bits a_4) in
  let a_6 = t_8[a_5] in
  let a_7 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x_1 = t_7[a_7] in
  let x_2 = t_7[(shift_uint8 a_6 x_1)] in
  let a_8 = (shiftfield_f5_lb_env_sd a_1) in
  let a_9 = (shift_cpumask a i) in
  let a_10 = t_8[a_8] in
  let a_11 = (shiftfield_f1_cpumask_bits a_9) in
  let a_12 = (shiftfield_f3_sched_domain_groups a_10) in
  let a_13 = t_8[a_12] in
  let a_14 = (l_group_balance_mask a_13) in
  let a_15 = t_8[a_11] in
  let a_16 = (shift_uint8 a_15 0) in
  let a_17 = (shift_uint8 a_6 0) in
  let a_18 = (havoc t_6 t_7 a_16 l_size) in
  let a_19 = a_18[(shift_uint8 a_15 i_5)] in
  let a_20 = a_18[(shift_uint8 a_6 i_2)] in
  let a_21 = a_18[(shift_uint8 a_6 i_5)] in
  let a_22 = t_8[(shiftfield_f1_cpumask_bits a_14)] in
  let a_23 = a_18[(shift_uint8 a_22 i_2)] in
  let a_24 = a_18[a_7] in
  let a_25 = (shiftfield_f3_sched_domain_flags a_10) in
  let a_26 = a_18[a_25] in
  let a_27 = (shift_uint8 a_22 0) in
  let x_3 = (land 7 a_26) in
  let x_4 = (l_group_balance_cpu a_13) in
  let x_5 = (to_uint32 i_6) in
  let a_28 = (havoc t_5 t_7 a_16 l_size) in
  (x <> 2) ->
  (x_2 <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= i_6) ->
  (i_6 <= l_size) ->
  (0 <= x_1) ->
  (x_1 < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_8)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((is_sint32 i_1)) ->
  ((is_sint32 i_2)) ->
  ((is_sint32 i_3)) ->
  ((is_sint32 i_4)) ->
  ((is_sint32 i_5)) ->
  ((is_sint32 i_6)) ->
  ((is_sint32 i_7)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 x)) ->
  ((is_sint32 x_1)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_7 1)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t a_8 1)) ->
  ((valid_rd t a_9 1)) ->
  ((valid_rd t a_4 1)) ->
  ((valid_rd t t_8[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_10 2)) ->
  ((valid_rd t a_11 1)) ->
  ((valid_rd t a_5 1)) ->
  ((valid_rd t a_12 1)) ->
  ((valid_rd t a_13 1)) ->
  ((valid_rd t a_14 1)) ->
  ((is_uint8 x_2)) ->
  ((valid_rd t a_16 l_size)) ->
  ((valid_rd t a_17 l_size)) ->
  ((valid_rw t a_16 l_size)) ->
  ((is_uint8 a_19)) ->
  ((is_uint8 a_20)) ->
  ((is_uint8 a_21)) ->
  ((is_uint8 a_23)) ->
  ((is_sint32 a_24)) ->
  ((is_sint32 a_26)) ->
  ((valid_rd t a_27 l_size)) ->
  ((separated a_16 l_size a_27 l_size)) ->
  (if (((to_uint32 i_5)) < l_size)
   then ((i_7 = i_5) /\ (t_4 = t) /\ (((l_idle_cpu i_7)) <> 0) /\
         ((if (a_24 = i_7) then 1 else 0) = i_1) /\ (0 <= i_7) /\
         (i_7 < l_size) /\ ((valid_rd t_4 a_7 1)) /\
         ((valid_rd t_4 a_8 1)) /\ ((valid_rd t_4 a_25 1)) /\
         ((x_3 <> 0) \/
          (((p_idle_core t_8 a_18 i_7)) /\
           (forall i_8 : int. let a_29 = (shift_cpumask a i_8) in
            (0 <= i_8) -> (i_8 < l_size) ->
            (((valid_rd t_4 a_29 1)) /\
             ((valid_rw t_4
                ((shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_29)] 0))
                l_size)))) /\
           (forall a_29 : addr. let a_30 = (l_sched_group_cpus a_29) in
            let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
            ((valid_rd t_4 a_30 1)) /\ ((valid_rd t_4 a_31 l_size)) /\
            (forall i_8 : int. (0 <= i_8) -> (i_8 < l_size) ->
             ((separated a_31 l_size
                ((shift_uint8
                   t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_8)))]
                   0)) l_size)))) /\
           (forall a_29 : addr. let a_30 = (l_sched_group_mask a_29) in
            let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
            ((valid_rd t_4 a_30 1)) /\ ((valid_rd t_4 a_31 l_size)) /\
            (forall i_8 : int. (0 <= i_8) -> (i_8 < l_size) ->
             ((separated a_31 l_size
                ((shift_uint8
                   t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_8)))]
                   0)) l_size)))) /\
           (forall a_29 : addr. let a_30 = (l_group_balance_mask a_29) in
            let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
            ((valid_rd t_4 a_30 1)) /\ ((valid_rd t_4 a_31 l_size)) /\
            (forall i_8 : int. (0 <= i_8) -> (i_8 < l_size) ->
             ((separated a_31 l_size
                ((shift_uint8
                   t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_8)))]
                   0)) l_size)))) /\
           (forall i_8 : int. let a_29 = (l_cpu_smt_mask i_8) in
            let a_30 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_29)] 0) in
            (0 <= i_8) -> (i_8 < l_size) ->
            (((valid_rd t_4 a_29 1)) /\ ((valid_rd t_4 a_30 l_size)) /\
             (forall i_9 : int. (0 <= i_9) -> (i_9 < l_size) ->
              ((separated a_30 l_size
                 ((shift_uint8
                    t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_9)))]
                    0)) l_size))))))))
   else ((i_3 = i_2) /\ (t_1 = t) /\
         (if (i_3 = (-1))
          then ((t_2 = t_1) /\ (x_4 = i_4) /\
                ((if (a_24 = i_4) then 1 else 0) = i_1) /\
                ((valid_rd t_2 a_7 1)))
          else ((t_3 = t_1) /\ ((if (a_24 = i_3) then 1 else 0) = i_1) /\
                ((valid_rd t_3 a_7 1)))))) ->
  ((x_3 <> 0) -> (i_2 = (-1))) ->
  ((i_2 <> (-1)) ->
   ((((l_idle_cpu i_2)) <> 0) /\ (a_20 <> 0) /\ (a_23 <> 0) /\ (0 <= i_2) /\
    (i_2 < l_size))) ->
  ((i_2 = (-1)) ->
   (forall i_8 : int. (a_18[(shift_uint8 a_22 i_8)] <> 0) -> (0 <= i_8) ->
    (i_8 < l_size) -> (a_18[(shift_uint8 a_15 i_8)] <> 0))) ->
  ((exists i_8 : int. (a_18[(shift_uint8 a_15 i_8)] <> 0) /\
    (a_18[(shift_uint8 a_6 i_8)] <> 0) /\ (i_8 < l_size) /\ (x_5 <= i_8)) ->
   (i_5 < l_size)) ->
  ((exists i_8 : int. (a_18[(shift_uint8 a_15 i_8)] <> 0) /\
    (a_18[(shift_uint8 a_6 i_8)] <> 0) /\ (i_8 < l_size) /\ (x_5 <= i_8)) ->
   ((i_5 < l_size) /\ (x_5 <= i_5))) ->
  ((exists i_8 : int. (a_18[(shift_uint8 a_15 i_8)] <> 0) /\
    (a_18[(shift_uint8 a_6 i_8)] <> 0) /\ (i_8 < l_size) /\ (x_5 <= i_8)) ->
   ((a_19 <> 0) /\ (a_21 <> 0))) ->
  ((forall i_8 : int. (i_8 < l_size) -> (x_5 <= i_8) ->
    ((a_18[(shift_uint8 a_15 i_8)] = 0) \/ (a_18[(shift_uint8 a_6 i_8)] = 0))) ->
   (l_size = i_5)) ->
  ((i_2 <> (-1)) ->
   (forall i_8 : int. (a_18[(shift_uint8 a_6 i_8)] <> 0) ->
    (a_18[(shift_uint8 a_22 i_8)] <> 0) -> (0 <= i_8) -> (i_8 < i_2) ->
    (i_8 < l_size) -> (((l_idle_cpu i_8)) = 0))) ->
  ((i_2 = (-1)) ->
   (forall i_8 : int. (a_18[(shift_uint8 a_6 i_8)] <> 0) ->
    (a_18[(shift_uint8 a_22 i_8)] <> 0) -> (0 <= i_8) -> (i_8 < i_6) ->
    (i_8 < l_size) -> (((l_idle_cpu i_8)) = 0))) ->
  ((exists i_8 : int. (a_18[(shift_uint8 a_15 i_8)] <> 0) /\
    (a_18[(shift_uint8 a_6 i_8)] <> 0) /\ (i_8 < l_size) /\ (x_5 <= i_8)) ->
   (forall i_8 : int. (i_8 < i_5) -> (x_5 <= i_8) ->
    ((a_18[(shift_uint8 a_15 i_8)] = 0) \/ (a_18[(shift_uint8 a_6 i_8)] = 0)))) ->
  ((i_2 <> (-1)) ->
   (forall i_8 : int. (a_18[(shift_uint8 a_6 i_8)] <> 0) ->
    (a_18[(shift_uint8 a_22 i_8)] <> 0) -> (0 <= i_8) -> (i_2 <= i_8) ->
    (i_8 < i_6) -> (i_8 < l_size) -> (not (p_idle_core t_8 a_18 i_8)))) ->
  ((i_2 <> (-1)) ->
   (forall i_8 : int. (a_18[(shift_uint8 a_22 i_8)] <> 0) -> (0 <= i_8) ->
    (i_8 < l_size) ->
    ((a_18[(shift_uint8 a_15 i_8)] <> 0) \/ (not (p_idle_core t_8 a_18 i_8))))) ->
  (forall i_8 : int. (0 <= i_8) -> (i_8 < l_size) ->
   ((separated a_17 l_size
      ((shift_uint8 t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_8)))]
         0)) l_size))) ->
  (forall i_8 : int. let a_29 = (shift_cpumask a i_8) in (0 <= i_8) ->
   (i_8 < l_size) ->
   (((valid_rd t a_29 1)) /\
    ((valid_rw t ((shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_29)] 0))
       l_size)))) ->
  (forall i_8 : int. (0 <= i_8) -> (i_8 < l_size) ->
   ((a_28[(shift_uint8 a_22 i_8)] <> 0) <->
    (a_28[(shift_uint8 a_15 i_8)] <> 0))) ->
  (forall i_8 : int. (a_18[(shift_uint8 a_15 i_8)] <> 0) -> (0 <= i_8) ->
   (i_8 < l_size) -> (a_18[(shift_uint8 a_22 i_8)] <> 0)) ->
  (forall i_8 : int. (t_7[(shift_uint8 a_6 i_8)] <> 0) ->
   (t_7[(shift_uint8 a_22 i_8)] <> 0) -> (0 <= i_8) -> (i_8 < l_size) ->
   (((l_idle_cpu i_8)) = 0)) ->
  (forall a_29 : addr. let a_30 = (l_sched_group_cpus a_29) in
   let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
   ((valid_rd t a_30 1)) /\ ((valid_rd t a_31 l_size)) /\
   (forall i_8 : int. (0 <= i_8) -> (i_8 < l_size) ->
    ((separated a_31 l_size
       ((shift_uint8
          t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_8)))] 0))
       l_size)))) ->
  (forall a_29 : addr. let a_30 = (l_sched_group_mask a_29) in
   let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
   ((valid_rd t a_30 1)) /\ ((valid_rd t a_31 l_size)) /\
   (forall i_8 : int. (0 <= i_8) -> (i_8 < l_size) ->
    ((separated a_31 l_size
       ((shift_uint8
          t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_8)))] 0))
       l_size)))) ->
  (forall a_29 : addr. let a_30 = (l_group_balance_mask a_29) in
   let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
   ((valid_rd t a_30 1)) /\ ((valid_rd t a_31 l_size)) /\
   (forall i_8 : int. (0 <= i_8) -> (i_8 < l_size) ->
    ((separated a_31 l_size
       ((shift_uint8
          t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_8)))] 0))
       l_size)))) ->
  (forall i_8 : int. let a_29 = (l_cpu_smt_mask i_8) in
   let a_30 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_29)] 0) in
   (0 <= i_8) -> (i_8 < l_size) ->
   (((valid_rd t a_29 1)) /\ ((valid_rd t a_30 l_size)) /\
    (forall i_9 : int. (0 <= i_9) -> (i_9 < l_size) ->
     ((separated a_30 l_size
        ((shift_uint8
           t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_9)))] 0))
        l_size))))) ->
  ((a_24 = x_4) <-> (i_1 <> 0))

end

(* ---------------------------------------------------------- *)
(* --- Post-condition for 'not_newly_idle_without_idle' (file c11.c, line 106) in 'should_we_balance' --- *)
(* ---------------------------------------------------------- *)
theory VCshould_we_balance_not_newly_idle_without_idle_post_2
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import Compound.Compound
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import A_schedule_cpumask.A_schedule_cpumask
use import Cbits.Cbits

(*
goal WP "expl:Post-condition for 'not_newly_idle_without_idle' (file c11.c, line 106) in 'should_we_balance'":
*)
goal goal41:
  forall i_7 i_6 i_5 i_4 i_3 i_2 i_1 i : int.
  forall t_4 t_3 t_2 t_1 t : map int int.
  forall t_7 t_6 t_5 : map addr int.
  forall t_8 : map addr addr.
  forall a_1 a : addr.
  let a_2 = (shiftfield_f5_lb_env_idle a_1) in
  let x = t_7[a_2] in
  let a_3 = (shiftfield_f5_lb_env_cpus a_1) in
  let a_4 = t_8[a_3] in
  let a_5 = (shiftfield_f1_cpumask_bits a_4) in
  let a_6 = t_8[a_5] in
  let a_7 = (shiftfield_f5_lb_env_dst_cpu a_1) in
  let x_1 = t_7[a_7] in
  let x_2 = t_7[(shift_uint8 a_6 x_1)] in
  let a_8 = (shiftfield_f5_lb_env_sd a_1) in
  let a_9 = (shift_cpumask a i) in
  let a_10 = t_8[a_8] in
  let a_11 = (shiftfield_f1_cpumask_bits a_9) in
  let a_12 = (shiftfield_f3_sched_domain_groups a_10) in
  let a_13 = t_8[a_12] in
  let a_14 = (l_group_balance_mask a_13) in
  let a_15 = t_8[a_11] in
  let a_16 = (shift_uint8 a_15 0) in
  let a_17 = (shift_uint8 a_6 0) in
  let a_18 = (havoc t_6 t_7 a_16 l_size) in
  let a_19 = a_18[(shift_uint8 a_15 i_5)] in
  let a_20 = a_18[(shift_uint8 a_6 i_2)] in
  let a_21 = a_18[(shift_uint8 a_6 i_5)] in
  let a_22 = t_8[(shiftfield_f1_cpumask_bits a_14)] in
  let a_23 = a_18[(shift_uint8 a_22 i_2)] in
  let a_24 = a_18[a_7] in
  let a_25 = (shiftfield_f3_sched_domain_flags a_10) in
  let a_26 = a_18[a_25] in
  let a_27 = (shift_uint8 a_22 0) in
  let x_3 = (land 7 a_26) in
  let x_4 = (l_group_balance_cpu a_13) in
  let x_5 = (to_uint32 i_6) in
  let a_28 = (havoc t_5 t_7 a_16 l_size) in
  (x <> 2) ->
  (x_2 <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= i_6) ->
  (i_6 <= l_size) ->
  (0 <= x_1) ->
  (x_1 < l_size) ->
  (((region (a.base))) <= 0) ->
  (((region (a_1.base))) <= 0) ->
  ((framed t_8)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((is_sint32 i_1)) ->
  ((is_sint32 i_2)) ->
  ((is_sint32 i_3)) ->
  ((is_sint32 i_4)) ->
  ((is_sint32 i_5)) ->
  ((is_sint32 i_6)) ->
  ((is_sint32 i_7)) ->
  ((valid_rd t a_1 5)) ->
  ((is_uint32 x)) ->
  ((is_sint32 x_1)) ->
  ((valid_rd t a_3 1)) ->
  ((valid_rd t a_7 1)) ->
  ((valid_rd t a_2 1)) ->
  ((valid_rd t a_8 1)) ->
  ((valid_rd t a_9 1)) ->
  ((valid_rd t a_4 1)) ->
  ((valid_rd t t_8[(shiftfield_f5_lb_env_dst_rq a_1)] 2)) ->
  ((valid_rd t a_10 2)) ->
  ((valid_rd t a_11 1)) ->
  ((valid_rd t a_5 1)) ->
  ((valid_rd t a_12 1)) ->
  ((valid_rd t a_13 1)) ->
  ((valid_rd t a_14 1)) ->
  ((is_uint8 x_2)) ->
  ((valid_rd t a_16 l_size)) ->
  ((valid_rd t a_17 l_size)) ->
  ((valid_rw t a_16 l_size)) ->
  ((is_uint8 a_19)) ->
  ((is_uint8 a_20)) ->
  ((is_uint8 a_21)) ->
  ((is_uint8 a_23)) ->
  ((is_sint32 a_24)) ->
  ((is_sint32 a_26)) ->
  ((valid_rd t a_27 l_size)) ->
  ((separated a_16 l_size a_27 l_size)) ->
  (if (((to_uint32 i_5)) < l_size)
   then ((i_7 = i_5) /\ (t_4 = t) /\ (((l_idle_cpu i_7)) <> 0) /\
         ((if (a_24 = i_7) then 1 else 0) = i_1) /\ (0 <= i_7) /\
         (i_7 < l_size) /\ ((valid_rd t_4 a_7 1)) /\
         ((valid_rd t_4 a_8 1)) /\ ((valid_rd t_4 a_25 1)) /\
         ((x_3 <> 0) \/
          (((p_idle_core t_8 a_18 i_7)) /\
           (forall i_8 : int. let a_29 = (shift_cpumask a i_8) in
            (0 <= i_8) -> (i_8 < l_size) ->
            (((valid_rd t_4 a_29 1)) /\
             ((valid_rw t_4
                ((shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_29)] 0))
                l_size)))) /\
           (forall a_29 : addr. let a_30 = (l_sched_group_cpus a_29) in
            let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
            ((valid_rd t_4 a_30 1)) /\ ((valid_rd t_4 a_31 l_size)) /\
            (forall i_8 : int. (0 <= i_8) -> (i_8 < l_size) ->
             ((separated a_31 l_size
                ((shift_uint8
                   t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_8)))]
                   0)) l_size)))) /\
           (forall a_29 : addr. let a_30 = (l_sched_group_mask a_29) in
            let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
            ((valid_rd t_4 a_30 1)) /\ ((valid_rd t_4 a_31 l_size)) /\
            (forall i_8 : int. (0 <= i_8) -> (i_8 < l_size) ->
             ((separated a_31 l_size
                ((shift_uint8
                   t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_8)))]
                   0)) l_size)))) /\
           (forall a_29 : addr. let a_30 = (l_group_balance_mask a_29) in
            let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
            ((valid_rd t_4 a_30 1)) /\ ((valid_rd t_4 a_31 l_size)) /\
            (forall i_8 : int. (0 <= i_8) -> (i_8 < l_size) ->
             ((separated a_31 l_size
                ((shift_uint8
                   t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_8)))]
                   0)) l_size)))) /\
           (forall i_8 : int. let a_29 = (l_cpu_smt_mask i_8) in
            let a_30 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_29)] 0) in
            (0 <= i_8) -> (i_8 < l_size) ->
            (((valid_rd t_4 a_29 1)) /\ ((valid_rd t_4 a_30 l_size)) /\
             (forall i_9 : int. (0 <= i_9) -> (i_9 < l_size) ->
              ((separated a_30 l_size
                 ((shift_uint8
                    t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_9)))]
                    0)) l_size))))))))
   else ((i_3 = i_2) /\ (t_1 = t) /\
         (if (i_3 = (-1))
          then ((t_2 = t_1) /\ (x_4 = i_4) /\
                ((if (a_24 = i_4) then 1 else 0) = i_1) /\
                ((valid_rd t_2 a_7 1)))
          else ((t_3 = t_1) /\ ((if (a_24 = i_3) then 1 else 0) = i_1) /\
                ((valid_rd t_3 a_7 1)))))) ->
  ((x_3 <> 0) -> (i_2 = (-1))) ->
  ((i_2 <> (-1)) ->
   ((((l_idle_cpu i_2)) <> 0) /\ (a_20 <> 0) /\ (a_23 <> 0) /\ (0 <= i_2) /\
    (i_2 < l_size))) ->
  ((i_2 = (-1)) ->
   (forall i_8 : int. (a_18[(shift_uint8 a_22 i_8)] <> 0) -> (0 <= i_8) ->
    (i_8 < l_size) -> (a_18[(shift_uint8 a_15 i_8)] <> 0))) ->
  ((exists i_8 : int. (a_18[(shift_uint8 a_15 i_8)] <> 0) /\
    (a_18[(shift_uint8 a_6 i_8)] <> 0) /\ (i_8 < l_size) /\ (x_5 <= i_8)) ->
   (i_5 < l_size)) ->
  ((exists i_8 : int. (a_18[(shift_uint8 a_15 i_8)] <> 0) /\
    (a_18[(shift_uint8 a_6 i_8)] <> 0) /\ (i_8 < l_size) /\ (x_5 <= i_8)) ->
   ((i_5 < l_size) /\ (x_5 <= i_5))) ->
  ((exists i_8 : int. (a_18[(shift_uint8 a_15 i_8)] <> 0) /\
    (a_18[(shift_uint8 a_6 i_8)] <> 0) /\ (i_8 < l_size) /\ (x_5 <= i_8)) ->
   ((a_19 <> 0) /\ (a_21 <> 0))) ->
  ((forall i_8 : int. (i_8 < l_size) -> (x_5 <= i_8) ->
    ((a_18[(shift_uint8 a_15 i_8)] = 0) \/ (a_18[(shift_uint8 a_6 i_8)] = 0))) ->
   (l_size = i_5)) ->
  ((i_2 <> (-1)) ->
   (forall i_8 : int. (a_18[(shift_uint8 a_6 i_8)] <> 0) ->
    (a_18[(shift_uint8 a_22 i_8)] <> 0) -> (0 <= i_8) -> (i_8 < i_2) ->
    (i_8 < l_size) -> (((l_idle_cpu i_8)) = 0))) ->
  ((i_2 = (-1)) ->
   (forall i_8 : int. (a_18[(shift_uint8 a_6 i_8)] <> 0) ->
    (a_18[(shift_uint8 a_22 i_8)] <> 0) -> (0 <= i_8) -> (i_8 < i_6) ->
    (i_8 < l_size) -> (((l_idle_cpu i_8)) = 0))) ->
  ((exists i_8 : int. (a_18[(shift_uint8 a_15 i_8)] <> 0) /\
    (a_18[(shift_uint8 a_6 i_8)] <> 0) /\ (i_8 < l_size) /\ (x_5 <= i_8)) ->
   (forall i_8 : int. (i_8 < i_5) -> (x_5 <= i_8) ->
    ((a_18[(shift_uint8 a_15 i_8)] = 0) \/ (a_18[(shift_uint8 a_6 i_8)] = 0)))) ->
  ((i_2 <> (-1)) ->
   (forall i_8 : int. (a_18[(shift_uint8 a_6 i_8)] <> 0) ->
    (a_18[(shift_uint8 a_22 i_8)] <> 0) -> (0 <= i_8) -> (i_2 <= i_8) ->
    (i_8 < i_6) -> (i_8 < l_size) -> (not (p_idle_core t_8 a_18 i_8)))) ->
  ((i_2 <> (-1)) ->
   (forall i_8 : int. (a_18[(shift_uint8 a_22 i_8)] <> 0) -> (0 <= i_8) ->
    (i_8 < l_size) ->
    ((a_18[(shift_uint8 a_15 i_8)] <> 0) \/ (not (p_idle_core t_8 a_18 i_8))))) ->
  (forall i_8 : int. (0 <= i_8) -> (i_8 < l_size) ->
   ((separated a_17 l_size
      ((shift_uint8 t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_8)))]
         0)) l_size))) ->
  (forall i_8 : int. let a_29 = (shift_cpumask a i_8) in (0 <= i_8) ->
   (i_8 < l_size) ->
   (((valid_rd t a_29 1)) /\
    ((valid_rw t ((shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_29)] 0))
       l_size)))) ->
  (forall i_8 : int. (0 <= i_8) -> (i_8 < l_size) ->
   ((a_28[(shift_uint8 a_22 i_8)] <> 0) <->
    (a_28[(shift_uint8 a_15 i_8)] <> 0))) ->
  (forall i_8 : int. (a_18[(shift_uint8 a_15 i_8)] <> 0) -> (0 <= i_8) ->
   (i_8 < l_size) -> (a_18[(shift_uint8 a_22 i_8)] <> 0)) ->
  (forall i_8 : int. (t_7[(shift_uint8 a_6 i_8)] <> 0) ->
   (t_7[(shift_uint8 a_22 i_8)] <> 0) -> (0 <= i_8) -> (i_8 < l_size) ->
   (((l_idle_cpu i_8)) = 0)) ->
  (forall a_29 : addr. let a_30 = (l_sched_group_cpus a_29) in
   let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
   ((valid_rd t a_30 1)) /\ ((valid_rd t a_31 l_size)) /\
   (forall i_8 : int. (0 <= i_8) -> (i_8 < l_size) ->
    ((separated a_31 l_size
       ((shift_uint8
          t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_8)))] 0))
       l_size)))) ->
  (forall a_29 : addr. let a_30 = (l_sched_group_mask a_29) in
   let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
   ((valid_rd t a_30 1)) /\ ((valid_rd t a_31 l_size)) /\
   (forall i_8 : int. (0 <= i_8) -> (i_8 < l_size) ->
    ((separated a_31 l_size
       ((shift_uint8
          t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_8)))] 0))
       l_size)))) ->
  (forall a_29 : addr. let a_30 = (l_group_balance_mask a_29) in
   let a_31 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_30)] 0) in
   ((valid_rd t a_30 1)) /\ ((valid_rd t a_31 l_size)) /\
   (forall i_8 : int. (0 <= i_8) -> (i_8 < l_size) ->
    ((separated a_31 l_size
       ((shift_uint8
          t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_8)))] 0))
       l_size)))) ->
  (forall i_8 : int. let a_29 = (l_cpu_smt_mask i_8) in
   let a_30 = (shift_uint8 t_8[(shiftfield_f1_cpumask_bits a_29)] 0) in
   (0 <= i_8) -> (i_8 < l_size) ->
   (((valid_rd t a_29 1)) /\ ((valid_rd t a_30 l_size)) /\
    (forall i_9 : int. (0 <= i_9) -> (i_9 < l_size) ->
     ((separated a_30 l_size
        ((shift_uint8
           t_8[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_9)))] 0))
        l_size))))) ->
  ((x_1 = x_4) <-> (i_1 <> 0))

end

