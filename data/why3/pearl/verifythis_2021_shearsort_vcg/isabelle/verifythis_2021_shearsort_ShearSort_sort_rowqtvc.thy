theory verifythis_2021_shearsort_ShearSort_sort_rowqtvc
  imports "NTP4Verif.NTP4Verif" "Why3STD.Ref_Ref" "Why3STD.int_NumOf" "Why3STD.int_Sum" "Why3STD.map_MapExt" "Why3STD.map_MapPermut" "Why3STD.matrix_Matrix"
begin
consts column :: "'a matrix \<Rightarrow> int \<Rightarrow> int \<Rightarrow> 'a"
axiomatization where column'def:   "column m j i = elts m i j"
  for m :: "'a matrix"
  and j :: "int"
  and i :: "int"
consts moccf :: "'a \<Rightarrow> (int \<Rightarrow> int \<Rightarrow> 'a) \<Rightarrow> int \<Rightarrow> int \<Rightarrow> int"
axiomatization where moccf'def:   "moccf x e c i = int (map_occ x (e i) (0 :: int) c)"
  for x :: "'a"
  and e :: "int \<Rightarrow> int \<Rightarrow> 'a"
  and c :: "int"
  and i :: "int"
definition mocc :: "'a \<Rightarrow> (int \<Rightarrow> int \<Rightarrow> 'a) \<Rightarrow> int \<Rightarrow> int \<Rightarrow> int"
  where "mocc x e r c = sum (moccf x e c) (0 :: int) r" for x e r c
consts compose :: "('b \<Rightarrow> 'c) \<Rightarrow> ('a \<Rightarrow> 'b) \<Rightarrow> 'a \<Rightarrow> 'c"
axiomatization where compose'def:   "compose g f x = g (f x)"
  for g :: "'b \<Rightarrow> 'c"
  and f :: "'a \<Rightarrow> 'b"
  and x :: "'a"
theorem sort_row'vc:
  fixes i :: "int"
  fixes m :: "int matrix"
  fixes ascending :: "bool"
  assumes fact0: "(0 :: int) \<le> i"
  assumes fact1: "i < rows m"
  shows "let o1 :: int = columns m in (0 :: int) \<le> o1 \<and> (\<forall>(a :: int list). (\<forall>(i1 :: int). (0 :: int) \<le> i1 \<and> i1 < o1 \<longrightarrow> a ! nat i1 = (0 :: int)) \<and> int (length a) = o1 \<longrightarrow> (let o2 :: int = columns m - (1 :: int) in ((0 :: int) \<le> o2 + (1 :: int) \<longrightarrow> (\<forall>(k :: int). (0 :: int) \<le> k \<and> k < (0 :: int) \<longrightarrow> (nth a o nat) k = elts m i k) \<and> (\<forall>(a1 :: int list). length a1 = length a \<longrightarrow> (\<forall>(j :: int). ((0 :: int) \<le> j \<and> j \<le> o2) \<and> (\<forall>(k :: int). (0 :: int) \<le> k \<and> k < j \<longrightarrow> (nth a1 o nat) k = elts m i k) \<longrightarrow> valid_index m i j \<and> (let o3 :: int = elts m i j in ((0 :: int) \<le> j \<and> j < int (length a1)) \<and> (length (a1[nat j := o3]) = length a1 \<longrightarrow> nth (a1[nat j := o3]) o nat = (nth a1 o nat)(j := o3) \<longrightarrow> (\<forall>(k :: int). (0 :: int) \<le> k \<and> k < j + (1 :: int) \<longrightarrow> (nth (a1[nat j := o3]) o nat) k = elts m i k)))) \<and> ((\<forall>(k :: int). (0 :: int) \<le> k \<and> k < o2 + (1 :: int) \<longrightarrow> (nth a1 o nat) k = elts m i k) \<longrightarrow> (\<forall>(a2 :: int list). length a2 = length a1 \<longrightarrow> (\<forall>(i1 :: int) (j :: int). (0 :: int) \<le> i1 \<and> i1 \<le> j \<and> j < int (length a2) \<longrightarrow> a2 ! nat i1 \<le> a2 ! nat j) \<and> permut (nth a2 o nat) (nth a1 o nat) (0 :: int) (int (length a2)) \<longrightarrow> (if \<not>ascending = True then let o3 :: int = int (length a2) - (1 :: int) in (((0 :: int) \<le> (0 :: int) \<and> (0 :: int) \<le> o3 + (1 :: int) \<and> o3 + (1 :: int) \<le> int (length a2)) \<and> (0 :: int) + o3 = int (length a2) - (1 :: int) \<and> (\<forall>(j :: int). (0 :: int) \<le> j \<and> j < (0 :: int) \<or> o3 < j \<and> j < int (length a2) \<longrightarrow> (nth a2 o nat) j = (nth a2 o nat) (int (length a2) - (1 :: int) - j)) \<and> permut (nth a2 o nat) (nth a2 o nat) (0 :: int) (int (length a2))) \<and> (\<forall>(v :: int) (u :: int) (a3 :: int list). length a3 = length a2 \<longrightarrow> ((0 :: int) \<le> u \<and> u \<le> v + (1 :: int) \<and> v + (1 :: int) \<le> int (length a3)) \<and> u + v = int (length a3) - (1 :: int) \<and> (\<forall>(j :: int). u \<le> j \<and> j \<le> v \<longrightarrow> (nth a3 o nat) j = (nth a2 o nat) j) \<and> (\<forall>(j :: int). (0 :: int) \<le> j \<and> j < u \<or> v < j \<and> j < int (length a3) \<longrightarrow> (nth a3 o nat) j = (nth a2 o nat) (int (length a3) - (1 :: int) - j)) \<and> permut (nth a2 o nat) (nth a3 o nat) (0 :: int) (int (length a3)) \<longrightarrow> (if u < v then let e :: int \<Rightarrow> int = nth a3 o nat in ((0 :: int) \<le> v \<and> v < int (length a3)) \<and> (let tmp :: int = a3 ! nat v in ((0 :: int) \<le> u \<and> u < int (length a3)) \<and> (let o4 :: int = a3 ! nat u in ((0 :: int) \<le> v \<and> v < int (length a3)) \<and> (length (a3[nat v := o4]) = length a3 \<longrightarrow> nth (a3[nat v := o4]) o nat = (nth a3 o nat)(v := o4) \<longrightarrow> ((0 :: int) \<le> u \<and> u < int (length (a3[nat v := o4]))) \<and> (length (a3[nat u := tmp, nat v := o4]) = length (a3[nat v := o4]) \<longrightarrow> nth (a3[nat u := tmp, nat v := o4]) o nat = (nth (a3[nat v := o4]) o nat)(u := tmp) \<longrightarrow> (let o5 :: int = int (length (a3[nat u := tmp, nat v := o4])); o6 :: int \<Rightarrow> int = nth (a3[nat u := tmp, nat v := o4]) o nat in ((((0 :: int) \<le> u \<and> u < o5) \<and> (0 :: int) \<le> v \<and> v < o5) \<and> (\<forall>(i1 :: int). ((0 :: int) \<le> i1 \<and> i1 \<le> o5) \<and> \<not>i1 = u \<and> \<not>i1 = v \<longrightarrow> o6 i1 = e i1) \<and> o6 u = e v \<and> o6 v = e u) \<and> (permut o6 e (0 :: int) o5 \<longrightarrow> ((0 :: int) \<le> v - u \<and> v - (1 :: int) - (u + (1 :: int)) < v - u) \<and> ((0 :: int) \<le> u + (1 :: int) \<and> u + (1 :: int) \<le> v - (1 :: int) + (1 :: int) \<and> v - (1 :: int) + (1 :: int) \<le> int (length (a3[nat u := tmp, nat v := o4]))) \<and> u + (1 :: int) + (v - (1 :: int)) = int (length (a3[nat u := tmp, nat v := o4])) - (1 :: int) \<and> (\<forall>(j :: int). u + (1 :: int) \<le> j \<and> j \<le> v - (1 :: int) \<longrightarrow> (nth (a3[nat u := tmp, nat v := o4]) o nat) j = (nth a2 o nat) j) \<and> (\<forall>(j :: int). (0 :: int) \<le> j \<and> j < u + (1 :: int) \<or> v - (1 :: int) < j \<and> j < int (length (a3[nat u := tmp, nat v := o4])) \<longrightarrow> (nth (a3[nat u := tmp, nat v := o4]) o nat) j = (nth a2 o nat) (int (length (a3[nat u := tmp, nat v := o4])) - (1 :: int) - j)) \<and> permut (nth a2 o nat) (nth (a3[nat u := tmp, nat v := o4]) o nat) (0 :: int) (int (length (a3[nat u := tmp, nat v := o4]))))))))) else let o4 :: int = columns m - (1 :: int) in ((0 :: int) \<le> o4 + (1 :: int) \<longrightarrow> (\<forall>(k :: int). (0 :: int) \<le> k \<and> k < (0 :: int) \<longrightarrow> (nth a3 o nat) k = elts m i k) \<and> (\<forall>(m1 :: int matrix). rows m1 = rows m \<and> columns m1 = columns m \<longrightarrow> (\<forall>(j :: int). ((0 :: int) \<le> j \<and> j \<le> o4) \<and> (\<forall>(k :: int). (0 :: int) \<le> k \<and> k < j \<longrightarrow> (nth a3 o nat) k = elts m1 i k) \<and> (\<forall>(k :: int) (l :: int). ((0 :: int) \<le> k \<and> k < rows m1) \<and> ((0 :: int) \<le> l \<and> l < columns m1) \<and> \<not>k = i \<longrightarrow> elts m1 k l = elts m k l) \<longrightarrow> ((0 :: int) \<le> j \<and> j < int (length a3)) \<and> valid_index m1 i j \<and> (\<forall>(m2 :: int matrix). rows m2 = rows m1 \<and> columns m2 = columns m1 \<longrightarrow> elts m2 = (elts m1)(i := (elts m1 i)(j := a3 ! nat j)) \<longrightarrow> (\<forall>(k :: int). (0 :: int) \<le> k \<and> k < j + (1 :: int) \<longrightarrow> (nth a3 o nat) k = elts m2 i k) \<and> (\<forall>(k :: int) (l :: int). ((0 :: int) \<le> k \<and> k < rows m2) \<and> ((0 :: int) \<le> l \<and> l < columns m2) \<and> \<not>k = i \<longrightarrow> elts m2 k l = elts m k l))) \<and> ((\<forall>(k :: int). (0 :: int) \<le> k \<and> k < o4 + (1 :: int) \<longrightarrow> (nth a3 o nat) k = elts m1 i k) \<and> (\<forall>(k :: int) (l :: int). ((0 :: int) \<le> k \<and> k < rows m1) \<and> ((0 :: int) \<le> l \<and> l < columns m1) \<and> \<not>k = i \<longrightarrow> elts m1 k l = elts m k l) \<longrightarrow> (\<forall>(j :: int) (k :: int). (0 :: int) \<le> j \<and> j < rows m1 \<and> ((0 :: int) \<le> k \<and> k < columns m1) \<and> \<not>j = i \<longrightarrow> elts m1 j k = elts m j k) \<and> (\<forall>(j :: int) (k :: int). (0 :: int) \<le> j \<and> j \<le> k \<and> k < columns m1 \<longrightarrow> (let a4 :: int = elts m1 i j; b :: int = elts m1 i k in if ascending = True then a4 \<le> b else b \<le> a4)) \<and> permut (elts m1 i) (elts m i) (0 :: int) (columns m1)))) \<and> (o4 + (1 :: int) < (0 :: int) \<longrightarrow> (\<forall>(j :: int) (k :: int). (0 :: int) \<le> j \<and> j \<le> k \<and> k < columns m \<longrightarrow> (let a4 :: int = elts m i j; b :: int = elts m i k in if ascending = True then a4 \<le> b else b \<le> a4)) \<and> permut (elts m i) (elts m i) (0 :: int) (columns m)))) else let o3 :: int = columns m - (1 :: int) in ((0 :: int) \<le> o3 + (1 :: int) \<longrightarrow> (\<forall>(k :: int). (0 :: int) \<le> k \<and> k < (0 :: int) \<longrightarrow> (nth a2 o nat) k = elts m i k) \<and> (\<forall>(m1 :: int matrix). rows m1 = rows m \<and> columns m1 = columns m \<longrightarrow> (\<forall>(j :: int). ((0 :: int) \<le> j \<and> j \<le> o3) \<and> (\<forall>(k :: int). (0 :: int) \<le> k \<and> k < j \<longrightarrow> (nth a2 o nat) k = elts m1 i k) \<and> (\<forall>(k :: int) (l :: int). ((0 :: int) \<le> k \<and> k < rows m1) \<and> ((0 :: int) \<le> l \<and> l < columns m1) \<and> \<not>k = i \<longrightarrow> elts m1 k l = elts m k l) \<longrightarrow> ((0 :: int) \<le> j \<and> j < int (length a2)) \<and> valid_index m1 i j \<and> (\<forall>(m2 :: int matrix). rows m2 = rows m1 \<and> columns m2 = columns m1 \<longrightarrow> elts m2 = (elts m1)(i := (elts m1 i)(j := a2 ! nat j)) \<longrightarrow> (\<forall>(k :: int). (0 :: int) \<le> k \<and> k < j + (1 :: int) \<longrightarrow> (nth a2 o nat) k = elts m2 i k) \<and> (\<forall>(k :: int) (l :: int). ((0 :: int) \<le> k \<and> k < rows m2) \<and> ((0 :: int) \<le> l \<and> l < columns m2) \<and> \<not>k = i \<longrightarrow> elts m2 k l = elts m k l))) \<and> ((\<forall>(k :: int). (0 :: int) \<le> k \<and> k < o3 + (1 :: int) \<longrightarrow> (nth a2 o nat) k = elts m1 i k) \<and> (\<forall>(k :: int) (l :: int). ((0 :: int) \<le> k \<and> k < rows m1) \<and> ((0 :: int) \<le> l \<and> l < columns m1) \<and> \<not>k = i \<longrightarrow> elts m1 k l = elts m k l) \<longrightarrow> (\<forall>(j :: int) (k :: int). (0 :: int) \<le> j \<and> j < rows m1 \<and> ((0 :: int) \<le> k \<and> k < columns m1) \<and> \<not>j = i \<longrightarrow> elts m1 j k = elts m j k) \<and> (\<forall>(j :: int) (k :: int). (0 :: int) \<le> j \<and> j \<le> k \<and> k < columns m1 \<longrightarrow> (let a3 :: int = elts m1 i j; b :: int = elts m1 i k in if ascending = True then a3 \<le> b else b \<le> a3)) \<and> permut (elts m1 i) (elts m i) (0 :: int) (columns m1)))) \<and> (o3 + (1 :: int) < (0 :: int) \<longrightarrow> (\<forall>(j :: int) (k :: int). (0 :: int) \<le> j \<and> j \<le> k \<and> k < columns m \<longrightarrow> (let a3 :: int = elts m i j; b :: int = elts m i k in if ascending = True then a3 \<le> b else b \<le> a3)) \<and> permut (elts m i) (elts m i) (0 :: int) (columns m))))))) \<and> (o2 + (1 :: int) < (0 :: int) \<longrightarrow> (\<forall>(a1 :: int list). length a1 = length a \<longrightarrow> (\<forall>(i1 :: int) (j :: int). (0 :: int) \<le> i1 \<and> i1 \<le> j \<and> j < int (length a1) \<longrightarrow> a1 ! nat i1 \<le> a1 ! nat j) \<and> permut (nth a1 o nat) (nth a o nat) (0 :: int) (int (length a1)) \<longrightarrow> (if \<not>ascending = True then let o3 :: int = int (length a1) - (1 :: int) in (((0 :: int) \<le> (0 :: int) \<and> (0 :: int) \<le> o3 + (1 :: int) \<and> o3 + (1 :: int) \<le> int (length a1)) \<and> (0 :: int) + o3 = int (length a1) - (1 :: int) \<and> (\<forall>(j :: int). (0 :: int) \<le> j \<and> j < (0 :: int) \<or> o3 < j \<and> j < int (length a1) \<longrightarrow> (nth a1 o nat) j = (nth a1 o nat) (int (length a1) - (1 :: int) - j)) \<and> permut (nth a1 o nat) (nth a1 o nat) (0 :: int) (int (length a1))) \<and> (\<forall>(v :: int) (u :: int) (a2 :: int list). length a2 = length a1 \<longrightarrow> ((0 :: int) \<le> u \<and> u \<le> v + (1 :: int) \<and> v + (1 :: int) \<le> int (length a2)) \<and> u + v = int (length a2) - (1 :: int) \<and> (\<forall>(j :: int). u \<le> j \<and> j \<le> v \<longrightarrow> (nth a2 o nat) j = (nth a1 o nat) j) \<and> (\<forall>(j :: int). (0 :: int) \<le> j \<and> j < u \<or> v < j \<and> j < int (length a2) \<longrightarrow> (nth a2 o nat) j = (nth a1 o nat) (int (length a2) - (1 :: int) - j)) \<and> permut (nth a1 o nat) (nth a2 o nat) (0 :: int) (int (length a2)) \<longrightarrow> (if u < v then let e :: int \<Rightarrow> int = nth a2 o nat in ((0 :: int) \<le> v \<and> v < int (length a2)) \<and> (let tmp :: int = a2 ! nat v in ((0 :: int) \<le> u \<and> u < int (length a2)) \<and> (let o4 :: int = a2 ! nat u in ((0 :: int) \<le> v \<and> v < int (length a2)) \<and> (length (a2[nat v := o4]) = length a2 \<longrightarrow> nth (a2[nat v := o4]) o nat = (nth a2 o nat)(v := o4) \<longrightarrow> ((0 :: int) \<le> u \<and> u < int (length (a2[nat v := o4]))) \<and> (length (a2[nat u := tmp, nat v := o4]) = length (a2[nat v := o4]) \<longrightarrow> nth (a2[nat u := tmp, nat v := o4]) o nat = (nth (a2[nat v := o4]) o nat)(u := tmp) \<longrightarrow> (let o5 :: int = int (length (a2[nat u := tmp, nat v := o4])); o6 :: int \<Rightarrow> int = nth (a2[nat u := tmp, nat v := o4]) o nat in ((((0 :: int) \<le> u \<and> u < o5) \<and> (0 :: int) \<le> v \<and> v < o5) \<and> (\<forall>(i1 :: int). ((0 :: int) \<le> i1 \<and> i1 \<le> o5) \<and> \<not>i1 = u \<and> \<not>i1 = v \<longrightarrow> o6 i1 = e i1) \<and> o6 u = e v \<and> o6 v = e u) \<and> (permut o6 e (0 :: int) o5 \<longrightarrow> ((0 :: int) \<le> v - u \<and> v - (1 :: int) - (u + (1 :: int)) < v - u) \<and> ((0 :: int) \<le> u + (1 :: int) \<and> u + (1 :: int) \<le> v - (1 :: int) + (1 :: int) \<and> v - (1 :: int) + (1 :: int) \<le> int (length (a2[nat u := tmp, nat v := o4]))) \<and> u + (1 :: int) + (v - (1 :: int)) = int (length (a2[nat u := tmp, nat v := o4])) - (1 :: int) \<and> (\<forall>(j :: int). u + (1 :: int) \<le> j \<and> j \<le> v - (1 :: int) \<longrightarrow> (nth (a2[nat u := tmp, nat v := o4]) o nat) j = (nth a1 o nat) j) \<and> (\<forall>(j :: int). (0 :: int) \<le> j \<and> j < u + (1 :: int) \<or> v - (1 :: int) < j \<and> j < int (length (a2[nat u := tmp, nat v := o4])) \<longrightarrow> (nth (a2[nat u := tmp, nat v := o4]) o nat) j = (nth a1 o nat) (int (length (a2[nat u := tmp, nat v := o4])) - (1 :: int) - j)) \<and> permut (nth a1 o nat) (nth (a2[nat u := tmp, nat v := o4]) o nat) (0 :: int) (int (length (a2[nat u := tmp, nat v := o4]))))))))) else let o4 :: int = columns m - (1 :: int) in ((0 :: int) \<le> o4 + (1 :: int) \<longrightarrow> (\<forall>(k :: int). (0 :: int) \<le> k \<and> k < (0 :: int) \<longrightarrow> (nth a2 o nat) k = elts m i k) \<and> (\<forall>(m1 :: int matrix). rows m1 = rows m \<and> columns m1 = columns m \<longrightarrow> (\<forall>(j :: int). ((0 :: int) \<le> j \<and> j \<le> o4) \<and> (\<forall>(k :: int). (0 :: int) \<le> k \<and> k < j \<longrightarrow> (nth a2 o nat) k = elts m1 i k) \<and> (\<forall>(k :: int) (l :: int). ((0 :: int) \<le> k \<and> k < rows m1) \<and> ((0 :: int) \<le> l \<and> l < columns m1) \<and> \<not>k = i \<longrightarrow> elts m1 k l = elts m k l) \<longrightarrow> ((0 :: int) \<le> j \<and> j < int (length a2)) \<and> valid_index m1 i j \<and> (\<forall>(m2 :: int matrix). rows m2 = rows m1 \<and> columns m2 = columns m1 \<longrightarrow> elts m2 = (elts m1)(i := (elts m1 i)(j := a2 ! nat j)) \<longrightarrow> (\<forall>(k :: int). (0 :: int) \<le> k \<and> k < j + (1 :: int) \<longrightarrow> (nth a2 o nat) k = elts m2 i k) \<and> (\<forall>(k :: int) (l :: int). ((0 :: int) \<le> k \<and> k < rows m2) \<and> ((0 :: int) \<le> l \<and> l < columns m2) \<and> \<not>k = i \<longrightarrow> elts m2 k l = elts m k l))) \<and> ((\<forall>(k :: int). (0 :: int) \<le> k \<and> k < o4 + (1 :: int) \<longrightarrow> (nth a2 o nat) k = elts m1 i k) \<and> (\<forall>(k :: int) (l :: int). ((0 :: int) \<le> k \<and> k < rows m1) \<and> ((0 :: int) \<le> l \<and> l < columns m1) \<and> \<not>k = i \<longrightarrow> elts m1 k l = elts m k l) \<longrightarrow> (\<forall>(j :: int) (k :: int). (0 :: int) \<le> j \<and> j < rows m1 \<and> ((0 :: int) \<le> k \<and> k < columns m1) \<and> \<not>j = i \<longrightarrow> elts m1 j k = elts m j k) \<and> (\<forall>(j :: int) (k :: int). (0 :: int) \<le> j \<and> j \<le> k \<and> k < columns m1 \<longrightarrow> (let a3 :: int = elts m1 i j; b :: int = elts m1 i k in if ascending = True then a3 \<le> b else b \<le> a3)) \<and> permut (elts m1 i) (elts m i) (0 :: int) (columns m1)))) \<and> (o4 + (1 :: int) < (0 :: int) \<longrightarrow> (\<forall>(j :: int) (k :: int). (0 :: int) \<le> j \<and> j \<le> k \<and> k < columns m \<longrightarrow> (let a3 :: int = elts m i j; b :: int = elts m i k in if ascending = True then a3 \<le> b else b \<le> a3)) \<and> permut (elts m i) (elts m i) (0 :: int) (columns m)))) else let o3 :: int = columns m - (1 :: int) in ((0 :: int) \<le> o3 + (1 :: int) \<longrightarrow> (\<forall>(k :: int). (0 :: int) \<le> k \<and> k < (0 :: int) \<longrightarrow> (nth a1 o nat) k = elts m i k) \<and> (\<forall>(m1 :: int matrix). rows m1 = rows m \<and> columns m1 = columns m \<longrightarrow> (\<forall>(j :: int). ((0 :: int) \<le> j \<and> j \<le> o3) \<and> (\<forall>(k :: int). (0 :: int) \<le> k \<and> k < j \<longrightarrow> (nth a1 o nat) k = elts m1 i k) \<and> (\<forall>(k :: int) (l :: int). ((0 :: int) \<le> k \<and> k < rows m1) \<and> ((0 :: int) \<le> l \<and> l < columns m1) \<and> \<not>k = i \<longrightarrow> elts m1 k l = elts m k l) \<longrightarrow> ((0 :: int) \<le> j \<and> j < int (length a1)) \<and> valid_index m1 i j \<and> (\<forall>(m2 :: int matrix). rows m2 = rows m1 \<and> columns m2 = columns m1 \<longrightarrow> elts m2 = (elts m1)(i := (elts m1 i)(j := a1 ! nat j)) \<longrightarrow> (\<forall>(k :: int). (0 :: int) \<le> k \<and> k < j + (1 :: int) \<longrightarrow> (nth a1 o nat) k = elts m2 i k) \<and> (\<forall>(k :: int) (l :: int). ((0 :: int) \<le> k \<and> k < rows m2) \<and> ((0 :: int) \<le> l \<and> l < columns m2) \<and> \<not>k = i \<longrightarrow> elts m2 k l = elts m k l))) \<and> ((\<forall>(k :: int). (0 :: int) \<le> k \<and> k < o3 + (1 :: int) \<longrightarrow> (nth a1 o nat) k = elts m1 i k) \<and> (\<forall>(k :: int) (l :: int). ((0 :: int) \<le> k \<and> k < rows m1) \<and> ((0 :: int) \<le> l \<and> l < columns m1) \<and> \<not>k = i \<longrightarrow> elts m1 k l = elts m k l) \<longrightarrow> (\<forall>(j :: int) (k :: int). (0 :: int) \<le> j \<and> j < rows m1 \<and> ((0 :: int) \<le> k \<and> k < columns m1) \<and> \<not>j = i \<longrightarrow> elts m1 j k = elts m j k) \<and> (\<forall>(j :: int) (k :: int). (0 :: int) \<le> j \<and> j \<le> k \<and> k < columns m1 \<longrightarrow> (let a2 :: int = elts m1 i j; b :: int = elts m1 i k in if ascending = True then a2 \<le> b else b \<le> a2)) \<and> permut (elts m1 i) (elts m i) (0 :: int) (columns m1)))) \<and> (o3 + (1 :: int) < (0 :: int) \<longrightarrow> (\<forall>(j :: int) (k :: int). (0 :: int) \<le> j \<and> j \<le> k \<and> k < columns m \<longrightarrow> (let a2 :: int = elts m i j; b :: int = elts m i k in if ascending = True then a2 \<le> b else b \<le> a2)) \<and> permut (elts m i) (elts m i) (0 :: int) (columns m)))))))"
  sorry
end
