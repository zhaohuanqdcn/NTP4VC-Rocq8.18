(* ---------------------------------------------------------- *)
(* --- Post-condition (file masks.c, line 96) in 'is_core_idle' --- *)
(* ---------------------------------------------------------- *)
theory VCis_core_idle_post
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import A_schedule_cpumask.A_schedule_cpumask
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import Compound.Compound

(*
goal WP "expl:Post-condition (file masks.c, line 96) in 'is_core_idle'":
*)
goal goal0:
  forall p : bool.
  forall i_4 i_3 i_2 i_1 i : int.
  forall t : map int int.
  forall t_1 : map addr int.
  forall t_2 : map addr addr.
  forall a : addr.
  let a_1 = (shiftfield_f1_cpumask_bits ((l_cpu_smt_mask i_4))) in
  let a_2 = t_2[a_1] in
  let x = t_1[(shift_uint8 a_2 i_3)] in
  let x_1 = (to_uint32 i_1) in
  (((l_idle_cpu i_4)) <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= i_1) ->
  (0 <= i_4) ->
  (i_4 < l_size) ->
  (i_1 <= l_size) ->
  (((region (a.base))) <= 0) ->
  ((framed t_2)) ->
  ((linked t)) ->
  ((is_uint8 i_2)) ->
  ((is_uint32 i)) ->
  ((is_sint32 i_1)) ->
  ((is_sint32 i_3)) ->
  ((is_sint32 i_4)) ->
  ((valid_rd t a_1 1)) ->
  ((is_uint8 x)) ->
  ((valid_rd t ((shift_uint8 a_2 0)) l_size)) ->
  (if (((to_uint32 i_3)) < l_size)
   then ((p=False) /\ (i_2 = 0) /\ (i_4 <> i_3) /\
         (((l_idle_cpu i_3)) = 0) /\ (0 <= i_3) /\ (i_3 < l_size))
   else (i_2 = 1)) ->
  ((forall i_5 : int. (i_5 < l_size) -> (x_1 <= i_5) ->
    (t_1[(shift_uint8 a_2 i_5)] = 0)) -> (l_size = i_3)) ->
  ((exists i_5 : int. (t_1[(shift_uint8 a_2 i_5)] <> 0) /\ (i_5 < l_size) /\
    (x_1 <= i_5)) -> (x <> 0)) ->
  ((exists i_5 : int. (t_1[(shift_uint8 a_2 i_5)] <> 0) /\ (i_5 < l_size) /\
    (x_1 <= i_5)) -> (i_3 < l_size)) ->
  ((exists i_5 : int. (t_1[(shift_uint8 a_2 i_5)] <> 0) /\ (i_5 < l_size) /\
    (x_1 <= i_5)) -> ((i_3 < l_size) /\ (x_1 <= i_3))) ->
  ((exists i_5 : int. (t_1[(shift_uint8 a_2 i_5)] <> 0) /\ (i_5 < l_size) /\
    (x_1 <= i_5)) ->
   (forall i_5 : int. (i_5 < i_3) -> (x_1 <= i_5) ->
    (t_1[(shift_uint8 a_2 i_5)] = 0))) ->
  (forall i_5 : int. (t_1[(shift_uint8 a_2 i_5)] <> 0) -> (0 <= i_5) ->
   (i_5 < i_1) -> (((l_idle_cpu i_5)) <> 0)) ->
  (forall i_5 : int. let a_3 = (shift_cpumask a i_5) in (0 <= i_5) ->
   (i_5 < l_size) ->
   (((valid_rd t a_3 1)) /\
    ((valid_rw t ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_3)] 0))
       l_size)))) ->
  (forall a_3 : addr. let a_4 = (l_sched_group_cpus a_3) in
   let a_5 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_4)] 0) in
   ((valid_rd t a_4 1)) /\ ((valid_rd t a_5 l_size)) /\
   (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
    ((separated a_5 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_5)))] 0))
       l_size)))) ->
  (forall a_3 : addr. let a_4 = (l_sched_group_mask a_3) in
   let a_5 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_4)] 0) in
   ((valid_rd t a_4 1)) /\ ((valid_rd t a_5 l_size)) /\
   (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
    ((separated a_5 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_5)))] 0))
       l_size)))) ->
  (forall a_3 : addr. let a_4 = (l_group_balance_mask a_3) in
   let a_5 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_4)] 0) in
   ((valid_rd t a_4 1)) /\ ((valid_rd t a_5 l_size)) /\
   (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
    ((separated a_5 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_5)))] 0))
       l_size)))) ->
  (forall i_5 : int. let a_3 = (l_cpu_smt_mask i_5) in
   let a_4 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_3)] 0) in
   (0 <= i_5) -> (i_5 < l_size) ->
   (((valid_rd t a_3 1)) /\ ((valid_rd t a_4 l_size)) /\
    (forall i_6 : int. (0 <= i_6) -> (i_6 < l_size) ->
     ((separated a_4 l_size
        ((shift_uint8
           t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_6)))] 0))
        l_size))))) ->
  (((p_idle_core t_2 t_1 i_4)) <-> (i_2 <> 0))

end

(* ---------------------------------------------------------- *)
(* --- Preservation of Invariant (file masks.c, line 103) --- *)
(* ---------------------------------------------------------- *)
theory VCis_core_idle_loop_inv_preserved
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import A_schedule_cpumask.A_schedule_cpumask
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import Compound.Compound

(*
goal WP "expl:Preservation of Invariant (file masks.c, line 103)":
*)
goal goal1:
  forall i_4 i_3 i_2 i_1 i : int.
  forall t : map int int.
  forall t_1 : map addr int.
  forall t_2 : map addr addr.
  forall a : addr.
  let a_1 = (shiftfield_f1_cpumask_bits ((l_cpu_smt_mask i_4))) in
  let a_2 = t_2[a_1] in
  let x = t_1[(shift_uint8 a_2 i_3)] in
  let x_1 = (to_uint32 i_1) in
  (((l_idle_cpu i_4)) <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= i_1) ->
  (0 <= i_4) ->
  (i_4 < l_size) ->
  (i_1 <= l_size) ->
  (((to_uint32 i_3)) < l_size) ->
  (((region (a.base))) <= 0) ->
  ((framed t_2)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((is_sint32 i_1)) ->
  ((is_sint32 i_2)) ->
  ((is_sint32 i_3)) ->
  ((is_sint32 i_4)) ->
  ((valid_rd t a_1 1)) ->
  ((is_uint8 x)) ->
  ((valid_rd t ((shift_uint8 a_2 0)) l_size)) ->
  (if (i_4 = i_3) then (((1 + i_4) = i_2) /\ (i_4 <= 2147483646))
   else ((((l_idle_cpu i_3)) <> 0) /\ ((1 + i_3) = i_2) /\ (0 <= i_3) /\
         (i_3 < l_size) /\ (i_3 <= 2147483646))) ->
  ((forall i_5 : int. (i_5 < l_size) -> (x_1 <= i_5) ->
    (t_1[(shift_uint8 a_2 i_5)] = 0)) -> (l_size = i_3)) ->
  ((exists i_5 : int. (t_1[(shift_uint8 a_2 i_5)] <> 0) /\ (i_5 < l_size) /\
    (x_1 <= i_5)) -> (x <> 0)) ->
  ((exists i_5 : int. (t_1[(shift_uint8 a_2 i_5)] <> 0) /\ (i_5 < l_size) /\
    (x_1 <= i_5)) -> (i_3 < l_size)) ->
  ((exists i_5 : int. (t_1[(shift_uint8 a_2 i_5)] <> 0) /\ (i_5 < l_size) /\
    (x_1 <= i_5)) -> ((i_3 < l_size) /\ (x_1 <= i_3))) ->
  ((exists i_5 : int. (t_1[(shift_uint8 a_2 i_5)] <> 0) /\ (i_5 < l_size) /\
    (x_1 <= i_5)) ->
   (forall i_5 : int. (i_5 < i_3) -> (x_1 <= i_5) ->
    (t_1[(shift_uint8 a_2 i_5)] = 0))) ->
  (forall i_5 : int. (t_1[(shift_uint8 a_2 i_5)] <> 0) -> (0 <= i_5) ->
   (i_5 < i_1) -> (((l_idle_cpu i_5)) <> 0)) ->
  (forall i_5 : int. let a_3 = (shift_cpumask a i_5) in (0 <= i_5) ->
   (i_5 < l_size) ->
   (((valid_rd t a_3 1)) /\
    ((valid_rw t ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_3)] 0))
       l_size)))) ->
  (forall a_3 : addr. let a_4 = (l_sched_group_cpus a_3) in
   let a_5 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_4)] 0) in
   ((valid_rd t a_4 1)) /\ ((valid_rd t a_5 l_size)) /\
   (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
    ((separated a_5 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_5)))] 0))
       l_size)))) ->
  (forall a_3 : addr. let a_4 = (l_sched_group_mask a_3) in
   let a_5 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_4)] 0) in
   ((valid_rd t a_4 1)) /\ ((valid_rd t a_5 l_size)) /\
   (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
    ((separated a_5 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_5)))] 0))
       l_size)))) ->
  (forall a_3 : addr. let a_4 = (l_group_balance_mask a_3) in
   let a_5 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_4)] 0) in
   ((valid_rd t a_4 1)) /\ ((valid_rd t a_5 l_size)) /\
   (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
    ((separated a_5 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_5)))] 0))
       l_size)))) ->
  (forall i_5 : int. let a_3 = (l_cpu_smt_mask i_5) in
   let a_4 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_3)] 0) in
   (0 <= i_5) -> (i_5 < l_size) ->
   (((valid_rd t a_3 1)) /\ ((valid_rd t a_4 l_size)) /\
    (forall i_6 : int. (0 <= i_6) -> (i_6 < l_size) ->
     ((separated a_4 l_size
        ((shift_uint8
           t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_6)))] 0))
        l_size))))) ->
  ((0 <= i_2) /\ (i_2 <= l_size))

end

(* ---------------------------------------------------------- *)
(* --- Establishment of Invariant (file masks.c, line 103) --- *)
(* ---------------------------------------------------------- *)
theory VCis_core_idle_loop_inv_established
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import A_schedule_cpumask.A_schedule_cpumask
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import Compound.Compound

(*
goal WP "expl:Establishment of Invariant (file masks.c, line 103)":
*)
goal goal2:
  forall i_1 i : int.
  forall t : map int int.
  forall t_1 : map addr addr.
  forall a : addr.
  (((l_idle_cpu i_1)) <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= i_1) ->
  (i_1 < l_size) ->
  (((region (a.base))) <= 0) ->
  ((framed t_1)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((is_sint32 i_1)) ->
  (forall i_2 : int. let a_1 = (shift_cpumask a i_2) in (0 <= i_2) ->
   (i_2 < l_size) ->
   (((valid_rd t a_1 1)) /\
    ((valid_rw t ((shift_uint8 t_1[(shiftfield_f1_cpumask_bits a_1)] 0))
       l_size)))) ->
  (forall a_1 : addr. let a_2 = (l_sched_group_cpus a_1) in
   let a_3 = (shift_uint8 t_1[(shiftfield_f1_cpumask_bits a_2)] 0) in
   ((valid_rd t a_2 1)) /\ ((valid_rd t a_3 l_size)) /\
   (forall i_2 : int. (0 <= i_2) -> (i_2 < l_size) ->
    ((separated a_3 l_size
       ((shift_uint8
          t_1[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_2)))] 0))
       l_size)))) ->
  (forall a_1 : addr. let a_2 = (l_sched_group_mask a_1) in
   let a_3 = (shift_uint8 t_1[(shiftfield_f1_cpumask_bits a_2)] 0) in
   ((valid_rd t a_2 1)) /\ ((valid_rd t a_3 l_size)) /\
   (forall i_2 : int. (0 <= i_2) -> (i_2 < l_size) ->
    ((separated a_3 l_size
       ((shift_uint8
          t_1[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_2)))] 0))
       l_size)))) ->
  (forall a_1 : addr. let a_2 = (l_group_balance_mask a_1) in
   let a_3 = (shift_uint8 t_1[(shiftfield_f1_cpumask_bits a_2)] 0) in
   ((valid_rd t a_2 1)) /\ ((valid_rd t a_3 l_size)) /\
   (forall i_2 : int. (0 <= i_2) -> (i_2 < l_size) ->
    ((separated a_3 l_size
       ((shift_uint8
          t_1[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_2)))] 0))
       l_size)))) ->
  (forall i_2 : int. let a_1 = (l_cpu_smt_mask i_2) in
   let a_2 = (shift_uint8 t_1[(shiftfield_f1_cpumask_bits a_1)] 0) in
   (0 <= i_2) -> (i_2 < l_size) ->
   (((valid_rd t a_1 1)) /\ ((valid_rd t a_2 l_size)) /\
    (forall i_3 : int. (0 <= i_3) -> (i_3 < l_size) ->
     ((separated a_2 l_size
        ((shift_uint8
           t_1[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_3)))] 0))
        l_size))))) ->
  (0 <= l_size)

end

(* ---------------------------------------------------------- *)
(* --- Preservation of Invariant (file masks.c, line 104) --- *)
(* ---------------------------------------------------------- *)
theory VCis_core_idle_loop_inv_2_preserved
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import A_schedule_cpumask.A_schedule_cpumask
use import Compound.Compound
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint

(*
goal WP "expl:Preservation of Invariant (file masks.c, line 104)":
*)
goal goal3:
  forall i_5 i_4 i_3 i_2 i_1 i : int.
  forall t : map int int.
  forall t_1 : map addr int.
  forall t_2 : map addr addr.
  forall a : addr.
  let a_1 = (shiftfield_f1_cpumask_bits ((l_cpu_smt_mask i_5))) in
  let a_2 = t_2[a_1] in
  let x = t_1[(shift_uint8 a_2 i_4)] in
  let x_1 = (to_uint32 i_2) in
  (((l_idle_cpu i_5)) <> 0) ->
  (t_1[(shift_uint8 a_2 i_3)] <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (i_3 <= i_1) ->
  (0 <= i_2) ->
  (0 <= i_3) ->
  (0 <= i_5) ->
  (i_5 < l_size) ->
  (i_2 <= l_size) ->
  (((to_uint32 i_4)) < l_size) ->
  (((region (a.base))) <= 0) ->
  ((framed t_2)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((is_sint32 i_1)) ->
  ((is_sint32 i_2)) ->
  ((is_sint32 i_4)) ->
  ((is_sint32 i_5)) ->
  ((is_sint32 (1 + i_1))) ->
  ((valid_rd t a_1 1)) ->
  ((is_uint8 x)) ->
  ((valid_rd t ((shift_uint8 a_2 0)) l_size)) ->
  (if (i_5 = i_4) then ((i_5 = i_1) /\ (i_5 <= 2147483646))
   else ((i_4 = i_1) /\ (((l_idle_cpu i_4)) <> 0) /\ (0 <= i_4) /\
         (i_4 < l_size) /\ (i_4 <= 2147483646))) ->
  ((forall i_6 : int. (i_6 < l_size) -> (x_1 <= i_6) ->
    (t_1[(shift_uint8 a_2 i_6)] = 0)) -> (l_size = i_4)) ->
  ((exists i_6 : int. (t_1[(shift_uint8 a_2 i_6)] <> 0) /\ (i_6 < l_size) /\
    (x_1 <= i_6)) -> (x <> 0)) ->
  ((exists i_6 : int. (t_1[(shift_uint8 a_2 i_6)] <> 0) /\ (i_6 < l_size) /\
    (x_1 <= i_6)) -> (i_4 < l_size)) ->
  ((exists i_6 : int. (t_1[(shift_uint8 a_2 i_6)] <> 0) /\ (i_6 < l_size) /\
    (x_1 <= i_6)) -> ((i_4 < l_size) /\ (x_1 <= i_4))) ->
  ((exists i_6 : int. (t_1[(shift_uint8 a_2 i_6)] <> 0) /\ (i_6 < l_size) /\
    (x_1 <= i_6)) ->
   (forall i_6 : int. (i_6 < i_4) -> (x_1 <= i_6) ->
    (t_1[(shift_uint8 a_2 i_6)] = 0))) ->
  (forall i_6 : int. (t_1[(shift_uint8 a_2 i_6)] <> 0) -> (0 <= i_6) ->
   (i_6 < i_2) -> (((l_idle_cpu i_6)) <> 0)) ->
  (forall i_6 : int. let a_3 = (shift_cpumask a i_6) in (0 <= i_6) ->
   (i_6 < l_size) ->
   (((valid_rd t a_3 1)) /\
    ((valid_rw t ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_3)] 0))
       l_size)))) ->
  (forall a_3 : addr. let a_4 = (l_sched_group_cpus a_3) in
   let a_5 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_4)] 0) in
   ((valid_rd t a_4 1)) /\ ((valid_rd t a_5 l_size)) /\
   (forall i_6 : int. (0 <= i_6) -> (i_6 < l_size) ->
    ((separated a_5 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_6)))] 0))
       l_size)))) ->
  (forall a_3 : addr. let a_4 = (l_sched_group_mask a_3) in
   let a_5 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_4)] 0) in
   ((valid_rd t a_4 1)) /\ ((valid_rd t a_5 l_size)) /\
   (forall i_6 : int. (0 <= i_6) -> (i_6 < l_size) ->
    ((separated a_5 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_6)))] 0))
       l_size)))) ->
  (forall a_3 : addr. let a_4 = (l_group_balance_mask a_3) in
   let a_5 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_4)] 0) in
   ((valid_rd t a_4 1)) /\ ((valid_rd t a_5 l_size)) /\
   (forall i_6 : int. (0 <= i_6) -> (i_6 < l_size) ->
    ((separated a_5 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_6)))] 0))
       l_size)))) ->
  (forall i_6 : int. let a_3 = (l_cpu_smt_mask i_6) in
   let a_4 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_3)] 0) in
   (0 <= i_6) -> (i_6 < l_size) ->
   (((valid_rd t a_3 1)) /\ ((valid_rd t a_4 l_size)) /\
    (forall i_7 : int. (0 <= i_7) -> (i_7 < l_size) ->
     ((separated a_4 l_size
        ((shift_uint8
           t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_7)))] 0))
        l_size))))) ->
  (((l_idle_cpu i_3)) <> 0)

end

(* ---------------------------------------------------------- *)
(* --- Assertion 'rte,mem_access' (file masks.c, line 108) --- *)
(* ---------------------------------------------------------- *)
theory VCis_core_idle_assert_rte_mem_access
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import A_schedule_cpumask.A_schedule_cpumask
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import Compound.Compound

(*
goal WP "expl:Assertion 'rte,mem_access' (file masks.c, line 108)":
*)
goal goal4:
  forall i_2 i_1 i : int.
  forall t : map int int.
  forall t_1 : map addr int.
  forall t_2 : map addr addr.
  forall a : addr.
  let a_1 = (shiftfield_f1_cpumask_bits ((l_cpu_smt_mask i_2))) in
  (((l_idle_cpu i_2)) <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= i_1) ->
  (0 <= i_2) ->
  (i_2 < l_size) ->
  (i_1 <= l_size) ->
  (((region (a.base))) <= 0) ->
  ((framed t_2)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((is_sint32 i_1)) ->
  ((is_sint32 i_2)) ->
  (forall i_3 : int. (t_1[(shift_uint8 t_2[a_1] i_3)] <> 0) -> (0 <= i_3) ->
   (i_3 < i_1) -> (((l_idle_cpu i_3)) <> 0)) ->
  (forall i_3 : int. let a_2 = (shift_cpumask a i_3) in (0 <= i_3) ->
   (i_3 < l_size) ->
   (((valid_rd t a_2 1)) /\
    ((valid_rw t ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_2)] 0))
       l_size)))) ->
  (forall a_2 : addr. let a_3 = (l_sched_group_cpus a_2) in
   let a_4 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_3)] 0) in
   ((valid_rd t a_3 1)) /\ ((valid_rd t a_4 l_size)) /\
   (forall i_3 : int. (0 <= i_3) -> (i_3 < l_size) ->
    ((separated a_4 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_3)))] 0))
       l_size)))) ->
  (forall a_2 : addr. let a_3 = (l_sched_group_mask a_2) in
   let a_4 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_3)] 0) in
   ((valid_rd t a_3 1)) /\ ((valid_rd t a_4 l_size)) /\
   (forall i_3 : int. (0 <= i_3) -> (i_3 < l_size) ->
    ((separated a_4 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_3)))] 0))
       l_size)))) ->
  (forall a_2 : addr. let a_3 = (l_group_balance_mask a_2) in
   let a_4 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_3)] 0) in
   ((valid_rd t a_3 1)) /\ ((valid_rd t a_4 l_size)) /\
   (forall i_3 : int. (0 <= i_3) -> (i_3 < l_size) ->
    ((separated a_4 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_3)))] 0))
       l_size)))) ->
  (forall i_3 : int. let a_2 = (l_cpu_smt_mask i_3) in
   let a_3 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_2)] 0) in
   (0 <= i_3) -> (i_3 < l_size) ->
   (((valid_rd t a_2 1)) /\ ((valid_rd t a_3 l_size)) /\
    (forall i_4 : int. (0 <= i_4) -> (i_4 < l_size) ->
     ((separated a_3 l_size
        ((shift_uint8
           t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_4)))] 0))
        l_size))))) ->
  ((valid_rd t a_1 1))

end

(* ---------------------------------------------------------- *)
(* --- Assertion 'rte,bool_value' (file masks.c, line 112) --- *)
(* ---------------------------------------------------------- *)
theory VCis_core_idle_assert_rte_bool_value
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import A_schedule_cpumask.A_schedule_cpumask
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import Compound.Compound

(*
goal WP "expl:Assertion 'rte,bool_value' (file masks.c, line 112)":
*)
goal goal5:
  forall i_4 i_3 i_2 i_1 i : int.
  forall t : map int int.
  forall t_1 : map addr int.
  forall t_2 : map addr addr.
  forall a : addr.
  let a_1 = (shiftfield_f1_cpumask_bits ((l_cpu_smt_mask i_4))) in
  let a_2 = t_2[a_1] in
  let x = t_1[(shift_uint8 a_2 i_2)] in
  let x_1 = (to_uint32 i_3) in
  (i_4 <> i_2) ->
  (((l_idle_cpu i_4)) <> 0) ->
  ((((l_idle_cpu i_2)) <> 0) <-> (i <> 0)) ->
  (0 <= i_1) ->
  (i_1 < l_size) ->
  (0 <= i_2) ->
  (i_2 < l_size) ->
  (0 <= i_3) ->
  (0 <= i_4) ->
  (i_4 < l_size) ->
  (i_3 <= l_size) ->
  (((to_uint32 i_2)) < l_size) ->
  (((region (a.base))) <= 0) ->
  ((framed t_2)) ->
  ((linked t)) ->
  ((is_uint8 i)) ->
  ((is_uint32 i_1)) ->
  ((is_sint32 i_2)) ->
  ((is_sint32 i_3)) ->
  ((is_sint32 i_4)) ->
  ((valid_rd t a_1 1)) ->
  ((is_uint8 x)) ->
  ((valid_rd t ((shift_uint8 a_2 0)) l_size)) ->
  ((forall i_5 : int. (i_5 < l_size) -> (x_1 <= i_5) ->
    (t_1[(shift_uint8 a_2 i_5)] = 0)) -> (l_size = i_2)) ->
  ((exists i_5 : int. (t_1[(shift_uint8 a_2 i_5)] <> 0) /\ (i_5 < l_size) /\
    (x_1 <= i_5)) -> (x <> 0)) ->
  ((exists i_5 : int. (t_1[(shift_uint8 a_2 i_5)] <> 0) /\ (i_5 < l_size) /\
    (x_1 <= i_5)) -> (x_1 <= i_2)) ->
  ((exists i_5 : int. (t_1[(shift_uint8 a_2 i_5)] <> 0) /\ (i_5 < l_size) /\
    (x_1 <= i_5)) ->
   (forall i_5 : int. (i_5 < i_2) -> (x_1 <= i_5) ->
    (t_1[(shift_uint8 a_2 i_5)] = 0))) ->
  (forall i_5 : int. (t_1[(shift_uint8 a_2 i_5)] <> 0) -> (0 <= i_5) ->
   (i_5 < i_3) -> (((l_idle_cpu i_5)) <> 0)) ->
  (forall i_5 : int. let a_3 = (shift_cpumask a i_5) in (0 <= i_5) ->
   (i_5 < l_size) ->
   (((valid_rd t a_3 1)) /\
    ((valid_rw t ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_3)] 0))
       l_size)))) ->
  (forall a_3 : addr. let a_4 = (l_sched_group_cpus a_3) in
   let a_5 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_4)] 0) in
   ((valid_rd t a_4 1)) /\ ((valid_rd t a_5 l_size)) /\
   (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
    ((separated a_5 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_5)))] 0))
       l_size)))) ->
  (forall a_3 : addr. let a_4 = (l_sched_group_mask a_3) in
   let a_5 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_4)] 0) in
   ((valid_rd t a_4 1)) /\ ((valid_rd t a_5 l_size)) /\
   (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
    ((separated a_5 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_5)))] 0))
       l_size)))) ->
  (forall a_3 : addr. let a_4 = (l_group_balance_mask a_3) in
   let a_5 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_4)] 0) in
   ((valid_rd t a_4 1)) /\ ((valid_rd t a_5 l_size)) /\
   (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
    ((separated a_5 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_5)))] 0))
       l_size)))) ->
  (forall i_5 : int. let a_3 = (l_cpu_smt_mask i_5) in
   let a_4 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_3)] 0) in
   (0 <= i_5) -> (i_5 < l_size) ->
   (((valid_rd t a_3 1)) /\ ((valid_rd t a_4 l_size)) /\
    (forall i_6 : int. (0 <= i_6) -> (i_6 < l_size) ->
     ((separated a_4 l_size
        ((shift_uint8
           t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_6)))] 0))
        l_size))))) ->
  ((i = 0) \/ (i = 1))

end

(* ---------------------------------------------------------- *)
(* --- Assertion 'rte,signed_overflow' (file masks.c, line 108) --- *)
(* ---------------------------------------------------------- *)
theory VCis_core_idle_assert_rte_signed_overflow
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import A_schedule_cpumask.A_schedule_cpumask
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import Compound.Compound

(*
goal WP "expl:Assertion 'rte,signed_overflow' (file masks.c, line 108)":
*)
goal goal6:
  forall p : bool.
  forall i_5 i_4 i_3 i_2 i_1 i : int.
  forall t : map int int.
  forall t_1 : map addr int.
  forall t_2 : map addr addr.
  forall a : addr.
  let a_1 = (shiftfield_f1_cpumask_bits ((l_cpu_smt_mask i_5))) in
  let a_2 = t_2[a_1] in
  let x = t_1[(shift_uint8 a_2 i_4)] in
  let x_1 = (to_uint32 i_3) in
  (((l_idle_cpu i_5)) <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= i_3) ->
  (0 <= i_5) ->
  (i_5 < l_size) ->
  (i_3 <= l_size) ->
  (((to_uint32 i_4)) < l_size) ->
  (((region (a.base))) <= 0) ->
  ((framed t_2)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((is_sint32 i_1)) ->
  ((is_sint32 i_2)) ->
  ((is_sint32 i_3)) ->
  ((is_sint32 i_4)) ->
  ((is_sint32 i_5)) ->
  ((valid_rd t a_1 1)) ->
  ((is_uint8 x)) ->
  ((valid_rd t ((shift_uint8 a_2 0)) l_size)) ->
  (if (i_5 = i_4) then ((p=True) /\ (i_5 = i_2))
   else ((p=False) /\ (i_2 = i_1) /\ (i_4 = i_1) /\ (i_4 = i_2) /\
         (((l_idle_cpu i_2)) <> 0) /\ (0 <= i_2) /\ (i_2 < l_size))) ->
  ((forall i_6 : int. (i_6 < l_size) -> (x_1 <= i_6) ->
    (t_1[(shift_uint8 a_2 i_6)] = 0)) -> (l_size = i_4)) ->
  ((exists i_6 : int. (t_1[(shift_uint8 a_2 i_6)] <> 0) /\ (i_6 < l_size) /\
    (x_1 <= i_6)) -> (x <> 0)) ->
  ((exists i_6 : int. (t_1[(shift_uint8 a_2 i_6)] <> 0) /\ (i_6 < l_size) /\
    (x_1 <= i_6)) -> (i_4 < l_size)) ->
  ((exists i_6 : int. (t_1[(shift_uint8 a_2 i_6)] <> 0) /\ (i_6 < l_size) /\
    (x_1 <= i_6)) -> ((i_4 < l_size) /\ (x_1 <= i_4))) ->
  ((exists i_6 : int. (t_1[(shift_uint8 a_2 i_6)] <> 0) /\ (i_6 < l_size) /\
    (x_1 <= i_6)) ->
   (forall i_6 : int. (i_6 < i_4) -> (x_1 <= i_6) ->
    (t_1[(shift_uint8 a_2 i_6)] = 0))) ->
  (forall i_6 : int. (t_1[(shift_uint8 a_2 i_6)] <> 0) -> (0 <= i_6) ->
   (i_6 < i_3) -> (((l_idle_cpu i_6)) <> 0)) ->
  (forall i_6 : int. let a_3 = (shift_cpumask a i_6) in (0 <= i_6) ->
   (i_6 < l_size) ->
   (((valid_rd t a_3 1)) /\
    ((valid_rw t ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_3)] 0))
       l_size)))) ->
  (forall a_3 : addr. let a_4 = (l_sched_group_cpus a_3) in
   let a_5 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_4)] 0) in
   ((valid_rd t a_4 1)) /\ ((valid_rd t a_5 l_size)) /\
   (forall i_6 : int. (0 <= i_6) -> (i_6 < l_size) ->
    ((separated a_5 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_6)))] 0))
       l_size)))) ->
  (forall a_3 : addr. let a_4 = (l_sched_group_mask a_3) in
   let a_5 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_4)] 0) in
   ((valid_rd t a_4 1)) /\ ((valid_rd t a_5 l_size)) /\
   (forall i_6 : int. (0 <= i_6) -> (i_6 < l_size) ->
    ((separated a_5 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_6)))] 0))
       l_size)))) ->
  (forall a_3 : addr. let a_4 = (l_group_balance_mask a_3) in
   let a_5 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_4)] 0) in
   ((valid_rd t a_4 1)) /\ ((valid_rd t a_5 l_size)) /\
   (forall i_6 : int. (0 <= i_6) -> (i_6 < l_size) ->
    ((separated a_5 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_6)))] 0))
       l_size)))) ->
  (forall i_6 : int. let a_3 = (l_cpu_smt_mask i_6) in
   let a_4 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_3)] 0) in
   (0 <= i_6) -> (i_6 < l_size) ->
   (((valid_rd t a_3 1)) /\ ((valid_rd t a_4 l_size)) /\
    (forall i_7 : int. (0 <= i_7) -> (i_7 < l_size) ->
     ((separated a_4 l_size
        ((shift_uint8
           t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_7)))] 0))
        l_size))))) ->
  (if (p=True) then (i_2 <= 2147483646) else (i_1 <= 2147483646))

end

(* ---------------------------------------------------------- *)
(* --- Decreasing of Loop variant at loop (file masks.c, line 108) --- *)
(* ---------------------------------------------------------- *)
theory VCis_core_idle_loop_term_decrease
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import A_schedule_cpumask.A_schedule_cpumask
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import Compound.Compound

(*
goal WP "expl:Decreasing of Loop variant at loop (file masks.c, line 108)":
*)
goal goal7:
  forall i_4 i_3 i_2 i_1 i : int.
  forall t : map int int.
  forall t_1 : map addr int.
  forall t_2 : map addr addr.
  forall a : addr.
  let a_1 = (shiftfield_f1_cpumask_bits ((l_cpu_smt_mask i_4))) in
  let a_2 = t_2[a_1] in
  let x = t_1[(shift_uint8 a_2 i_3)] in
  let x_1 = (to_uint32 i_1) in
  (((l_idle_cpu i_4)) <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= i_1) ->
  (0 <= i_4) ->
  (i_4 < l_size) ->
  (i_1 <= l_size) ->
  (((to_uint32 i_3)) < l_size) ->
  (((region (a.base))) <= 0) ->
  ((framed t_2)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((is_sint32 i_1)) ->
  ((is_sint32 i_2)) ->
  ((is_sint32 i_3)) ->
  ((is_sint32 i_4)) ->
  ((valid_rd t a_1 1)) ->
  ((is_uint8 x)) ->
  ((valid_rd t ((shift_uint8 a_2 0)) l_size)) ->
  (if (i_4 = i_3) then (((1 + i_4) = i_2) /\ (i_4 <= 2147483646))
   else ((((l_idle_cpu i_3)) <> 0) /\ ((1 + i_3) = i_2) /\ (0 <= i_3) /\
         (i_3 < l_size) /\ (i_3 <= 2147483646))) ->
  ((forall i_5 : int. (i_5 < l_size) -> (x_1 <= i_5) ->
    (t_1[(shift_uint8 a_2 i_5)] = 0)) -> (l_size = i_3)) ->
  ((exists i_5 : int. (t_1[(shift_uint8 a_2 i_5)] <> 0) /\ (i_5 < l_size) /\
    (x_1 <= i_5)) -> (x <> 0)) ->
  ((exists i_5 : int. (t_1[(shift_uint8 a_2 i_5)] <> 0) /\ (i_5 < l_size) /\
    (x_1 <= i_5)) -> (i_3 < l_size)) ->
  ((exists i_5 : int. (t_1[(shift_uint8 a_2 i_5)] <> 0) /\ (i_5 < l_size) /\
    (x_1 <= i_5)) -> ((i_3 < l_size) /\ (x_1 <= i_3))) ->
  ((exists i_5 : int. (t_1[(shift_uint8 a_2 i_5)] <> 0) /\ (i_5 < l_size) /\
    (x_1 <= i_5)) ->
   (forall i_5 : int. (i_5 < i_3) -> (x_1 <= i_5) ->
    (t_1[(shift_uint8 a_2 i_5)] = 0))) ->
  (forall i_5 : int. (t_1[(shift_uint8 a_2 i_5)] <> 0) -> (0 <= i_5) ->
   (i_5 < i_1) -> (((l_idle_cpu i_5)) <> 0)) ->
  (forall i_5 : int. let a_3 = (shift_cpumask a i_5) in (0 <= i_5) ->
   (i_5 < l_size) ->
   (((valid_rd t a_3 1)) /\
    ((valid_rw t ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_3)] 0))
       l_size)))) ->
  (forall a_3 : addr. let a_4 = (l_sched_group_cpus a_3) in
   let a_5 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_4)] 0) in
   ((valid_rd t a_4 1)) /\ ((valid_rd t a_5 l_size)) /\
   (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
    ((separated a_5 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_5)))] 0))
       l_size)))) ->
  (forall a_3 : addr. let a_4 = (l_sched_group_mask a_3) in
   let a_5 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_4)] 0) in
   ((valid_rd t a_4 1)) /\ ((valid_rd t a_5 l_size)) /\
   (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
    ((separated a_5 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_5)))] 0))
       l_size)))) ->
  (forall a_3 : addr. let a_4 = (l_group_balance_mask a_3) in
   let a_5 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_4)] 0) in
   ((valid_rd t a_4 1)) /\ ((valid_rd t a_5 l_size)) /\
   (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
    ((separated a_5 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_5)))] 0))
       l_size)))) ->
  (forall i_5 : int. let a_3 = (l_cpu_smt_mask i_5) in
   let a_4 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_3)] 0) in
   (0 <= i_5) -> (i_5 < l_size) ->
   (((valid_rd t a_3 1)) /\ ((valid_rd t a_4 l_size)) /\
    (forall i_6 : int. (0 <= i_6) -> (i_6 < l_size) ->
     ((separated a_4 l_size
        ((shift_uint8
           t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_6)))] 0))
        l_size))))) ->
  (i_1 < i_2)

end

(* ---------------------------------------------------------- *)
(* --- Instance of 'Pre-condition (file for_loops.c, line 13) in 'find_next_bit'' in 'is_core_idle' at call 'find_next_bit' (file masks.c, line 108)
 --- *)
(* ---------------------------------------------------------- *)
theory VCis_core_idle_call_find_next_bit_pre_2
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import A_schedule_cpumask.A_schedule_cpumask
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import Compound.Compound

(*
goal WP "expl:Instance of 'Pre-condition (file for_loops.c, line 13) in 'find_next_bit'' in 'is_core_idle' at call 'find_next_bit' (file masks.c, line 108)
":
*)
goal goal8:
  forall i_2 i_1 i : int.
  forall t : map int int.
  forall t_1 : map addr int.
  forall t_2 : map addr addr.
  forall a : addr.
  let a_1 = (shiftfield_f1_cpumask_bits ((l_cpu_smt_mask i_2))) in
  let a_2 = t_2[a_1] in
  (((l_idle_cpu i_2)) <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= i_1) ->
  (0 <= i_2) ->
  (i_2 < l_size) ->
  (i_1 <= l_size) ->
  (((region (a.base))) <= 0) ->
  ((framed t_2)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((is_sint32 i_1)) ->
  ((is_sint32 i_2)) ->
  ((valid_rd t a_1 1)) ->
  (forall i_3 : int. (t_1[(shift_uint8 a_2 i_3)] <> 0) -> (0 <= i_3) ->
   (i_3 < i_1) -> (((l_idle_cpu i_3)) <> 0)) ->
  (forall i_3 : int. let a_3 = (shift_cpumask a i_3) in (0 <= i_3) ->
   (i_3 < l_size) ->
   (((valid_rd t a_3 1)) /\
    ((valid_rw t ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_3)] 0))
       l_size)))) ->
  (forall a_3 : addr. let a_4 = (l_sched_group_cpus a_3) in
   let a_5 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_4)] 0) in
   ((valid_rd t a_4 1)) /\ ((valid_rd t a_5 l_size)) /\
   (forall i_3 : int. (0 <= i_3) -> (i_3 < l_size) ->
    ((separated a_5 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_3)))] 0))
       l_size)))) ->
  (forall a_3 : addr. let a_4 = (l_sched_group_mask a_3) in
   let a_5 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_4)] 0) in
   ((valid_rd t a_4 1)) /\ ((valid_rd t a_5 l_size)) /\
   (forall i_3 : int. (0 <= i_3) -> (i_3 < l_size) ->
    ((separated a_5 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_3)))] 0))
       l_size)))) ->
  (forall a_3 : addr. let a_4 = (l_group_balance_mask a_3) in
   let a_5 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_4)] 0) in
   ((valid_rd t a_4 1)) /\ ((valid_rd t a_5 l_size)) /\
   (forall i_3 : int. (0 <= i_3) -> (i_3 < l_size) ->
    ((separated a_5 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_3)))] 0))
       l_size)))) ->
  (forall i_3 : int. let a_3 = (l_cpu_smt_mask i_3) in
   let a_4 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_3)] 0) in
   (0 <= i_3) -> (i_3 < l_size) ->
   (((valid_rd t a_3 1)) /\ ((valid_rd t a_4 l_size)) /\
    (forall i_4 : int. (0 <= i_4) -> (i_4 < l_size) ->
     ((separated a_4 l_size
        ((shift_uint8
           t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_4)))] 0))
        l_size))))) ->
  ((valid_rd t ((shift_uint8 a_2 0)) l_size))

end

(* ---------------------------------------------------------- *)
(* --- Instance of 'Pre-condition (file masks.c, line 85) in 'idle_cpu'' in 'is_core_idle' at call 'idle_cpu' (file masks.c, line 112)
 --- *)
(* ---------------------------------------------------------- *)
theory VCis_core_idle_call_idle_cpu_pre
  
use import bool.Bool
use import int.Int
use import int.ComputerDivision
use import real.RealInfix
use import Qed.Qed
use import int.Abs as IAbs
use import map.Map
use import Memory.Memory
use import A_schedule_cpumask.A_schedule_cpumask
use import A_thread_variables_properties.A_thread_variables_properties
use import Cint.Cint
use import Compound.Compound

(*
goal WP "expl:Instance of 'Pre-condition (file masks.c, line 85) in 'idle_cpu'' in 'is_core_idle' at call 'idle_cpu' (file masks.c, line 112)
":
*)
goal goal9:
  forall i_3 i_2 i_1 i : int.
  forall t : map int int.
  forall t_1 : map addr int.
  forall t_2 : map addr addr.
  forall a : addr.
  let a_1 = (shiftfield_f1_cpumask_bits ((l_cpu_smt_mask i_3))) in
  let a_2 = t_2[a_1] in
  let x = t_1[(shift_uint8 a_2 i_1)] in
  let x_1 = (to_uint32 i_2) in
  (i_3 <> i_1) ->
  (((l_idle_cpu i_3)) <> 0) ->
  (0 <= i) ->
  (i < l_size) ->
  (0 <= i_2) ->
  (0 <= i_3) ->
  (i_3 < l_size) ->
  (i_2 <= l_size) ->
  (((to_uint32 i_1)) < l_size) ->
  (((region (a.base))) <= 0) ->
  ((framed t_2)) ->
  ((linked t)) ->
  ((is_uint32 i)) ->
  ((is_sint32 i_1)) ->
  ((is_sint32 i_2)) ->
  ((is_sint32 i_3)) ->
  ((valid_rd t a_1 1)) ->
  ((is_uint8 x)) ->
  ((valid_rd t ((shift_uint8 a_2 0)) l_size)) ->
  ((forall i_4 : int. (i_4 < l_size) -> (x_1 <= i_4) ->
    (t_1[(shift_uint8 a_2 i_4)] = 0)) -> (l_size = i_1)) ->
  ((exists i_4 : int. (t_1[(shift_uint8 a_2 i_4)] <> 0) /\ (i_4 < l_size) /\
    (x_1 <= i_4)) -> (x <> 0)) ->
  ((exists i_4 : int. (t_1[(shift_uint8 a_2 i_4)] <> 0) /\ (i_4 < l_size) /\
    (x_1 <= i_4)) -> (i_1 < l_size)) ->
  ((exists i_4 : int. (t_1[(shift_uint8 a_2 i_4)] <> 0) /\ (i_4 < l_size) /\
    (x_1 <= i_4)) -> ((i_1 < l_size) /\ (x_1 <= i_1))) ->
  ((exists i_4 : int. (t_1[(shift_uint8 a_2 i_4)] <> 0) /\ (i_4 < l_size) /\
    (x_1 <= i_4)) ->
   (forall i_4 : int. (i_4 < i_1) -> (x_1 <= i_4) ->
    (t_1[(shift_uint8 a_2 i_4)] = 0))) ->
  (forall i_4 : int. (t_1[(shift_uint8 a_2 i_4)] <> 0) -> (0 <= i_4) ->
   (i_4 < i_2) -> (((l_idle_cpu i_4)) <> 0)) ->
  (forall i_4 : int. let a_3 = (shift_cpumask a i_4) in (0 <= i_4) ->
   (i_4 < l_size) ->
   (((valid_rd t a_3 1)) /\
    ((valid_rw t ((shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_3)] 0))
       l_size)))) ->
  (forall a_3 : addr. let a_4 = (l_sched_group_cpus a_3) in
   let a_5 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_4)] 0) in
   ((valid_rd t a_4 1)) /\ ((valid_rd t a_5 l_size)) /\
   (forall i_4 : int. (0 <= i_4) -> (i_4 < l_size) ->
    ((separated a_5 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_4)))] 0))
       l_size)))) ->
  (forall a_3 : addr. let a_4 = (l_sched_group_mask a_3) in
   let a_5 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_4)] 0) in
   ((valid_rd t a_4 1)) /\ ((valid_rd t a_5 l_size)) /\
   (forall i_4 : int. (0 <= i_4) -> (i_4 < l_size) ->
    ((separated a_5 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_4)))] 0))
       l_size)))) ->
  (forall a_3 : addr. let a_4 = (l_group_balance_mask a_3) in
   let a_5 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_4)] 0) in
   ((valid_rd t a_4 1)) /\ ((valid_rd t a_5 l_size)) /\
   (forall i_4 : int. (0 <= i_4) -> (i_4 < l_size) ->
    ((separated a_5 l_size
       ((shift_uint8
          t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_4)))] 0))
       l_size)))) ->
  (forall i_4 : int. let a_3 = (l_cpu_smt_mask i_4) in
   let a_4 = (shift_uint8 t_2[(shiftfield_f1_cpumask_bits a_3)] 0) in
   (0 <= i_4) -> (i_4 < l_size) ->
   (((valid_rd t a_3 1)) /\ ((valid_rd t a_4 l_size)) /\
    (forall i_5 : int. (0 <= i_5) -> (i_5 < l_size) ->
     ((separated a_4 l_size
        ((shift_uint8
           t_2[(shiftfield_f1_cpumask_bits ((shift_cpumask a i_5)))] 0))
        l_size))))) ->
  ((0 <= i_1) /\ (i_1 < l_size))

end

