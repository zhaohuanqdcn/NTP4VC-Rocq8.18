import Why3.Base
import Why3.why3.Ref.Ref
import Why3.map.Const
import Why3.map.MapEq
import Why3.mach.int.Unsigned
import Why3.mach.c.C
import pearl.multiprecision.lib.lean.types.Config
import pearl.multiprecision.lib.lean.types.Types
import pearl.multiprecision.lib.lean.types.Int32Eq
import pearl.multiprecision.lib.lean.types.UInt64Eq
import pearl.multiprecision.lib.lean.lemmas.Lemmas
import pearl.multiprecision.lib.lean.ptralias.Alias
open Classical
open Lean4Why3
namespace util_Util_wmpn_copyiqtvc
theorem wmpn_copyi'vc (up : C.ptr (BitVec 64)) (n : BitVec 32) (rp : C.ptr (BitVec 64)) (fact0 : C.valid up (BitVec.toInt n)) (fact1 : C.valid rp (BitVec.toInt n)) (fact2 : C.writable rp = true) (fact3 : C.offset rp ≤ C.offset up ∨ C.offset up + BitVec.toInt n ≤ C.offset rp) : int'32_in_bounds (BitVec.toInt n - (1 : ℤ)) ∧ (∀(o1 : BitVec 32), BitVec.toInt o1 = BitVec.toInt n - (1 : ℤ) → ((0 : ℤ) ≤ BitVec.toInt o1 + (1 : ℤ) → (∀(j : ℤ), (0 : ℤ) ≤ j ∧ j < (0 : ℤ) → C.pelts rp (C.offset rp + j) = C.pelts up (C.offset up + j)) ∧ (∀(up1 : C.ptr (BitVec 64)) (rp1 : C.ptr (BitVec 64)), C.data up1 = C.data rp1 ∧ List.length (C.data rp1) = List.length (C.data up) ∧ C.offset up1 = C.offset up ∧ C.min up1 = C.min up ∧ C.max up1 = C.max up ∧ C.writable up1 = C.writable up ∧ C.zone1 up1 = C.zone1 up → List.length (C.data rp1) = List.length (C.data rp) ∧ C.offset rp1 = C.offset rp ∧ C.min rp1 = C.min rp ∧ C.max rp1 = C.max rp ∧ C.writable rp1 = C.writable rp ∧ C.zone1 rp1 = C.zone1 rp → (∀(i : BitVec 32), let i1 : ℤ := BitVec.toInt i; ((0 : ℤ) ≤ i1 ∧ i1 ≤ BitVec.toInt o1) ∧ (∀(j : ℤ), (0 : ℤ) ≤ j ∧ j < i1 → C.pelts rp1 (C.offset rp1 + j) = C.pelts up (C.offset up1 + j)) ∧ (∀(j : ℤ), j < C.offset rp1 ∨ C.offset rp1 + BitVec.toInt n ≤ j → C.pelts rp1 j = C.pelts rp j) ∧ (∀(j : ℤ), i1 ≤ j ∧ j < BitVec.toInt n → C.pelts up1 (C.offset up1 + j) = C.pelts up (C.offset up1 + j)) → (C.min up1 ≤ C.offset up1 + BitVec.toInt i ∧ C.offset up1 + BitVec.toInt i < C.max up1) ∧ (let lu : BitVec 64 := C.pelts up1 (C.offset up1 + BitVec.toInt i); (C.min up ≤ C.offset up + BitVec.toInt i ∧ C.offset up + BitVec.toInt i < C.max up) ∧ ((C.min rp1 ≤ C.offset rp1 + BitVec.toInt i ∧ C.offset rp1 + BitVec.toInt i < C.max rp1) ∧ C.writable rp1 = true) ∧ (∀(up2 : C.ptr (BitVec 64)) (rp2 : C.ptr (BitVec 64)), C.data up2 = C.data rp2 ∧ List.length (C.data rp2) = List.length (C.data up1) ∧ C.offset up2 = C.offset up1 ∧ C.min up2 = C.min up1 ∧ C.max up2 = C.max up1 ∧ C.writable up2 = C.writable up1 ∧ C.zone1 up2 = C.zone1 up1 → List.length (C.data rp2) = List.length (C.data rp1) ∧ C.offset rp2 = C.offset rp1 ∧ C.min rp2 = C.min rp1 ∧ C.max rp2 = C.max rp1 ∧ C.writable rp2 = C.writable rp1 ∧ C.zone1 rp2 = C.zone1 rp1 → C.pelts rp2 = Function.update (C.pelts rp1) (C.offset rp2 + BitVec.toInt i) lu ∧ C.pelts rp2 (C.offset rp2 + BitVec.toInt i) = lu → (∀(j : ℤ), (0 : ℤ) ≤ j ∧ j < i1 + (1 : ℤ) → C.pelts rp2 (C.offset rp2 + j) = C.pelts up (C.offset up2 + j)) ∧ (∀(j : ℤ), j < C.offset rp2 ∨ C.offset rp2 + BitVec.toInt n ≤ j → C.pelts rp2 j = C.pelts rp j) ∧ (∀(j : ℤ), i1 + (1 : ℤ) ≤ j ∧ j < BitVec.toInt n → C.pelts up2 (C.offset up2 + j) = C.pelts up (C.offset up2 + j))))) ∧ ((∀(j : ℤ), (0 : ℤ) ≤ j ∧ j < BitVec.toInt o1 + (1 : ℤ) → C.pelts rp1 (C.offset rp1 + j) = C.pelts up (C.offset up1 + j)) ∧ (∀(j : ℤ), j < C.offset rp1 ∨ C.offset rp1 + BitVec.toInt n ≤ j → C.pelts rp1 j = C.pelts rp j) ∧ (∀(j : ℤ), BitVec.toInt o1 + (1 : ℤ) ≤ j ∧ j < BitVec.toInt n → C.pelts up1 (C.offset up1 + j) = C.pelts up (C.offset up1 + j)) → Lemmas.map_eq_sub_shift (C.pelts rp1) (C.pelts up) (C.offset rp1) (C.offset up1) (BitVec.toInt n) ∧ (∀(j : ℤ), j < C.offset rp1 ∨ C.offset rp1 + BitVec.toInt n ≤ j → C.pelts rp1 j = C.pelts rp j)))) ∧ (BitVec.toInt o1 + (1 : ℤ) < (0 : ℤ) → Lemmas.map_eq_sub_shift (C.pelts rp) (C.pelts up) (C.offset rp) (C.offset up) (BitVec.toInt n)))
  := sorry
end util_Util_wmpn_copyiqtvc
